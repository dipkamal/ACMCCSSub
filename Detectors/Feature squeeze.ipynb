{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb73c9c",
   "metadata": {},
   "source": [
    "# Feature squeeze implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d8ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0907725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76d0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_dist = lambda x1,x2: np.sum(np.abs(x1 - x2), axis=tuple(range(len(x1.shape))[1:]))\n",
    "l2_dist = lambda x1,x2: np.sum((x1-x2)**2, axis=tuple(range(len(x1.shape))[1:]))**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa96171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: KL-divergence is not symentric.\n",
    "# Designed for probability distribution (e.g. softmax output).\n",
    "def kl(x1, x2):\n",
    "    assert x1.shape == x2.shape\n",
    "    # x1_2d, x2_2d = reshape_2d(x1), reshape_2d(x2)\n",
    "\n",
    "    # Transpose to [?, #num_examples]\n",
    "    x1_2d_t = x1.transpose()\n",
    "    x2_2d_t = x2.transpose()\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    e = entropy(x1_2d_t, x2_2d_t)\n",
    "    e[np.where(e==np.inf)] = 2\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853d40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_precision_py(x, npp):\n",
    "    \"\"\"\n",
    "    Reduce the precision of image, the numpy version.\n",
    "    :param x: a float tensor, which has been scaled to [0, 1].\n",
    "    :param npp: number of possible values per pixel. E.g. it's 256 for 8-bit gray-scale image, and 2 for binarized image.\n",
    "    :return: a tensor representing image(s) with lower precision.\n",
    "    \"\"\"\n",
    "    # Note: 0 is a possible value too.\n",
    "    npp_int = npp - 1\n",
    "    x_int = np.rint(x * npp_int)\n",
    "    x_float = x_int / npp_int\n",
    "    return x_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6aabce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter_py(x, width, height=-1):\n",
    "    \"\"\"\n",
    "    Median smoothing by Scipy.\n",
    "    :param x: a tensor of image(s)\n",
    "    :param width: the width of the sliding window (number of pixels)\n",
    "    :param height: the height of the window. The same as width by default.\n",
    "    :return: a modified tensor with the same shape as x.\n",
    "    \"\"\"\n",
    "    if height == -1:\n",
    "        height = width\n",
    "    var = ndimage.filters.median_filter(x, size=(1,width,height,1), mode='reflect')\n",
    "    #print(\"inside median filter\")\n",
    "    #print(type(var))\n",
    "    return torch.from_numpy(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad5f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeezers implemented in OpenCV\n",
    "# OpenCV expects uint8 as image data type.\n",
    "def opencv_wrapper(imgs, opencv_func, argv):\n",
    "    ret_imgs = []\n",
    "    imgs_copy = imgs\n",
    "\n",
    "    if imgs.shape[3] == 1:\n",
    "        imgs_copy = np.squeeze(imgs)\n",
    "\n",
    "    for img in imgs_copy:\n",
    "        img_uint8 = np.clip(np.rint(img * 255), 0, 255).astype(np.uint8)\n",
    "        ret_img = opencv_func(*[img_uint8]+argv)\n",
    "        if type(ret_img) == tuple:\n",
    "            ret_img = ret_img[1]\n",
    "        ret_img = ret_img.astype(np.float32) / 255.\n",
    "        ret_imgs.append(ret_img)\n",
    "    ret_imgs = np.stack(ret_imgs)\n",
    "\n",
    "    if imgs.shape[3] == 1:\n",
    "        ret_imgs = np.expand_dims(ret_imgs, axis=3)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5604dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_depth_py(x, bits):\n",
    "    precisions = 2**bits\n",
    "    return reduce_precision_py(x, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22758577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_local_means_color_py(imgs, search_window, block_size, photo_render):\n",
    "    import cv2\n",
    "    ret_imgs = opencv_wrapper(imgs, cv2.fastNlMeansDenoisingColored, [None,photo_render,photo_render,block_size,search_window])\n",
    "    return ret_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f125057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33ee257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(model, dataset, X1):\n",
    "    #X1_pred = model.predict(X1)\n",
    "    X1_pred = m(model(X1))\n",
    "    vals_squeezed = []\n",
    "\n",
    "    if dataset == 'mnist':\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.cpu(), 1)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        \n",
    "        #model.predict is tf based. need torch based softmax. \n",
    "        #vals_squeezed.append(model.predict(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.cpu(), 2)\n",
    "        #print((\"outside func\",type(X1_seqeezed_filter_median)))\n",
    "        vals_squeezed.append(m(model(X1_seqeezed_filter_median.to(device))))\n",
    "\n",
    "    else:\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.cpu(), 5)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.cpu(), 2)\n",
    "        #vals_squeezed.append(model(torch.from_numpy(X1_seqeezed_filter_median).float().to(device)))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_filter_median).to(device))))\n",
    "        #X1_seqeezed_filter_local = non_local_means_color_py(X1.cpu().numpy(), 13, 3, 2)\n",
    "        #vals_squeezed.append(m(model((X1_seqeezed_filter_local).to(device))))\n",
    "\n",
    "    dist_array = []\n",
    "    for val_squeezed in vals_squeezed:\n",
    "        dist = np.sum(np.abs(X1_pred.cpu().detach().numpy() - val_squeezed.cpu().detach().numpy()), axis=tuple(range(len(X1_pred.shape))[1:]))\n",
    "        dist_array.append(dist)\n",
    "\n",
    "    dist_array = np.array(dist_array)\n",
    "    return np.max(dist_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0869d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fs(model, dataset, X1, train_fpr):\n",
    "    distances = get_distance(model, dataset, X1)\n",
    "    selected_distance_idx = int(np.ceil(len(X1) * (1-train_fpr)))\n",
    "    threshold = sorted(distances)[selected_distance_idx-1]\n",
    "    threshold = threshold\n",
    "    #print (\"Threshold value: %f\" % threshold)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e159e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_test(model, dataset, X1):\n",
    "    #X1_pred = model.predict(X1)\n",
    "    X1_pred = m(model(X1))\n",
    "    vals_squeezed = []\n",
    "\n",
    "    if dataset == 'mnist':\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.detach().cpu(), 1)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        \n",
    "        #model.predict is tf based. need torch based softmax. \n",
    "        #vals_squeezed.append(model.predict(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.detach().cpu(), 2)\n",
    "        #print((\"outside func\",type(X1_seqeezed_filter_median)))\n",
    "        vals_squeezed.append(m(model(X1_seqeezed_filter_median.to(device))))\n",
    "\n",
    "    else:\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.detach().cpu(), 5)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.detach().cpu(), 2)\n",
    "        #vals_squeezed.append(model(torch.from_numpy(X1_seqeezed_filter_median).float().to(device)))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_filter_median).to(device))))\n",
    "        #X1_seqeezed_filter_local = non_local_means_color_py(X1.cpu().numpy(), 13, 3, 2)\n",
    "        #vals_squeezed.append(m(model((X1_seqeezed_filter_local).to(device))))\n",
    "\n",
    "    dist_array = []\n",
    "    for val_squeezed in vals_squeezed:\n",
    "        dist = np.sum(np.abs(X1_pred.cpu().detach().numpy() - val_squeezed.cpu().detach().numpy()), axis=tuple(range(len(X1_pred.shape))[1:]))\n",
    "        dist_array.append(dist)\n",
    "\n",
    "    dist_array = np.array(dist_array)\n",
    "    return np.max(dist_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6351b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset, X, threshold):\n",
    "    distances = get_distance_test(model, dataset, X)\n",
    "    Y_pred = distances > threshold\n",
    "    return Y_pred, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a14ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(model, dataset, X):\n",
    "    distances = get_distance_test(model, dataset, X)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aa3cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_fpr(true_labels, pred_labels):\n",
    "    TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1))\n",
    "    FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0))\n",
    "\n",
    "    AP = np.sum(true_labels)\n",
    "    AN = np.sum(1-true_labels)\n",
    "\n",
    "    tpr = TP/AP if AP>0 else np.nan\n",
    "    fpr = FP/AN if AN>0 else np.nan\n",
    "\n",
    "    return tpr, fpr, TP, AP, FP, AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bef22514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, x_test, threshold, dataset):\n",
    "    Y_all = np.concatenate([np.ones(len(x_test), dtype=bool)])\n",
    "    #print(Y_all)\n",
    "    Y_all_pred, Y_all_pred_score = test(model, dataset, x_test, threshold)\n",
    "    tpr, fpr, tp, ap, fp, an = get_tpr_fpr(Y_all, Y_all_pred)\n",
    "    return tpr\n",
    "                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994cd778",
   "metadata": {},
   "source": [
    "# MNIST thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92e67183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f2c8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for natural and adversarial LeNet Model \n",
    "class LeNet_normal(torch.nn.Module):\n",
    "    \"\"\"Network architecture from: https://github.com/ChawDoe/LeNet5-MNIST-PyTorch.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.conv_2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.fc_1 = torch.nn.Linear(256, 120)\n",
    "        self.relu_3 = torch.nn.ReLU()\n",
    "        self.fc_2 = torch.nn.Linear(120, 84)\n",
    "        self.relu_4 = torch.nn.ReLU()\n",
    "        self.fc_3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool_1(self.relu_1(self.conv_1(x)))\n",
    "        x = self.pool_2(self.relu_2(self.conv_2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.relu_3(self.fc_1(x))\n",
    "        x = self.relu_4(self.fc_2(x))\n",
    "        x = self.fc_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2245df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_model(path):\n",
    "    model = LeNet_normal()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "429bfe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet_normal(\n",
       "  (conv_1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu_1): ReLU()\n",
       "  (conv_2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu_2): ReLU()\n",
       "  (fc_1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (fc_2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (relu_4): ReLU()\n",
       "  (fc_3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"mnist_model.pth\"\n",
    "mnist_model = load_mnist_model(path)\n",
    "mnist_model.to(device)\n",
    "mnist_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00a39f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get dataset\n",
    "train_set = torchvision.datasets.MNIST(root='./sample_data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a7e8108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2163/987440447.py:11: DeprecationWarning: Please use `median_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  var = ndimage.filters.median_filter(x, size=(1,width,height,1), mode='reflect')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for 0.01 FPR is 0.5400584977487417.\n",
      "Threshold for 0.05 FPR is 0.5400584977487417.\n",
      "Threshold for 0.1 FPR is 0.059712059444638435.\n"
     ]
    }
   ],
   "source": [
    "FPR = [0.01,0.05,0.1]\n",
    "for fpr in FPR:\n",
    "    t=[]\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        threshold = train_fs(mnist_model, \"mnist\", x_batch, fpr)\n",
    "        t.append(threshold)\n",
    "        if step==100:\n",
    "            break\n",
    "    print(\"Threshold for {} FPR is {}.\".format(fpr, sum(t)/len(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b333233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "\n",
    "def make_fgsm_attack(x_batch, y_batch, eps, normal_model): \n",
    "    \n",
    "    images_pgd = fast_gradient_method(normal_model, x_batch, eps, np.inf)\n",
    "    _, y_pred_pgd = normal_model(images_pgd).max(1)\n",
    "    index = (y_pred_pgd != y_batch)\n",
    "    pgd_images = images_pgd[index]\n",
    "    y_pred_pgd = y_pred_pgd[index]\n",
    "    return pgd_images, y_pred_pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19e1932d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2163/987440447.py:11: DeprecationWarning: Please use `median_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  var = ndimage.filters.median_filter(x, size=(1,width,height,1), mode='reflect')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR is  1.6921674875925565\n"
     ]
    }
   ],
   "source": [
    "# testing test function\n",
    "threshold = 0.011\n",
    "t=[]\n",
    "for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "    images_adv,y_pred_adv = make_fgsm_attack(x_batch, y_batch, 0.15, mnist_model)\n",
    "    images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "    #tpr = evaluate_test(mnist_model, images_adv, threshold, \"mnist\")\n",
    "    d = compute_distance(mnist_model, \"mnist\", images_adv)\n",
    "    t.extend(d)\n",
    "    if step==50:\n",
    "        break\n",
    "#avg = sum(t)/len(t)\n",
    "print('TPR is ', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40a0936e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0037023888,\n",
       " 1.4547563,\n",
       " 1.9398155,\n",
       " 1.9642309,\n",
       " 1.9949434,\n",
       " 1.9999357,\n",
       " 1.8329766,\n",
       " 1.82579,\n",
       " 1.9863436,\n",
       " 1.6510091,\n",
       " 1.8830819,\n",
       " 1.7945919,\n",
       " 1.6853534,\n",
       " 1.999431,\n",
       " 1.4717724,\n",
       " 1.7163935,\n",
       " 1.7187643,\n",
       " 1.4445529,\n",
       " 0.31661597,\n",
       " 1.9820156,\n",
       " 0.69838613,\n",
       " 1.2439761,\n",
       " 1.8433343,\n",
       " 1.9856117,\n",
       " 1.9242642,\n",
       " 1.8001755,\n",
       " 1.607698,\n",
       " 0.8374935,\n",
       " 0.5282521,\n",
       " 1.9833698,\n",
       " 1.7635174,\n",
       " 0.7651484,\n",
       " 1.975861,\n",
       " 1.9880788,\n",
       " 1.5262078,\n",
       " 1.9976143,\n",
       " 1.9947714,\n",
       " 1.9979838,\n",
       " 1.9735583,\n",
       " 1.214601,\n",
       " 1.9197868,\n",
       " 1.9992412,\n",
       " 1.9748027,\n",
       " 1.4058942,\n",
       " 1.9893807,\n",
       " 1.7211668,\n",
       " 1.9999855,\n",
       " 1.9739358,\n",
       " 0.14934598,\n",
       " 1.9302452,\n",
       " 0.9445748,\n",
       " 1.3355427,\n",
       " 1.6497753,\n",
       " 1.9679126,\n",
       " 1.9794323,\n",
       " 1.8673459,\n",
       " 1.9780377,\n",
       " 1.950849,\n",
       " 1.9072189,\n",
       " 1.9990618,\n",
       " 0.32116923,\n",
       " 1.9619154,\n",
       " 1.9953034,\n",
       " 1.99959,\n",
       " 1.99879,\n",
       " 1.9403043,\n",
       " 1.9644465,\n",
       " 1.9987391,\n",
       " 1.8372264,\n",
       " 1.998923,\n",
       " 1.904904,\n",
       " 1.630156,\n",
       " 1.8219489,\n",
       " 1.9664894,\n",
       " 0.62454545,\n",
       " 1.9222841,\n",
       " 1.9922737,\n",
       " 1.9150343,\n",
       " 1.3534813,\n",
       " 1.8638101,\n",
       " 1.9197011,\n",
       " 1.9988408,\n",
       " 1.9413468,\n",
       " 1.9328399,\n",
       " 1.9760023,\n",
       " 0.9880485,\n",
       " 0.89448416,\n",
       " 1.4150612,\n",
       " 1.6071665,\n",
       " 1.8693596,\n",
       " 1.9930834,\n",
       " 1.9444128,\n",
       " 1.361666,\n",
       " 1.2520374,\n",
       " 1.9141833,\n",
       " 1.9705136,\n",
       " 1.7072233,\n",
       " 1.9221147,\n",
       " 1.8983241,\n",
       " 1.911586,\n",
       " 1.9999064,\n",
       " 1.9679509,\n",
       " 1.9670047,\n",
       " 1.8284781,\n",
       " 1.5223838,\n",
       " 1.9832355,\n",
       " 1.9770352,\n",
       " 1.983464,\n",
       " 1.9997449,\n",
       " 1.7368801,\n",
       " 1.6300646,\n",
       " 1.9917773,\n",
       " 1.9572346,\n",
       " 1.3425295,\n",
       " 0.937983,\n",
       " 1.9947597,\n",
       " 1.6299117,\n",
       " 1.8756225,\n",
       " 1.9923756,\n",
       " 1.9700521,\n",
       " 1.9802138,\n",
       " 1.6519004,\n",
       " 1.9996097,\n",
       " 1.960402,\n",
       " 1.4927847,\n",
       " 1.8665279,\n",
       " 1.9970224,\n",
       " 0.9810276,\n",
       " 1.5573827,\n",
       " 1.9608665,\n",
       " 1.8653073,\n",
       " 1.9976451,\n",
       " 1.872963,\n",
       " 1.9999999,\n",
       " 1.6544021,\n",
       " 1.9745885,\n",
       " 1.3990355,\n",
       " 1.5146804,\n",
       " 1.6027573,\n",
       " 1.4049352,\n",
       " 1.9543613,\n",
       " 1.9336364,\n",
       " 1.99997,\n",
       " 1.4286771,\n",
       " 1.9998507,\n",
       " 1.9465768,\n",
       " 1.9988333,\n",
       " 0.5241052,\n",
       " 1.5492088,\n",
       " 1.8934003,\n",
       " 1.9587164,\n",
       " 1.886533,\n",
       " 1.4138263,\n",
       " 1.9746782,\n",
       " 1.3099421,\n",
       " 1.9991157,\n",
       " 1.9596577,\n",
       " 1.8605142,\n",
       " 1.9646126,\n",
       " 1.9602911,\n",
       " 0.73842144,\n",
       " 1.9999945,\n",
       " 1.4775043,\n",
       " 0.0008283792,\n",
       " 1.9988787,\n",
       " 1.9900584,\n",
       " 1.9803599,\n",
       " 1.8786677,\n",
       " 1.992775,\n",
       " 1.813552,\n",
       " 1.8208352,\n",
       " 1.9769824,\n",
       " 1.9958136,\n",
       " 1.9984303,\n",
       " 1.8005033,\n",
       " 1.9072659,\n",
       " 1.9706264,\n",
       " 1.9996411,\n",
       " 1.9589038,\n",
       " 1.2001433,\n",
       " 0.7517915,\n",
       " 0.47086558,\n",
       " 1.9894947,\n",
       " 1.9999999,\n",
       " 1.860864,\n",
       " 1.9937911,\n",
       " 1.9714059,\n",
       " 1.9793905,\n",
       " 1.9015162,\n",
       " 1.7460692,\n",
       " 1.9579688,\n",
       " 1.1486281,\n",
       " 1.8835844,\n",
       " 0.2796856,\n",
       " 1.461201,\n",
       " 1.9997334,\n",
       " 1.9985865,\n",
       " 1.6545305,\n",
       " 1.9178772,\n",
       " 1.962986,\n",
       " 1.9999816,\n",
       " 1.9434723,\n",
       " 1.9882841,\n",
       " 1.6794751,\n",
       " 1.9989169,\n",
       " 0.6321993,\n",
       " 1.3447618,\n",
       " 0.06397147,\n",
       " 1.9993107,\n",
       " 0.030859303,\n",
       " 0.039838575,\n",
       " 1.8731809,\n",
       " 1.8121368,\n",
       " 1.8524213,\n",
       " 1.9841648,\n",
       " 1.9999998,\n",
       " 1.599415]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "428ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame([d], index=[\"distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffd9c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d2c38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from rev2.cifar10.model_utils import resnet50, CIFAR10_RESNET50_CKPT_PATH\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, out_keys=None):\n",
    "        out = {}\n",
    "        x = self.conv1(x)\n",
    "        out[\"c1\"] = x\n",
    "        x = self.bn1(x)\n",
    "        out[\"bn1\"] = x\n",
    "        x = F.relu(x)\n",
    "        out[\"r1\"] = x\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        out[\"l1\"] = x\n",
    "        x = self.layer2(x)\n",
    "        out[\"l2\"] = x\n",
    "        x = self.layer3(x)\n",
    "        out[\"l3\"] = x\n",
    "        x = self.layer4(x)\n",
    "        out[\"l4\"] = x\n",
    "\n",
    "        x = F.avg_pool2d(x, 4)\n",
    "        out[\"gvp\"] = x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        out[\"fc\"] = x\n",
    "\n",
    "        if out_keys is None:\n",
    "            return x\n",
    "        res = {}\n",
    "        for key in out_keys:\n",
    "            res[key] = out[key]\n",
    "        return res\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,8,36,3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1,3,32,32))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190aa85b",
   "metadata": {},
   "source": [
    "# CIFAR thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a2d5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar_model(path):\n",
    "    model = resnet50()\n",
    "    ckpt_dict = torch.load(path, lambda storage, loc: storage)\n",
    "    model.load_state_dict(ckpt_dict)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53d20de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"cifar.ckpt\"\n",
    "normal_model = load_cifar_model(path)\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adf35bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                           download=True, transform=torchvision.transforms.ToTensor())\n",
    "train_loader = DataLoader(trainset, shuffle=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdc19560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2163/987440447.py:11: DeprecationWarning: Please use `median_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  var = ndimage.filters.median_filter(x, size=(1,width,height,1), mode='reflect')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for 0.01 FPR is 1.155263510995889.\n",
      "Threshold for 0.05 FPR is 1.143712807310474.\n",
      "Threshold for 0.1 FPR is 0.3224780978692945.\n"
     ]
    }
   ],
   "source": [
    "FPR = [0.01,0.05,0.1]\n",
    "for fpr in FPR:\n",
    "    t=[]\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        threshold = train_fs(normal_model, \"cifar\", x_batch, fpr)\n",
    "        t.append(threshold)\n",
    "        if step==100:\n",
    "            break\n",
    "    print(\"Threshold for {} FPR is {}.\".format(fpr, sum(t)/len(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029351b3",
   "metadata": {},
   "source": [
    "# ImageNet threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e8dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45158e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_model():\n",
    "    model=torchvision.models.mobilenet_v3_small(weights=True).to(device)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f62aff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Conv2dNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_imagenet_model()\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c21ae28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation transforms\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13f2e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset\n",
    "images = '/home/db1702/Downloads/imagenet-mini/val/'\n",
    "train = torchvision.datasets.ImageFolder(images, transform=valid_transform)\n",
    "train_loader = DataLoader(train, shuffle=True, batch_size = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e54fb86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79836/987440447.py:11: DeprecationWarning: Please use `median_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  var = ndimage.filters.median_filter(x, size=(1,width,height,1), mode='reflect')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for 0.01 FPR is 1.3641814877144733.\n",
      "Threshold for 0.05 FPR is 1.3909228329931325.\n",
      "Threshold for 0.1 FPR is 1.2991581189988264.\n"
     ]
    }
   ],
   "source": [
    "FPR = [0.01,0.05,0.1]\n",
    "for fpr in FPR:\n",
    "    t=[]\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        threshold = train_fs(normal_model, \"cifar\", x_batch, fpr)\n",
    "        t.append(threshold)\n",
    "        if step==200:\n",
    "            break\n",
    "    print(\"Threshold for {} FPR is {}.\".format(fpr, sum(t)/len(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d072ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
