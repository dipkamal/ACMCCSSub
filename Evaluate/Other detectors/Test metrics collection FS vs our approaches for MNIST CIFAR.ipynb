{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91223851",
   "metadata": {},
   "source": [
    "From previous experiments, we have following thresholds for Feature Squeezing methods: \n",
    "\n",
    "For 1% FPR:\n",
    "\n",
    "- CIFAR: 1.15526\n",
    "- MNIST: 0.54005\n",
    "- SVHN: 0.17120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a986df",
   "metadata": {},
   "source": [
    "# Feature squeezing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cba60923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "99c251ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_dist = lambda x1,x2: np.sum(np.abs(x1 - x2), axis=tuple(range(len(x1.shape))[1:]))\n",
    "l2_dist = lambda x1,x2: np.sum((x1-x2)**2, axis=tuple(range(len(x1.shape))[1:]))**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0ff041bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: KL-divergence is not symentric.\n",
    "# Designed for probability distribution (e.g. softmax output).\n",
    "def kl(x1, x2):\n",
    "    assert x1.shape == x2.shape\n",
    "    # x1_2d, x2_2d = reshape_2d(x1), reshape_2d(x2)\n",
    "\n",
    "    # Transpose to [?, #num_examples]\n",
    "    x1_2d_t = x1.transpose()\n",
    "    x2_2d_t = x2.transpose()\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    e = entropy(x1_2d_t, x2_2d_t)\n",
    "    e[np.where(e==np.inf)] = 2\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "625ceb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_precision_py(x, npp):\n",
    "    \"\"\"\n",
    "    Reduce the precision of image, the numpy version.\n",
    "    :param x: a float tensor, which has been scaled to [0, 1].\n",
    "    :param npp: number of possible values per pixel. E.g. it's 256 for 8-bit gray-scale image, and 2 for binarized image.\n",
    "    :return: a tensor representing image(s) with lower precision.\n",
    "    \"\"\"\n",
    "    # Note: 0 is a possible value too.\n",
    "    npp_int = npp - 1\n",
    "    x_int = np.rint(x * npp_int)\n",
    "    x_float = x_int / npp_int\n",
    "    return x_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8b28b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter_py(x, width, height=-1):\n",
    "    \"\"\"\n",
    "    Median smoothing by Scipy.\n",
    "    :param x: a tensor of image(s)\n",
    "    :param width: the width of the sliding window (number of pixels)\n",
    "    :param height: the height of the window. The same as width by default.\n",
    "    :return: a modified tensor with the same shape as x.\n",
    "    \"\"\"\n",
    "    if height == -1:\n",
    "        height = width\n",
    "    var = ndimage.filters.median_filter(x, size=(1,width,height,1), mode='reflect')\n",
    "    #print(\"inside median filter\")\n",
    "    #print(type(var))\n",
    "    return torch.from_numpy(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8a22f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeezers implemented in OpenCV\n",
    "# OpenCV expects uint8 as image data type.\n",
    "def opencv_wrapper(imgs, opencv_func, argv):\n",
    "    ret_imgs = []\n",
    "    imgs_copy = imgs\n",
    "\n",
    "    if imgs.shape[3] == 1:\n",
    "        imgs_copy = np.squeeze(imgs)\n",
    "\n",
    "    for img in imgs_copy:\n",
    "        img_uint8 = np.clip(np.rint(img * 255), 0, 255).astype(np.uint8)\n",
    "        ret_img = opencv_func(*[img_uint8]+argv)\n",
    "        if type(ret_img) == tuple:\n",
    "            ret_img = ret_img[1]\n",
    "        ret_img = ret_img.astype(np.float32) / 255.\n",
    "        ret_imgs.append(ret_img)\n",
    "    ret_imgs = np.stack(ret_imgs)\n",
    "\n",
    "    if imgs.shape[3] == 1:\n",
    "        ret_imgs = np.expand_dims(ret_imgs, axis=3)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "47924942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_depth_py(x, bits):\n",
    "    precisions = 2**bits\n",
    "    return reduce_precision_py(x, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1f01cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_local_means_color_py(imgs, search_window, block_size, photo_render):\n",
    "    import cv2\n",
    "    ret_imgs = opencv_wrapper(imgs, cv2.fastNlMeansDenoisingColored, [None,photo_render,photo_render,block_size,search_window])\n",
    "    return ret_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c1285355",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "47d17c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(model, dataset, X1):\n",
    "    #X1_pred = model.predict(X1)\n",
    "    X1_pred = m(model(X1))\n",
    "    vals_squeezed = []\n",
    "\n",
    "    if dataset == 'mnist':\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.cpu(), 1)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        \n",
    "        #model.predict is tf based. need torch based softmax. \n",
    "        #vals_squeezed.append(model.predict(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.cpu(), 2)\n",
    "        #print((\"outside func\",type(X1_seqeezed_filter_median)))\n",
    "        vals_squeezed.append(m(model(X1_seqeezed_filter_median.to(device))))\n",
    "\n",
    "    else:\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.cpu(), 5)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.cpu(), 2)\n",
    "        #vals_squeezed.append(model(torch.from_numpy(X1_seqeezed_filter_median).float().to(device)))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_filter_median).to(device))))\n",
    "        #X1_seqeezed_filter_local = non_local_means_color_py(X1.cpu().numpy(), 13, 3, 2)\n",
    "        #vals_squeezed.append(m(model((X1_seqeezed_filter_local).to(device))))\n",
    "\n",
    "    dist_array = []\n",
    "    for val_squeezed in vals_squeezed:\n",
    "        dist = np.sum(np.abs(X1_pred.cpu().detach().numpy() - val_squeezed.cpu().detach().numpy()), axis=tuple(range(len(X1_pred.shape))[1:]))\n",
    "        dist_array.append(dist)\n",
    "\n",
    "    dist_array = np.array(dist_array)\n",
    "    return np.max(dist_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "425dfc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fs(model, dataset, X1, train_fpr):\n",
    "    distances = get_distance(model, dataset, X1)\n",
    "    selected_distance_idx = int(np.ceil(len(X1) * (1-train_fpr)))\n",
    "    threshold = sorted(distances)[selected_distance_idx-1]\n",
    "    threshold = threshold\n",
    "    #print (\"Threshold value: %f\" % threshold)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f2a1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_test(model, dataset, X1):\n",
    "    #X1_pred = model.predict(X1)\n",
    "    X1_pred = m(model(X1))\n",
    "    vals_squeezed = []\n",
    "\n",
    "    if dataset == 'mnist':\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.detach().cpu(), 1)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        \n",
    "        #model.predict is tf based. need torch based softmax. \n",
    "        #vals_squeezed.append(model.predict(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.detach().cpu(), 2)\n",
    "        #print((\"outside func\",type(X1_seqeezed_filter_median)))\n",
    "        vals_squeezed.append(m(model(X1_seqeezed_filter_median.to(device))))\n",
    "\n",
    "    else:\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.detach().cpu(), 5)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.detach().cpu(), 2)\n",
    "        #vals_squeezed.append(model(torch.from_numpy(X1_seqeezed_filter_median).float().to(device)))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_filter_median).to(device))))\n",
    "        #X1_seqeezed_filter_local = non_local_means_color_py(X1.cpu().numpy(), 13, 3, 2)\n",
    "        #vals_squeezed.append(m(model((X1_seqeezed_filter_local).to(device))))\n",
    "\n",
    "    dist_array = []\n",
    "    for val_squeezed in vals_squeezed:\n",
    "        dist = np.sum(np.abs(X1_pred.cpu().detach().numpy() - val_squeezed.cpu().detach().numpy()), axis=tuple(range(len(X1_pred.shape))[1:]))\n",
    "        dist_array.append(dist)\n",
    "\n",
    "    dist_array = np.array(dist_array)\n",
    "    return np.max(dist_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e6eb31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_test(model, dataset, X):\n",
    "    distances = get_distance_test(model, dataset, X)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13177281",
   "metadata": {},
   "source": [
    "# Functions for proposed methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b25c5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent,\n",
    ")\n",
    "import gc\n",
    "from captum.attr import *\n",
    "import quantus\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torchvision.transforms as transforms\n",
    "from quantus.functions.perturb_func import baseline_replacement_by_indices\n",
    "from art.attacks.evasion import CarliniLInfMethod\n",
    "import torch.optim as optim\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import BasicIterativeMethod\n",
    "from art.attacks.evasion import SaliencyMapMethod\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "af987b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7aeb04",
   "metadata": {},
   "source": [
    "## Approach 1: Input squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bff49a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Sequence, Tuple, Union, List\n",
    "\n",
    "def infer_attribution_axes(a_batch: np.ndarray, x_batch: np.ndarray)-> Sequence[int]:\n",
    "    \"\"\"\n",
    "    Reference: quantus library\n",
    "    Infers the axes in x_batch that are covered by a_batch.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_batch: np.ndarray\n",
    "        A np.ndarray which contains the input data that are explained.\n",
    "    a_batch: np.ndarray\n",
    "        An array which contains pre-computed attributions i.e., explanations.\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The axes inferred.\n",
    "    \"\"\"\n",
    "    # TODO: Adapt for batched processing.\n",
    "\n",
    "    if a_batch.shape[0] != x_batch.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"a_batch and x_batch must have same number of batches ({a_batch.shape[0]} != {x_batch.shape[0]})\"\n",
    "        )\n",
    "\n",
    "    if a_batch.ndim > x_batch.ndim:\n",
    "        raise ValueError(\n",
    "            \"Attributions need to have <= dimensions than inputs, but {} > {}\".format(\n",
    "                a_batch.ndim, x_batch.ndim\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # TODO: We currently assume here that the batch axis is not carried into the perturbation functions.\n",
    "    a_shape = [s for s in np.shape(a_batch)[1:] if s != 1]\n",
    "    x_shape = [s for s in np.shape(x_batch)[1:]]\n",
    "\n",
    "    if a_shape == x_shape:\n",
    "        return np.arange(0, len(x_shape))\n",
    "\n",
    "    # One attribution value per sample\n",
    "    if len(a_shape) == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    x_subshapes = [\n",
    "        [x_shape[i] for i in range(start, start + len(a_shape))]\n",
    "        for start in range(0, len(x_shape) - len(a_shape) + 1)\n",
    "    ]\n",
    "    if x_subshapes.count(a_shape) < 1:\n",
    "\n",
    "        # Check that attribution dimensions are (consecutive) subdimensions of inputs\n",
    "        raise ValueError(\n",
    "            \"Attribution dimensions are not (consecutive) subdimensions of inputs:  \"\n",
    "            \"inputs were of shape {} and attributions of shape {}\".format(\n",
    "                x_batch.shape, a_batch.shape\n",
    "            )\n",
    "        )\n",
    "    elif x_subshapes.count(a_shape) > 1:\n",
    "\n",
    "        # Check that attribution dimensions are (unique) subdimensions of inputs.\n",
    "        # Consider potentially expanded dims in attributions.\n",
    "\n",
    "        if a_batch.ndim == x_batch.ndim and len(a_shape) < a_batch.ndim:\n",
    "            a_subshapes = [\n",
    "                [np.shape(a_batch)[1:][i] for i in range(start, start + len(a_shape))]\n",
    "                for start in range(0, len(np.shape(a_batch)[1:]) - len(a_shape) + 1)\n",
    "            ]\n",
    "            if a_subshapes.count(a_shape) == 1:\n",
    "\n",
    "                # Inferring channel shape.\n",
    "                for dim in range(len(np.shape(a_batch)[1:]) + 1):\n",
    "                    if a_shape == np.shape(a_batch)[1:][dim:]:\n",
    "                        return np.arange(dim, len(np.shape(a_batch)[1:]))\n",
    "                    if a_shape == np.shape(a_batch)[1:][:dim]:\n",
    "                        return np.arange(0, dim)\n",
    "\n",
    "            raise ValueError(\n",
    "                \"Attribution axes could not be inferred for inputs of \"\n",
    "                \"shape {} and attributions of shape {}\".format(\n",
    "                    x_batch.shape, a_batch.shape\n",
    "                )\n",
    "            )\n",
    "\n",
    "        raise ValueError(\n",
    "            \"Attribution dimensions are not unique subdimensions of inputs:  \"\n",
    "            \"inputs were of shape {} and attributions of shape {}.\"\n",
    "            \"Please expand attribution dimensions for a unique solution\".format(\n",
    "                x_batch.shape, a_batch.shape\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        # Infer attribution axes.\n",
    "        for dim in range(len(x_shape) + 1):\n",
    "            if a_shape == x_shape[dim:]:\n",
    "                return np.arange(dim, len(x_shape))\n",
    "            if a_shape == x_shape[:dim]:\n",
    "                return np.arange(0, dim)\n",
    "\n",
    "    raise ValueError(\n",
    "        \"Attribution axes could not be inferred for inputs of \"\n",
    "        \"shape {} and attributions of shape {}\".format(x_batch.shape, a_batch.shape)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5468a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_x_based_on_attribution(x_batch, a_batch_benign, d_type, top_k = 100):\n",
    "    #get attribution axes\n",
    "    a_axes = infer_attribution_axes(a_batch_benign, x_batch)\n",
    "    perturbed_arr = []\n",
    "\n",
    "    #modify each sample one-by-one\n",
    "    for x,a in zip(x_batch, a_batch_benign):\n",
    "        #flatten the attribution \n",
    "        a = a.flatten()\n",
    "        #get indices of sorted attributions (ascending)\n",
    "        a_ind = np.argsort(a)\n",
    "        #get indices of top_k \n",
    "        a_ix = a_ind[-top_k:]\n",
    "        if d_type==\"adv\":\n",
    "            x = x.cpu()\n",
    "            x_perturbed = baseline_replacement_by_indices(arr = x.detach().numpy(), indices = a_ix, indexed_axes = a_axes, perturb_baseline = \"black\")\n",
    "            if (x.detach().numpy().flatten() != x_perturbed.flatten()).any():\n",
    "                perturbed_arr.append(torch.from_numpy(x_perturbed))\n",
    "    \n",
    "        else:\n",
    "            x_perturbed = baseline_replacement_by_indices(arr = x.cpu().numpy(), indices = a_ix, indexed_axes = a_axes, perturb_baseline = \"black\")\n",
    "            if (x.cpu().numpy().flatten() != x_perturbed.flatten()).any():\n",
    "                perturbed_arr.append(torch.from_numpy(x_perturbed))\n",
    "    \n",
    "    new_batch = torch.stack(perturbed_arr)\n",
    "    return new_batch.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7aec1",
   "metadata": {},
   "source": [
    "## Approach 2: Adding noise and computing robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "79f626cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(x_batch, y_batch, spread):\n",
    "    new_x_batch = []\n",
    "    for x in x_batch:\n",
    "        x = x.data.cpu().numpy()\n",
    "        stdev = spread * (np.max(x)-np.min(x))\n",
    "        noise = np.random.normal(0, stdev, x.shape).astype(np.float32)\n",
    "        x_plus_noise = x + noise\n",
    "        x_plus_noise = np.clip(x_plus_noise, 0, 1)\n",
    "        x_plus_noise = torch.from_numpy(x_plus_noise).cpu()\n",
    "        new_x_batch.append(x_plus_noise)\n",
    "    new_batch = torch.stack(new_x_batch).to(device)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8236f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define uniform noise function\n",
    "def add_uniform_noise(image):\n",
    "    # Generate uniform noise with mean 0 and standard deviation 25\n",
    "    noise = np.random.uniform(low=-0.5, high=0.5, size=image.shape).astype(np.float32)\n",
    "    noisy_image = np.clip(image + noise, 0, 1).astype(np.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "def uniform_noise(x_batch, y_batch): \n",
    "    # Convert batch of images to numpy array\n",
    "    images = x_batch.detach().cpu().numpy().transpose(0, 2, 3, 1) * 1.0\n",
    "    # Add Poisson noise to each image in the batch\n",
    "    noisy_images = [add_uniform_noise(image) for image in images]\n",
    "    # Convert noisy images back to Tensor format\n",
    "    noisy_inputs = torch.from_numpy(np.array(noisy_images).transpose(0, 3, 1, 2) / 1.0).float()\n",
    "    return noisy_inputs.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b2cc17",
   "metadata": {},
   "source": [
    "# Approach 3: Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f6564f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_abs_dev(attr): \n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        avg = np.mean(a)\n",
    "        deviation = a - avg \n",
    "        absolute_deviation = np.abs(deviation)\n",
    "        result = np.mean(absolute_deviation)\n",
    "        scores.append(result)\n",
    "    return scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1a8cad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_median_abs_dev(attr): \n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        med = np.median(a)\n",
    "        deviation = a - med \n",
    "        abs_deviation = np.abs(deviation)\n",
    "        result = np.median(abs_deviation)\n",
    "        scores.append(result)\n",
    "    return scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c73bcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iqr(attr):\n",
    "    #inter-quartile range\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        score_qt = score_75 - score_25\n",
    "        scores.append(score_qt)\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f885f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative measure of dispersion\n",
    "def compute_coef_var(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        m = np.mean(a)\n",
    "        st = np.std(attr[i])\n",
    "        sc = m/st\n",
    "        scores.append(sc)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ed36cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative measure of dispersion\n",
    "\n",
    "## Coefficient of quartile dev\n",
    "\n",
    "def compute_coef_iqr(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        score_qt = (score_75 - score_25)/(score_75 + score_25)\n",
    "        scores.append(score_qt)\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d74403",
   "metadata": {},
   "source": [
    "# Attack functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "25e3f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_attack(x_batch, y_batch, eps, normal_model): \n",
    "    \n",
    "    alpha = eps/10\n",
    "    steps = int(alpha*eps)\n",
    "    images_pgd = projected_gradient_descent(normal_model, x_batch, eps, alpha, steps, np.inf)\n",
    "    _, y_pred_pgd = normal_model(images_pgd).max(1)\n",
    "    index = (y_pred_pgd != y_batch)\n",
    "    pgd_images = images_pgd[index]\n",
    "    y_pred_pgd = y_pred_pgd[index]\n",
    "    return pgd_images, y_pred_pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "506b3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fgsm_attack(x_batch, y_batch, eps, normal_model): \n",
    "    \n",
    "    images_pgd = fast_gradient_method(normal_model, x_batch, eps, np.inf)\n",
    "    _, y_pred_pgd = normal_model(images_pgd).max(1)\n",
    "    index = (y_pred_pgd != y_batch)\n",
    "    pgd_images = images_pgd[index]\n",
    "    y_pred_pgd = y_pred_pgd[index]\n",
    "    return pgd_images, y_pred_pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cb3dbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cw_attack(attack, x_batch, y_batch, normal_model):\n",
    "    #convert tensor to numpy\n",
    "    #x_batch=x_batch.to('cuda')\n",
    "    #_, y_pred_pgd = normal_model(x_batch).max(1)\n",
    "    x_batch = x_batch.cpu().numpy()\n",
    "    x_test_adv = attack.generate(x=x_batch)\n",
    "    #convert the nd array back to tensor\n",
    "    x_test = torch.from_numpy(x_test_adv).to('cuda')\n",
    "    _, y_test = normal_model(x_test).max(1)\n",
    "    index = (y_test != y_batch)\n",
    "    adv_images = x_test[index]\n",
    "    y_pred_adv = y_test[index]\n",
    "    return adv_images, y_pred_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "389ca668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bim_attack(attack, x_batch, y_batch, normal_model):\n",
    "    #convert tensor to numpy\n",
    "    #x_batch=x_batch.to('cuda')\n",
    "    #_, y_pred_pgd = normal_model(x_batch).max(1)\n",
    "    x_batch = x_batch.cpu().numpy()\n",
    "    x_test_adv = attack.generate(x=x_batch)\n",
    "    #convert the nd array back to tensor\n",
    "    x_test = torch.from_numpy(x_test_adv).to('cuda')\n",
    "    _, y_test = normal_model(x_test).max(1)\n",
    "    index = (y_test != y_batch)\n",
    "    adv_images = x_test[index]\n",
    "    y_pred_adv = y_test[index]\n",
    "    return adv_images, y_pred_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79217f8f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "10529808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for natural and adversarial LeNet Model \n",
    "class LeNet_normal(torch.nn.Module):\n",
    "    \"\"\"Network architecture from: https://github.com/ChawDoe/LeNet5-MNIST-PyTorch.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.conv_2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.fc_1 = torch.nn.Linear(256, 120)\n",
    "        self.relu_3 = torch.nn.ReLU()\n",
    "        self.fc_2 = torch.nn.Linear(120, 84)\n",
    "        self.relu_4 = torch.nn.ReLU()\n",
    "        self.fc_3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool_1(self.relu_1(self.conv_1(x)))\n",
    "        x = self.pool_2(self.relu_2(self.conv_2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.relu_3(self.fc_1(x))\n",
    "        x = self.relu_4(self.fc_2(x))\n",
    "        x = self.fc_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7c84ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from rev2.cifar10.model_utils import resnet50, CIFAR10_RESNET50_CKPT_PATH\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, out_keys=None):\n",
    "        out = {}\n",
    "        x = self.conv1(x)\n",
    "        out[\"c1\"] = x\n",
    "        x = self.bn1(x)\n",
    "        out[\"bn1\"] = x\n",
    "        x = F.relu(x)\n",
    "        out[\"r1\"] = x\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        out[\"l1\"] = x\n",
    "        x = self.layer2(x)\n",
    "        out[\"l2\"] = x\n",
    "        x = self.layer3(x)\n",
    "        out[\"l3\"] = x\n",
    "        x = self.layer4(x)\n",
    "        out[\"l4\"] = x\n",
    "\n",
    "        x = F.avg_pool2d(x, 4)\n",
    "        out[\"gvp\"] = x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        out[\"fc\"] = x\n",
    "\n",
    "        if out_keys is None:\n",
    "            return x\n",
    "        res = {}\n",
    "        for key in out_keys:\n",
    "            res[key] = out[key]\n",
    "        return res\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,8,36,3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1,3,32,32))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cde823",
   "metadata": {},
   "source": [
    "## For each of the dataset, save the metrics computed for the proposed approaches or using feature squeeze method to a csv. Then after all the metrics are computed, use thresholds we have to compute TPR. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b577413f",
   "metadata": {},
   "source": [
    "# CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "174a594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pgd_cifar(test_loader, normal_model, eps): \n",
    "    \n",
    "    print(\"Computing metrics for {} for PGD\".format(eps))\n",
    "    medianAbs = []\n",
    "    meanAbs = []\n",
    "    iqr= []\n",
    "    coef_var=[]\n",
    "    coef_iqr = []\n",
    "\n",
    "    logit1 = []\n",
    "    logit2 = []\n",
    "    logit3 = []\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    fs =[]\n",
    "    \n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        if len(images_adv) == 0:\n",
    "            continue\n",
    "            \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"cifar\", images_adv)\n",
    "        fs.extend(d)\n",
    "    \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(images_adv)\n",
    "        a_batch = (Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        meanAbs += compute_mean_abs_dev(a_batch)\n",
    "        medianAbs += compute_median_abs_dev(a_batch)\n",
    "        iqr += compute_iqr(a_batch)\n",
    "        coef_var += compute_coef_var(a_batch)\n",
    "        coef_iqr += compute_coef_iqr(a_batch)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 400, d_type=\"adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 450, d_type=\"adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 500, d_type=\"adv\")\n",
    "        \n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit1.extend(diff1.detach().cpu().numpy())\n",
    "        logit2.extend(diff2.detach().cpu().numpy())\n",
    "        logit3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.10)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if len(iqr) > 500:\n",
    "            \n",
    "            df = pd.DataFrame([\n",
    "            medianAbs,\n",
    "            meanAbs, \n",
    "            iqr, \n",
    "            coef_var, \n",
    "            coef_iqr, \n",
    "            logit1,\n",
    "            logit2,\n",
    "            logit3,\n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Median Absolute Dev\", \n",
    "            \"Mean Absolute Dev\", \n",
    "            \"IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze 400\",\n",
    "            \"Input squeeze 450\",\n",
    "            \"Input squeeze 500\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "                \"Feature squeezer\",\n",
    "        ])\n",
    "            \n",
    "            path = \"eps_\"+str(eps)+\"_CIFAR_PGD.csv\"\n",
    "            df.to_csv(path)\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3199d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fgsm_cifar(test_loader, normal_model, eps): \n",
    "    \n",
    "    print(\"Computing metrics for {} for PGD\".format(eps))\n",
    "    medianAbs = []\n",
    "    meanAbs = []\n",
    "    iqr= []\n",
    "    coef_var=[]\n",
    "    coef_iqr = []\n",
    "\n",
    "    logit1 = []\n",
    "    logit2 = []\n",
    "    logit3 = []\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    fs=[]\n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_fgsm_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        if len(images_adv) == 0:\n",
    "            continue\n",
    "            \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"cifar\", images_adv)\n",
    "        fs.extend(d)\n",
    "    \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(images_adv)\n",
    "        a_batch = (Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        meanAbs += compute_mean_abs_dev(a_batch)\n",
    "        medianAbs += compute_median_abs_dev(a_batch)\n",
    "        iqr += compute_iqr(a_batch)\n",
    "        coef_var += compute_coef_var(a_batch)\n",
    "        coef_iqr += compute_coef_iqr(a_batch)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 400, d_type=\"adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 450, d_type=\"adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 500, d_type=\"adv\")\n",
    "        \n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit1.extend(diff1.detach().cpu().numpy())\n",
    "        logit2.extend(diff2.detach().cpu().numpy())\n",
    "        logit3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.10)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if len(iqr) > 500:\n",
    "            \n",
    "            df = pd.DataFrame([\n",
    "            medianAbs,\n",
    "            meanAbs, \n",
    "            iqr, \n",
    "            coef_var, \n",
    "            coef_iqr, \n",
    "            logit1,\n",
    "            logit2,\n",
    "            logit3,\n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Median Absolute Dev\", \n",
    "            \"Mean Absolute Dev\", \n",
    "            \"IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze 400\",\n",
    "            \"Input squeeze 450\",\n",
    "            \"Input squeeze 500\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "                \"Feature squeezer\",\n",
    "        ])\n",
    "            \n",
    "            path = \"eps_\"+str(eps)+\"_CIFAR_FGSM.csv\"\n",
    "            df.to_csv(path)\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2cdac985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_bim_cifar(train_loader_cifar, normal_model, eps): \n",
    "    \n",
    "    print(\"Computing metrics for {} for BIM\".format(eps))\n",
    "    \n",
    "    medianAbs = []\n",
    "    meanAbs = []\n",
    "    iqr= []\n",
    "    coef_var=[]\n",
    "    coef_iqr = []\n",
    "\n",
    "    logit1 = []\n",
    "    logit2 = []\n",
    "    logit3 = []\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    fs = []\n",
    "    \n",
    "    #set attack parameters for BIM\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(normal_model.parameters(), lr=0.01)\n",
    "    classifier = PyTorchClassifier(\n",
    "    model=normal_model, clip_values=(0, 1), loss=criterion, optimizer=optimizer, input_shape=(3, 32, 32),\n",
    "        nb_classes=10,\n",
    ")\n",
    "    attack = BasicIterativeMethod(classifier, eps = eps, max_iter=int(eps*256*1.25))\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader_cifar):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_bim_attack(attack, x_batch, y_batch, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        if len(images_adv) == 0:\n",
    "            continue\n",
    "    \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"cifar\", images_adv)\n",
    "        fs.extend(d)\n",
    "        \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(images_adv)\n",
    "        a_batch = (Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        meanAbs += compute_mean_abs_dev(a_batch)\n",
    "        medianAbs += compute_median_abs_dev(a_batch)\n",
    "        iqr += compute_iqr(a_batch)\n",
    "        coef_var += compute_coef_var(a_batch)\n",
    "        coef_iqr += compute_coef_iqr(a_batch)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 400, d_type=\"adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 450, d_type=\"adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 500, d_type=\"adv\")\n",
    "        \n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit1.extend(diff1.detach().cpu().numpy())\n",
    "        logit2.extend(diff2.detach().cpu().numpy())\n",
    "        logit3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.10)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if len(iqr) > 500:\n",
    "            \n",
    "            df = pd.DataFrame([\n",
    "            medianAbs,\n",
    "            meanAbs, \n",
    "            iqr, \n",
    "            coef_var, \n",
    "            coef_iqr, \n",
    "            logit1,\n",
    "            logit2,\n",
    "            logit3,\n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Median Absolute Dev\", \n",
    "            \"Mean Absolute Dev\", \n",
    "            \"IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze 400\",\n",
    "            \"Input squeeze 450\",\n",
    "            \"Input squeeze 500\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "                \"Feature squeezer\"\n",
    "        ])\n",
    "            \n",
    "            path = \"eps_\"+str(eps)+\"_CIFAR_BIM.csv\"\n",
    "            df.to_csv(path)\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3cb547db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_cw_cifar(test_loader, normal_model, conf): \n",
    "    \n",
    "    print(\"Computing metrics for {} for CW\".format(conf))\n",
    "    medianAbs = []\n",
    "    meanAbs = []\n",
    "    iqr= []\n",
    "    coef_var=[]\n",
    "    coef_iqr = []\n",
    "\n",
    "    logit1 = []\n",
    "    logit2 = []\n",
    "    logit3 = []\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    fs = []\n",
    "    \n",
    "    #set attack parameters for BIM\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(normal_model.parameters(), lr=0.01)\n",
    "    classifier = PyTorchClassifier(\n",
    "    model=normal_model, clip_values=(0, 1), loss=criterion, optimizer=optimizer, input_shape=(3, 32, 32),\n",
    "        nb_classes=10,\n",
    ")\n",
    "    attack = CarliniLInfMethod(classifier, confidence = conf)\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_cw_attack(attack, x_batch, y_batch, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        if len(images_adv) == 0:\n",
    "            continue\n",
    "    \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"cifar\", images_adv)\n",
    "        fs.extend(d)\n",
    "        \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(images_adv)\n",
    "        a_batch = (Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        meanAbs += compute_mean_abs_dev(a_batch)\n",
    "        medianAbs += compute_median_abs_dev(a_batch)\n",
    "        iqr += compute_iqr(a_batch)\n",
    "        coef_var += compute_coef_var(a_batch)\n",
    "        coef_iqr += compute_coef_iqr(a_batch)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 400, d_type=\"adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 450, d_type=\"adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 500, d_type=\"adv\")\n",
    "        \n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit1.extend(diff1.detach().cpu().numpy())\n",
    "        logit2.extend(diff2.detach().cpu().numpy())\n",
    "        logit3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.10)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if len(iqr) > 500:\n",
    "            \n",
    "            df = pd.DataFrame([\n",
    "            medianAbs,\n",
    "            meanAbs, \n",
    "            iqr, \n",
    "            coef_var, \n",
    "            coef_iqr, \n",
    "            logit1,\n",
    "            logit2,\n",
    "            logit3,\n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Median Absolute Dev\", \n",
    "            \"Mean Absolute Dev\", \n",
    "            \"IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze 400\",\n",
    "            \"Input squeeze 450\",\n",
    "            \"Input squeeze 500\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "                \"Feature squeezer\"\n",
    "        ])\n",
    "            \n",
    "            path = \"confidence_\"+str(conf)+\"_CIFAR_CW.csv\"\n",
    "            df.to_csv(path)\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "65090672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar_model(path):\n",
    "    model = resnet50()\n",
    "    ckpt_dict = torch.load(path, lambda storage, loc: storage)\n",
    "    model.load_state_dict(ckpt_dict)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e1c70444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_cifar(): \n",
    "    \n",
    "    #load cifar model and set to eval\n",
    "    path = \"cifar.ckpt\"\n",
    "    normal_model = load_cifar_model(path)\n",
    "    normal_model.to(device)\n",
    "    normal_model.eval()\n",
    "    \n",
    "    #get dataset\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=torchvision.transforms.ToTensor())\n",
    "    test_loader = DataLoader(testset, shuffle=True, batch_size=10)\n",
    "    \n",
    "    #compute all attack for each hyperparameter one by one \n",
    "    epsilons = [64/255]\n",
    "    #confidences = [0,50]\n",
    "    #compute_benign_cifar(train_loader, normal_model) \n",
    "    for eps in epsilons:\n",
    "        compute_fgsm_cifar(test_loader, normal_model, eps)\n",
    "        compute_pgd_cifar(test_loader, normal_model, eps)\n",
    "        compute_bim_cifar(test_loader, normal_model, eps)\n",
    "    \n",
    "    #for conf in confidences: \n",
    "        #compute_cw_cifar(test_loader, normal_model, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ba19a4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Computing metrics for 0.25098039215686274 for PGD\n",
      "Computing metrics for 0.25098039215686274 for PGD\n",
      "Computing metrics for 0.25098039215686274 for BIM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec808a978ee94951b3cbec8ff76b8f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116b6a98f0bf4aaea5e711502c2992f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0ca047d9d345348afd784110c6744f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dfd738bc394dcd8b0ee1acc22dae58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38b27ed9db347c2af48dfde56616c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c437f9a9318d4d5c898b55fcf0f1a15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d765225af7f14824bf7b9176fe81c6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9124f315924c80882440badba81421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1de8b1fb6b84492abd461d8a4d442ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc980908ad51445aaa3ccab9ce582b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653b656c8633401e99176cb907ae79bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0d1847a61e400598b81bfae3e9004e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d4dcf1ff8549969361424a2346fc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc02f80501042329b286b6386a86413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03b464bca244c3ca6e3598ba064511d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2687b72f13a5428caf2ca0ddee16c9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7c654034d54b049aa97f4f92c7acce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4312df926f64a9abefe549c29501a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c539bde72846b2a069222f436d11f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2d5aa644b64459a3c7096f2e701468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bc0716f21948acb45ba5521878a031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a47f9bb0b2043c3b4b9a4287d72ddc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076d4d52c50e4239b272b2afd4108651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bafb2ea4f34d7ea07a10e482ab002e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534c835df7a1439681d5100290066184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5937c056df469887343da867f93906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9df6c2f29847b283945b1dcbd9a3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ef5927c8f6490f889b081b576537bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a966b7417ad4c5fb2d9cbd0ca188438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8a74d517964f7f8b3c71ca5a7a531e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407521c8295e40a1be5b52910c43b499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2592fb4e2f433ebde85df388b69f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3928c0a3650d4e03b97dfa9d90930644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff2f98c40f54626a4265545a7368c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d158f0aac24f00aa8dc4024a147fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39e503be03a45858a6bb49ab3bbba32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48806c7754304cd0b7446d627c01b9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b145342abea64bb193baf0265b2951da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa2f4197a144c9daae10ccc29923d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5db1ecbc07421a95454167975885fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a063cd250f34aa0a01cb898e422d489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bed98c91ad04c1b80416dc00ef93fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b166537c83a943afa23ff80bdd928f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66cad0f585d48b6b4812d10b37f934a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a5abdf8a474a95aa1b372c6b38e2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e3751a1e3548a48e47e055389c9e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eca7e4a7b414a2b8b04bd577844c406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf43e7c9c908455ea766bf7fb4b4cca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00aed89aebcd44f7af3fb1868b953e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5920af4cc4409ea075eeb94316c81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b74a5a837a46f6af1026291cd51bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_cifar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b61332",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e29b3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pgd_mnist(test_loader, normal_model, eps): \n",
    "    \n",
    "    print(\"Computing metrics for {} for PGD\".format(eps))\n",
    "    medianAbs = []\n",
    "    meanAbs = []\n",
    "    iqr= []\n",
    "    coef_var=[]\n",
    "    coef_iqr = []\n",
    "\n",
    "    logit1 = []\n",
    "    logit2 = []\n",
    "    logit3 = []\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    fs = []\n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        if len(images_adv) == 0:\n",
    "            continue\n",
    "        \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"mnist\", images_adv)\n",
    "        fs.extend(d)\n",
    "        \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(images_adv)\n",
    "        a_batch = (Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        meanAbs += compute_mean_abs_dev(a_batch)\n",
    "        medianAbs += compute_median_abs_dev(a_batch)\n",
    "        iqr += compute_iqr(a_batch)\n",
    "        coef_var += compute_coef_var(a_batch)\n",
    "        coef_iqr += compute_coef_iqr(a_batch)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 100, d_type=\"adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 150, d_type=\"adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 180, d_type=\"adv\")\n",
    "        \n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit1.extend(diff1.detach().cpu().numpy())\n",
    "        logit2.extend(diff2.detach().cpu().numpy())\n",
    "        logit3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.005)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.01)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if len(iqr) > 500:            \n",
    "            break\n",
    "    df = pd.DataFrame([\n",
    "            medianAbs,\n",
    "            meanAbs, \n",
    "            iqr, \n",
    "            coef_var, \n",
    "            coef_iqr, \n",
    "            logit1,\n",
    "            logit2,\n",
    "            logit3,\n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Median Absolute Dev\", \n",
    "            \"Mean Absolute Dev\", \n",
    "            \"IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze 100\",\n",
    "            \"Input squeeze 150\",\n",
    "            \"Input squeeze 180\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "            \"Feature squeeze\"\n",
    "        ])\n",
    "            \n",
    "    path = \"eps_\"+str(eps)+\"_MNIST_PGD.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "32127f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fgsm_mnist(test_loader, normal_model, eps): \n",
    "    \n",
    "    print(\"Computing metrics for {} for PGD\".format(eps))\n",
    "    medianAbs = []\n",
    "    meanAbs = []\n",
    "    iqr= []\n",
    "    coef_var=[]\n",
    "    coef_iqr = []\n",
    "\n",
    "    logit1 = []\n",
    "    logit2 = []\n",
    "    logit3 = []\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    fs = []\n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_fgsm_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        if len(images_adv) == 0:\n",
    "            continue\n",
    "        \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"mnist\", images_adv)\n",
    "        fs.extend(d)\n",
    "        \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(images_adv)\n",
    "        a_batch = (Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        meanAbs += compute_mean_abs_dev(a_batch)\n",
    "        medianAbs += compute_median_abs_dev(a_batch)\n",
    "        iqr += compute_iqr(a_batch)\n",
    "        coef_var += compute_coef_var(a_batch)\n",
    "        coef_iqr += compute_coef_iqr(a_batch)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 100, d_type=\"adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 150, d_type=\"adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 180, d_type=\"adv\")\n",
    "        \n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit1.extend(diff1.detach().cpu().numpy())\n",
    "        logit2.extend(diff2.detach().cpu().numpy())\n",
    "        logit3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.005)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.01)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if len(iqr) > 500:            \n",
    "            break\n",
    "    df = pd.DataFrame([\n",
    "            medianAbs,\n",
    "            meanAbs, \n",
    "            iqr, \n",
    "            coef_var, \n",
    "            coef_iqr, \n",
    "            logit1,\n",
    "            logit2,\n",
    "            logit3,\n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Median Absolute Dev\", \n",
    "            \"Mean Absolute Dev\", \n",
    "            \"IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze 100\",\n",
    "            \"Input squeeze 150\",\n",
    "            \"Input squeeze 180\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "            \"Feature squeeze\"\n",
    "        ])\n",
    "            \n",
    "    path = \"eps_\"+str(eps)+\"_MNIST_FGSM.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dab17ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bim_mnist(train_loader_mnist, normal_model, eps): \n",
    "    \n",
    "    print(\"Computing metrics for {} for BIM\".format(eps))\n",
    "    \n",
    "    medianAbs = []\n",
    "    meanAbs = []\n",
    "    iqr= []\n",
    "    coef_var=[]\n",
    "    coef_iqr = []\n",
    "\n",
    "    logit1 = []\n",
    "    logit2 = []\n",
    "    logit3 = []\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    fs = []\n",
    "    \n",
    "    #set attack parameters for BIM\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(normal_model.parameters(), lr=0.01)\n",
    "    classifier = PyTorchClassifier(\n",
    "    model=normal_model, clip_values=(0, 1), loss=criterion, optimizer=optimizer, input_shape=(1, 28, 28),\n",
    "        nb_classes=10,\n",
    ")\n",
    "    attack = BasicIterativeMethod(classifier, eps = eps, max_iter=int(eps*256*1.25))\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader_mnist):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_bim_attack(attack, x_batch, y_batch, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        if len(images_adv) == 0:\n",
    "            continue\n",
    "    \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"mnist\", images_adv)\n",
    "        fs.extend(d)\n",
    "        \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(images_adv)\n",
    "        a_batch = (Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        meanAbs += compute_mean_abs_dev(a_batch)\n",
    "        medianAbs += compute_median_abs_dev(a_batch)\n",
    "        iqr += compute_iqr(a_batch)\n",
    "        coef_var += compute_coef_var(a_batch)\n",
    "        coef_iqr += compute_coef_iqr(a_batch)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch = quantus.normalise_func.normalise_by_max(Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 100, d_type=\"adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 150, d_type=\"adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 180, d_type=\"adv\")\n",
    "        \n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit1.extend(diff1.detach().cpu().numpy())\n",
    "        logit2.extend(diff2.detach().cpu().numpy())\n",
    "        logit3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.005)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.01)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if len(iqr) > 500:\n",
    "            break\n",
    "    df = pd.DataFrame([\n",
    "            medianAbs,\n",
    "            meanAbs, \n",
    "            iqr, \n",
    "            coef_var, \n",
    "            coef_iqr, \n",
    "            logit1,\n",
    "            logit2,\n",
    "            logit3,\n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Median Absolute Dev\", \n",
    "            \"Mean Absolute Dev\", \n",
    "            \"IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze 100\",\n",
    "            \"Input squeeze 150\",\n",
    "            \"Input squeeze 180\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "            \"Feature squeeze\"\n",
    "        ])\n",
    "            \n",
    "    path = \"eps_\"+str(eps)+\"_MNIST_BIM.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e5487fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cw_mnist(train_loader_mnist, normal_model, conf): \n",
    "    #compute metrics for svhn\n",
    "    \n",
    "    print(\"Computing metrics for {} for CW\".format(conf))\n",
    "    medianAbs = []\n",
    "    meanAbs = []\n",
    "    iqr= []\n",
    "    coef_var=[]\n",
    "    coef_iqr = []\n",
    "\n",
    "    logit1 = []\n",
    "    logit2 = []\n",
    "    logit3 = []\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    fs = []\n",
    "    \n",
    "    #set attack parameters for BIM\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(normal_model.parameters(), lr=0.01)\n",
    "    classifier = PyTorchClassifier(\n",
    "    model=normal_model, clip_values=(0, 1), loss=criterion, optimizer=optimizer, input_shape=(1, 28, 28),\n",
    "        nb_classes=10,\n",
    ")\n",
    "    attack = CarliniLInfMethod(classifier, confidence = conf)\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader_mnist):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_cw_attack(attack, x_batch, y_batch, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        if len(images_adv) == 0:\n",
    "            continue\n",
    "    \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"mnist\", images_adv)\n",
    "        fs.extend(d)\n",
    "        \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(images_adv)\n",
    "        a_batch = (Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        meanAbs += compute_mean_abs_dev(a_batch)\n",
    "        medianAbs += compute_median_abs_dev(a_batch)\n",
    "        iqr += compute_iqr(a_batch)\n",
    "        coef_var += compute_coef_var(a_batch)\n",
    "        coef_iqr += compute_coef_iqr(a_batch)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=images_adv, target=y_pred_adv).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 100, d_type=\"adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 150, d_type=\"adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(images_adv, a_batch, top_k = 180, d_type=\"adv\")\n",
    "        \n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit1.extend(diff1.detach().cpu().numpy())\n",
    "        logit2.extend(diff2.detach().cpu().numpy())\n",
    "        logit3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.005)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.01)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if len(iqr) > 500:    \n",
    "            break\n",
    "    \n",
    "    df = pd.DataFrame([\n",
    "            medianAbs,\n",
    "            meanAbs, \n",
    "            iqr, \n",
    "            coef_var, \n",
    "            coef_iqr, \n",
    "            logit1,\n",
    "            logit2,\n",
    "            logit3,\n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Median Absolute Dev\", \n",
    "            \"Mean Absolute Dev\", \n",
    "            \"IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze 100\",\n",
    "            \"Input squeeze 150\",\n",
    "            \"Input squeeze 180\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "            \"Feature squeeze\"\n",
    "        ])\n",
    "            \n",
    "    path = \"confidence_\"+str(conf)+\"_MNIST_CW.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "48f89a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_model(path):\n",
    "    model = LeNet_normal()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1fb7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_mnist():\n",
    "    \n",
    "    \n",
    "    #get model\n",
    "    \n",
    "    #get dataset\n",
    "    test_set = torchvision.datasets.MNIST(root='./sample_data', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=10, pin_memory=True)\n",
    "    \n",
    "    #compute all attack for each hyperparameter one by one \n",
    "    epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "    confidences = [0,50]\n",
    "    compute_benign_mnist(test_loader, normal_model) \n",
    "    for eps in epsilons:\n",
    "        compute_fgsm_mnist(test_loader, normal_model, eps)\n",
    "        compute_pgd_mnist(test_loader, normal_model, eps)\n",
    "        compute_bim_mnist(test_loader, normal_model, eps)\n",
    "    \n",
    "    for conf in confidences: \n",
    "        compute_cw_mnist(test_loader, normal_model, conf)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa87532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
