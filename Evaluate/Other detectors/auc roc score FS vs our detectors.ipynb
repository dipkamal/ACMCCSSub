{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab9d23d2",
   "metadata": {},
   "source": [
    "# Compute AUC score for feature squeeze and our detectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60cf0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740eeee",
   "metadata": {},
   "source": [
    "# Feature squeeze method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dd32857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv, th): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in adv: \n",
    "        if value>th:\n",
    "            TP += 1\n",
    "        else: \n",
    "            FN += 1\n",
    "    \n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2d7f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ben, th): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in ben: \n",
    "        if value<th:\n",
    "            TN += 1\n",
    "        else: \n",
    "            FP += 1\n",
    "    \n",
    "    \n",
    "    return (FP/(FP+TN))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc47b28",
   "metadata": {},
   "source": [
    "# CIFAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece6cb6",
   "metadata": {},
   "source": [
    "For each epsilon attack, i need to compute a range of TPR FPR values and then compute AUC ROC score. there is no other way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea57df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [2, 1.5, 1.4, 1.3, 1.2, 1.1, 1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.3, 0.2, 0.1, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bcd3afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cifar = pd.read_csv(\"Benign_CIFAR_Metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f8c6b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_squeezer = df_cifar.iloc[16].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "caebbaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.08076923076923076, 0.09038461538461538, 0.10576923076923077, 0.1173076923076923, 0.12692307692307692, 0.13076923076923078, 0.13846153846153847, 0.14615384615384616, 0.15, 0.16153846153846152, 0.17115384615384616, 0.18461538461538463, 0.19230769230769235, 0.21346153846153848, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(feature_squeezer, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7825cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd with five epsilons\n",
    "df_pgd_eps1 = pd.read_csv('cifar/pgd/eps8_255.csv')\n",
    "df_pgd_eps2 = pd.read_csv('cifar/pgd/eps16_255.csv')\n",
    "df_pgd_eps3 = pd.read_csv('cifar/pgd/eps32_255.csv')\n",
    "df_pgd_eps4 = pd.read_csv('cifar/pgd/eps64_255.csv')\n",
    "\n",
    "\n",
    "#fgsm with five epsilons\n",
    "df_fgsm_eps1 = pd.read_csv('cifar/fgsm/eps8_255.csv')\n",
    "df_fgsm_eps2 = pd.read_csv('cifar/fgsm/eps16_255.csv')\n",
    "df_fgsm_eps3 = pd.read_csv('cifar/fgsm/eps32_255.csv')\n",
    "df_fgsm_eps4 = pd.read_csv('cifar/fgsm/eps64_255.csv')\n",
    "\n",
    "#bim with five epsilons\n",
    "df_bim_eps1 = pd.read_csv('cifar/bim/eps8_255.csv')\n",
    "df_bim_eps2 = pd.read_csv('cifar/bim/eps16_255.csv')\n",
    "df_bim_eps3 = pd.read_csv('cifar/bim/eps32_255.csv')\n",
    "df_bim_eps4 = pd.read_csv('cifar/bim/eps64_255.csv')\n",
    "\n",
    "#cw with four confidences\n",
    "df_cw_conf1 = pd.read_csv('cifar/cw/conf_0.csv')\n",
    "df_cw_conf2 = pd.read_csv('cifar/cw/conf_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "70118758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_auc(adv_list, th): \n",
    "    tpr_results = []\n",
    "    for th in threshold:\n",
    "        TPR = compute_TPR(adv_list, th)\n",
    "        tpr_results.append(TPR/100)\n",
    "    return sklearn.metrics.auc(fpr_results, tpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea8a0cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7950138185168125\n",
      "0.8041176020798286\n",
      "0.7271337726019\n",
      "0.5117726086288961\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_pgd_eps1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_pgd_eps2.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_3 = df_pgd_eps3.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_4 = df_pgd_eps4.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))\n",
    "print(compute_auc(feature_squeezer_3, threshold))\n",
    "print(compute_auc(feature_squeezer_4, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd23df40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.681759557807462\n",
      "0.7762475049900199\n",
      "0.6346890584857185\n",
      "0.762061902594447\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_fgsm_eps1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_fgsm_eps2.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_3 = df_fgsm_eps3.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_4 = df_fgsm_eps4.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))\n",
    "print(compute_auc(feature_squeezer_3, threshold))\n",
    "print(compute_auc(feature_squeezer_4, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb2cc73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7223557692307692\n",
      "0.5761712256309505\n",
      "0.4110328907203908\n",
      "0.39618055555555554\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_bim_eps1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_bim_eps2.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_3 = df_bim_eps3.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_4 = df_bim_eps4.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))\n",
    "print(compute_auc(feature_squeezer_3, threshold))\n",
    "print(compute_auc(feature_squeezer_4, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "997b4ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8516674297924297\n",
      "0.8517407492706894\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_cw_conf1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_cw_conf2.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8d2c6",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4c765895",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [2, 1.0, 0.1, 0.03, 0.001, 0.0001, 0.000001, 0.00000001, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b4951087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnist = pd.read_csv(\"Benign_MNIST_Metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9e9acd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_squeezer = df_mnist.iloc[16].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "51289545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.208463810709507e-24, 1.952345609664917)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(feature_squeezer), max(feature_squeezer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5cacd198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.023076923076923078, 0.1, 0.15384615384615385, 0.28846153846153844, 0.38076923076923075, 0.5538461538461539, 0.6942307692307692, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(feature_squeezer, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "094bfeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd with five epsilons\n",
    "df_pgd_eps1 = pd.read_csv('mnist/pgd/eps8_255.csv')\n",
    "df_pgd_eps2 = pd.read_csv('mnist/pgd/eps16_255.csv')\n",
    "df_pgd_eps3 = pd.read_csv('mnist/pgd/eps32_255.csv')\n",
    "df_pgd_eps4 = pd.read_csv('mnist/pgd/eps64_255.csv')\n",
    "\n",
    "\n",
    "#fgsm with five epsilons\n",
    "df_fgsm_eps1 = pd.read_csv('mnist/fgsm/eps8_255.csv')\n",
    "df_fgsm_eps2 = pd.read_csv('mnist/fgsm/eps16_255.csv')\n",
    "df_fgsm_eps3 = pd.read_csv('mnist/fgsm/eps32_255.csv')\n",
    "df_fgsm_eps4 = pd.read_csv('mnist/fgsm/eps64_255.csv')\n",
    "\n",
    "#bim with five epsilons\n",
    "df_bim_eps1 = pd.read_csv('mnist/bim/eps8_255.csv')\n",
    "df_bim_eps2 = pd.read_csv('mnist/bim/eps16_255.csv')\n",
    "df_bim_eps3 = pd.read_csv('mnist/bim/eps32_255.csv')\n",
    "df_bim_eps4 = pd.read_csv('mnist/bim/eps64_255.csv')\n",
    "\n",
    "#cw with four confidences\n",
    "df_cw_conf1 = pd.read_csv('mnist/cw/conf_0.csv')\n",
    "df_cw_conf2 = pd.read_csv('mnist/cw/conf_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "088dc2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9416528066528066\n",
      "0.946629659000793\n",
      "0.945732874091083\n",
      "0.9683207417582418\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_pgd_eps1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_pgd_eps2.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_3 = df_pgd_eps3.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_4 = df_pgd_eps4.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))\n",
    "print(compute_auc(feature_squeezer_3, threshold))\n",
    "print(compute_auc(feature_squeezer_4, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ba622ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9788385074170363\n",
      "0.9826731535396874\n",
      "0.9797562833206397\n",
      "0.9748774134232302\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_fgsm_eps1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_fgsm_eps2.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_3 = df_fgsm_eps3.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_4 = df_fgsm_eps4.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))\n",
    "print(compute_auc(feature_squeezer_3, threshold))\n",
    "print(compute_auc(feature_squeezer_4, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8a5559a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9784200829111008\n",
      "0.98380103991436\n",
      "0.9849946368372663\n",
      "0.9793031226199543\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_bim_eps1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_bim_eps2.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_3 = df_bim_eps3.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_4 = df_bim_eps4.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))\n",
    "print(compute_auc(feature_squeezer_3, threshold))\n",
    "print(compute_auc(feature_squeezer_4, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4187a0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9466977466977468\n",
      "0.9466977466977468\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_cw_conf1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_cw_conf2.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c60ba09",
   "metadata": {},
   "source": [
    "# ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1f0ab3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [1.5, 1.1, 0.7, 0.5, 0.3, 0.1, 0.000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c41a6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imagenet = pd.read_csv(\"Benign_IMAGENET_Metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a85f1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_squeezer = df_imagenet.iloc[16].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "835188b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09607843137254904, 0.2352941176470588, 0.47450980392156855, 0.5882352941176471, 0.7058823529411765, 0.8568627450980393, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(feature_squeezer, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f9e8f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd with five epsilons\n",
    "df_pgd_eps1 = pd.read_csv('imagenet/pgd/eps8_255.csv')\n",
    "df_pgd_eps2 = pd.read_csv('imagenet/pgd/eps16_255.csv')\n",
    "df_pgd_eps3 = pd.read_csv('imagenet/pgd/eps32_255.csv')\n",
    "df_pgd_eps4 = pd.read_csv('imagenet/pgd/eps64_255.csv')\n",
    "\n",
    "\n",
    "#fgsm with five epsilons\n",
    "df_fgsm_eps1 = pd.read_csv('imagenet/fgsm/eps8_255.csv')\n",
    "df_fgsm_eps2 = pd.read_csv('imagenet/fgsm/eps16_255.csv')\n",
    "df_fgsm_eps3 = pd.read_csv('imagenet/fgsm/eps32_255.csv')\n",
    "df_fgsm_eps4 = pd.read_csv('imagenet/fgsm/eps64_255.csv')\n",
    "\n",
    "#bim with five epsilons\n",
    "df_bim_eps1 = pd.read_csv('imagenet/bim/eps8_255.csv')\n",
    "df_bim_eps2 = pd.read_csv('imagenet/bim/eps16_255.csv')\n",
    "df_bim_eps3 = pd.read_csv('imagenet/bim/eps32_255.csv')\n",
    "df_bim_eps4 = pd.read_csv('imagenet/bim/eps64_255.csv')\n",
    "\n",
    "#cw with four confidences\n",
    "df_cw_conf1 = pd.read_csv('imagenet/cw/conf_0.csv')\n",
    "df_cw_conf2 = pd.read_csv('imagenet/cw/conf_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4f0845f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5644377910844977\n",
      "0.5830965519940512\n",
      "0.6284313725490196\n",
      "0.7187872763419483\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_pgd_eps1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_pgd_eps2.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_3 = df_pgd_eps3.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_4 = df_pgd_eps4.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))\n",
    "print(compute_auc(feature_squeezer_3, threshold))\n",
    "print(compute_auc(feature_squeezer_4, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d9ab0c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641426907396622\n",
      "0.6610318481269247\n",
      "0.6891787270463742\n",
      "0.7140970276999689\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_fgsm_eps1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_fgsm_eps2.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_3 = df_fgsm_eps3.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_4 = df_fgsm_eps4.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))\n",
    "print(compute_auc(feature_squeezer_3, threshold))\n",
    "print(compute_auc(feature_squeezer_4, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0dedbfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6488600995953937\n",
      "0.6230245391569802\n",
      "0.43260733435090604\n",
      "0.2704911667637352\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_bim_eps1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_bim_eps2.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_3 = df_bim_eps3.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_4 = df_bim_eps4.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))\n",
    "print(compute_auc(feature_squeezer_3, threshold))\n",
    "print(compute_auc(feature_squeezer_4, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c2c12317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4294312556036331\n",
      "0.4326453046427318\n"
     ]
    }
   ],
   "source": [
    "feature_squeezer_1 = df_cw_conf1.iloc[16].values.flatten().tolist()[1:]\n",
    "feature_squeezer_2 = df_cw_conf2.iloc[16].values.flatten().tolist()[1:]\n",
    "\n",
    "print(compute_auc(feature_squeezer_1, threshold))\n",
    "print(compute_auc(feature_squeezer_2, threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d67f9",
   "metadata": {},
   "source": [
    "# Our approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe6b782",
   "metadata": {},
   "source": [
    "## CIFAR dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c1db2",
   "metadata": {},
   "source": [
    "## 1. Approach 2: Robustness measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "ad88459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2 in zip(adv1, adv2): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else: \n",
    "                FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "485079db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "f61c867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cifar = pd.read_csv(\"Benign_CIFAR_Metrics.csv\")\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "dbdf2365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03076923076923077, 0.10384615384615385, 0.2076923076923077, 0.3403846153846154, 0.5403846153846154, 0.7134615384615386, 0.8673076923076922, 0.9461538461538461, 0.9865384615384616, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#logitgaussian3\n",
    "k=[44,64,76, 86, 96, 106, 126, 150, 200, 400]\n",
    "l=[405,405,405,405,405,405,405,405,405,405, 405]\n",
    "\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100, 3500, 4000, 4500, 5000, 5500, 6000, 8000]\n",
    "n=[8800,8800,8800, 8800,8800,8800, 8800,8800,8800, 8800]\n",
    "\n",
    "\n",
    "fpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    FPR = compute_FPR(logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "e77afc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd with five epsilons\n",
    "df_pgd_eps1 = pd.read_csv('cifar/pgd/eps8_255.csv')\n",
    "df_pgd_eps2 = pd.read_csv('cifar/pgd/eps16_255.csv')\n",
    "df_pgd_eps3 = pd.read_csv('cifar/pgd/eps32_255.csv')\n",
    "df_pgd_eps4 = pd.read_csv('cifar/pgd/eps64_255.csv')\n",
    "\n",
    "\n",
    "#fgsm with five epsilons\n",
    "df_fgsm_eps1 = pd.read_csv('cifar/fgsm/eps8_255.csv')\n",
    "df_fgsm_eps2 = pd.read_csv('cifar/fgsm/eps16_255.csv')\n",
    "df_fgsm_eps3 = pd.read_csv('cifar/fgsm/eps32_255.csv')\n",
    "df_fgsm_eps4 = pd.read_csv('cifar/fgsm/eps64_255.csv')\n",
    "\n",
    "#bim with five epsilons\n",
    "df_bim_eps1 = pd.read_csv('cifar/bim/eps8_255.csv')\n",
    "df_bim_eps2 = pd.read_csv('cifar/bim/eps16_255.csv')\n",
    "df_bim_eps3 = pd.read_csv('cifar/bim/eps32_255.csv')\n",
    "df_bim_eps4 = pd.read_csv('cifar/bim/eps64_255.csv')\n",
    "\n",
    "#cw with four confidences\n",
    "df_cw_conf1 = pd.read_csv('cifar/cw/conf_0.csv')\n",
    "df_cw_conf2 = pd.read_csv('cifar/cw/conf_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "8eefa6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6387455857515738\n",
      "--\n",
      "0.8056621807615845\n",
      "---\n",
      "0.9548709010113392\n",
      "---\n",
      "0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "#pgd\n",
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('---')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('---')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "3d144c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8772339935513589\n",
      "--\n",
      "0.9673345616459389\n",
      "---\n",
      "0.9692307692307692\n",
      "---\n",
      "0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "#fgsm\n",
    "logit_gaussian3_eps1 = df_fgsm_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_fgsm_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_fgsm_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_fgsm_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_fgsm_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_fgsm_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_fgsm_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_fgsm_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "x1 = df_fgsm_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_fgsm_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_fgsm_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_fgsm_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('---')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('---')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "0918ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603365384615385\n",
      "--\n",
      "0.9572880459422699\n",
      "---\n",
      "0.9685782967032966\n",
      "---\n",
      "0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "#bim\n",
    "logit_gaussian3_eps1 = df_bim_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_bim_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_bim_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_bim_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_bim_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_bim_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_bim_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_bim_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "x1 = df_bim_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_bim_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_bim_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_bim_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('---')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('---')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "fef361a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5543231074481074\n",
      "--\n",
      "0.5631333486872409\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#cw\n",
    "logit_gaussian3_eps1 = df_cw_conf1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_cw_conf2.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_cw_conf1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_cw_conf2.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6db1b",
   "metadata": {},
   "source": [
    "## 2. Approach 2 + coefficient of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "71c901ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(ap2a, k, l, ap2b, m, n, coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7, value8 in zip(ap2a,ap2b,coefvar):\n",
    "        if value6<k or value6>l:\n",
    "            TP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                TP +=1\n",
    "            else:\n",
    "                if value8<g or value8>h:\n",
    "                    TP+=1\n",
    "                \n",
    "    return (TP/(len(ap2a)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "a9309fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap2a, k, l, ap2b, m, n, coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7, value8 in zip(ap2a,ap2b,coefvar):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value8<g or value8>h:\n",
    "                    FP+=1\n",
    "                \n",
    "    return (FP/(len(ap2a)))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "c4957c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cifar = pd.read_csv(\"Benign_CIFAR_Metrics.csv\")\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "1a03aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1943.583984375, 9687.2734375)"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(attr_gaussian3), max(attr_gaussian3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "4a07d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03653846153846154, 0.10961538461538461, 0.24423076923076922, 0.39807692307692305, 0.5903846153846154, 0.8057692307692308, 0.9788461538461539, 0.9961538461538462, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#coef of var\n",
    "g=[0.42,0.42,0.42, 0.42,0.42,0.42, 0.42, 0.42, 0.42]\n",
    "h=[1.30, 1.27,1.19,1.146, 1.10, 1.0,0.8, 0.6, 0.5]\n",
    "\n",
    "#logitgaussian3\n",
    "k=[44,64,76, 86, 96, 106, 126, 150, 200]\n",
    "l=[405,405,405,405,405,405,405,405,405,405]\n",
    "\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100, 3500, 4000, 4500, 5000, 5500, 6000]\n",
    "n=[8800,8800,8800, 8800,8800,8800, 8800,8800,8800]\n",
    "\n",
    "fpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    FPR = compute_FPR(logit_gaussian3, t1,t2, attr_gaussian3,t3,t4, coef_var,t5,t6)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "1001ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd with five epsilons\n",
    "df_pgd_eps1 = pd.read_csv('cifar/pgd/eps8_255.csv')\n",
    "df_pgd_eps2 = pd.read_csv('cifar/pgd/eps16_255.csv')\n",
    "df_pgd_eps3 = pd.read_csv('cifar/pgd/eps32_255.csv')\n",
    "df_pgd_eps4 = pd.read_csv('cifar/pgd/eps64_255.csv')\n",
    "\n",
    "\n",
    "#fgsm with five epsilons\n",
    "df_fgsm_eps1 = pd.read_csv('cifar/fgsm/eps8_255.csv')\n",
    "df_fgsm_eps2 = pd.read_csv('cifar/fgsm/eps16_255.csv')\n",
    "df_fgsm_eps3 = pd.read_csv('cifar/fgsm/eps32_255.csv')\n",
    "df_fgsm_eps4 = pd.read_csv('cifar/fgsm/eps64_255.csv')\n",
    "\n",
    "#bim with five epsilons\n",
    "df_bim_eps1 = pd.read_csv('cifar/bim/eps8_255.csv')\n",
    "df_bim_eps2 = pd.read_csv('cifar/bim/eps16_255.csv')\n",
    "df_bim_eps3 = pd.read_csv('cifar/bim/eps32_255.csv')\n",
    "df_bim_eps4 = pd.read_csv('cifar/bim/eps64_255.csv')\n",
    "\n",
    "#cw with four confidences\n",
    "df_cw_conf1 = pd.read_csv('cifar/cw/conf_0.csv')\n",
    "df_cw_conf2 = pd.read_csv('cifar/cw/conf_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "1ce036ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd\n",
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "x1 = df_pgd_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_pgd_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_pgd_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_pgd_eps4.iloc[3].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "5a67e51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02794411177644711, 0.17764471057884232, 0.3972055888223553, 0.6227544910179641, 0.7924151696606786, 0.9221556886227547, 0.996007984031936, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4, x1,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(tpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "4c73567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6324965453707969"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.auc(fpr_results, tpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "ce99e790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7927703012693073\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4, x2,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "8e4a9f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9493985596077229\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4, x3,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "adc9b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "0.9634615384615385\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4, x4,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "ec89c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fgsm\n",
    "logit_gaussian3_eps1 = df_fgsm_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_fgsm_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_fgsm_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_fgsm_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_fgsm_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_fgsm_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_fgsm_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_fgsm_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "x1 = df_fgsm_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_fgsm_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_fgsm_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_fgsm_eps4.iloc[3].values.flatten().tolist()[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "ffd97bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701788730231843\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4, x1,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "3e9c186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9615653308767081\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4, x2,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "0cd16810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9634615384615385\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4, x3,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "95bbb118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9634615384615385\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4, x4,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "52bb844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bim\n",
    "logit_gaussian3_eps1 = df_bim_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_bim_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_bim_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_bim_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_bim_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_bim_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_bim_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_bim_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "x1 = df_bim_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_bim_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_bim_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_bim_eps4.iloc[3].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "9047d9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8498969780219781\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4, x1,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "1c044125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9524142360586368\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4, x2,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "c0a7c07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9628090659340659\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4, x3,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "d6fced27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9634615384615385\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4, x4,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "0c35166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cw\n",
    "logit_gaussian3_eps1 = df_cw_conf1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_cw_conf2.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_cw_conf1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_cw_conf2.iloc[10].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "f4a6b4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6335889804639805\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4, x1,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "edf22482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7028366344234608\n"
     ]
    }
   ],
   "source": [
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(k,l,m,n,g,h):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4, x2,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "#print(tpr_results)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d220b23",
   "metadata": {},
   "source": [
    "## Approach 3: Cascading all statistical detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "196820fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "76279ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4 in zip(meanAb,medianAb,coefiqr,coefvar): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    TP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        TP +=1\n",
    "                    else:\n",
    "                        FN+=1\n",
    "    \n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "c2b57ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h,iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value8 in zip(meanAb,medianAb,coefiqr,coefvar,iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else:\n",
    "                        if value8<o or value8>p:\n",
    "                            FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9208f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "39073d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1.3,1.85,2,2.5,3,3.5,4,4.5,5]\n",
    "b=[7,7,6,6,6,6,6,6,6]\n",
    "\n",
    "c=[0.9,1.08,1.23,1.33,1.6,1.7,2,2.5,3]\n",
    "d=[5,4,4,4,4,4,4,4,4]\n",
    "\n",
    "e=[0.461,0.491,0.502,0.55,0.66,0.7, 0.74, 0.78, 0.8]\n",
    "f=[0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8]\n",
    "\n",
    "g=[0.42,0.42,0.42, 0.42,0.42,0.42, 0.42, 0.42, 0.42]\n",
    "h=[1.30, 1.27,1.19,1.146, 1.10, 1.0,0.8, 0.6, 0.5]\n",
    "\n",
    "#iqr\n",
    "o=[2,2.5,2.8, 3.5, 4.0, 4.5, 5, 5.5, 6.0]\n",
    "p=[10,10,10,10,10,10,10,10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "bfb01c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "d9066270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.026923076923076925, 0.12115384615384615, 0.23076923076923075, 0.551923076923077, 0.9615384615384616, 0.9923076923076922, 0.9980769230769231, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    FPR = compute_FPR(meanAbsDev, t1,t2, medianAbsDev,t3,t4, coef_iqr,t5,t6, coef_var, t7, t8, iqr, t9, t10)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "3caf264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd with five epsilons\n",
    "df_pgd_eps1 = pd.read_csv('cifar/pgd/eps8_255.csv')\n",
    "df_pgd_eps2 = pd.read_csv('cifar/pgd/eps16_255.csv')\n",
    "df_pgd_eps3 = pd.read_csv('cifar/pgd/eps32_255.csv')\n",
    "df_pgd_eps4 = pd.read_csv('cifar/pgd/eps64_255.csv')\n",
    "\n",
    "\n",
    "#fgsm with five epsilons\n",
    "df_fgsm_eps1 = pd.read_csv('cifar/fgsm/eps8_255.csv')\n",
    "df_fgsm_eps2 = pd.read_csv('cifar/fgsm/eps16_255.csv')\n",
    "df_fgsm_eps3 = pd.read_csv('cifar/fgsm/eps32_255.csv')\n",
    "df_fgsm_eps4 = pd.read_csv('cifar/fgsm/eps64_255.csv')\n",
    "\n",
    "#bim with five epsilons\n",
    "df_bim_eps1 = pd.read_csv('cifar/bim/eps8_255.csv')\n",
    "df_bim_eps2 = pd.read_csv('cifar/bim/eps16_255.csv')\n",
    "df_bim_eps3 = pd.read_csv('cifar/bim/eps32_255.csv')\n",
    "df_bim_eps4 = pd.read_csv('cifar/bim/eps64_255.csv')\n",
    "\n",
    "#cw with four confidences\n",
    "df_cw_conf1 = pd.read_csv('cifar/cw/conf_0.csv')\n",
    "df_cw_conf2 = pd.read_csv('cifar/cw/conf_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "b2908a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48656341163826194\n",
      "0.5372342865881634\n",
      "0.8565583818571867\n",
      "0.9723245816060188\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_pgd_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_pgd_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_pgd_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_pgd_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_pgd_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_pgd_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_pgd_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_pgd_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_pgd_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_pgd_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_pgd_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_pgd_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_pgd_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_pgd_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_pgd_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_pgd_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_pgd_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_pgd_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_pgd_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_pgd_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4, cofiqreps1,t5,t6, x1, t7, t8, y1, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4, cofiqreps2,t5,t6, x2, t7, t8, y2, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4, cofiqreps3,t5,t6, x3, t7, t8, y3, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4, cofiqreps4,t5,t6, x4, t7, t8, y4, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "214fda24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7896975280208813\n",
      "0.9614309841854752\n",
      "0.9730769230769231\n",
      "0.9730769230769231\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_fgsm_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_fgsm_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_fgsm_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_fgsm_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_fgsm_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_fgsm_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_fgsm_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_fgsm_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_fgsm_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_fgsm_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_fgsm_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_fgsm_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_fgsm_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_fgsm_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_fgsm_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_fgsm_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_fgsm_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_fgsm_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_fgsm_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_fgsm_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4, cofiqreps1,t5,t6, x1, t7, t8, y1, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4, cofiqreps2,t5,t6, x2, t7, t8, y2, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4, cofiqreps3,t5,t6, x3, t7, t8, y3, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4, cofiqreps4,t5,t6, x4, t7, t8, y4, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "b8a66099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650555173992674\n",
      "0.9151220341544507\n",
      "0.9709268162393162\n",
      "0.9730769230769231\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_bim_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_bim_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_bim_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_bim_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_bim_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_bim_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_bim_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_bim_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_bim_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_bim_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_bim_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_bim_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_bim_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_bim_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_bim_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_bim_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_bim_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_bim_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_bim_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_bim_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4, cofiqreps1,t5,t6, x1, t7, t8, y1, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4, cofiqreps2,t5,t6, x2, t7, t8, y2, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4, cofiqreps3,t5,t6, x3, t7, t8, y3, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4, cofiqreps4,t5,t6, x4, t7, t8, y4, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "a1435412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5481913919413919\n",
      "0.5489847228619684\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_cw_conf1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_cw_conf2.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_cw_conf1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_cw_conf2.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_cw_conf1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_cw_conf2.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_cw_conf1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_cw_conf2.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_cw_conf1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_cw_conf2.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4, cofiqreps1,t5,t6, x1, t7, t8, y1, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6, t7, t8, t9, t10 in zip(a,b,c,d,e,f,g,h,o,p):\n",
    "    TPR = compute_TPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4, cofiqreps2,t5,t6, x2, t7, t8, y2, t9, t10)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b1596",
   "metadata": {},
   "source": [
    "# 3. Approach 1 and 2 combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "60fe1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "4e50b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=[48,68,78,88,98,118,138,158,168,188]\n",
    "j=[230,230,230,230,230,230,230,230,230,230]\n",
    "k=[44,64,76, 86, 96, 106, 126, 150, 200, 400]\n",
    "l=[405,405,405,405,405,405,405,405,405,405, 405]\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100, 3500, 4000, 4500, 5000, 5500, 6000, 8000]\n",
    "n=[8800,8800,8800, 8800,8800,8800, 8800,8800,8800, 8800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "db4be698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap1, i, j, ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value5, value6, value7 in zip(ap1,ap2a,ap2b):\n",
    "        if value5<i or value5>j:\n",
    "            FP +=1\n",
    "        else: \n",
    "            if value6<k or value6>l:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value7<m or value7>n:\n",
    "                    FP +=1\n",
    "\n",
    "    return (FP/(len(ap1)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "d945266b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05, 0.14615384615384616, 0.27115384615384613, 0.43653846153846154, 0.6346153846153846, 0.8403846153846153, 0.9326923076923077, 0.975, 0.9961538461538462, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    FPR = compute_FPR(squeezer_input,t0, t00, logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "c1069d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d, adv3, e, f): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3 in zip(adv1, adv2, adv3): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else:\n",
    "                if value3<e or value3>f:\n",
    "                    TP+=1\n",
    "                else:\n",
    "                    FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "6f3120e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd with five epsilons\n",
    "df_pgd_eps1 = pd.read_csv('cifar/pgd/eps8_255.csv')\n",
    "df_pgd_eps2 = pd.read_csv('cifar/pgd/eps16_255.csv')\n",
    "df_pgd_eps3 = pd.read_csv('cifar/pgd/eps32_255.csv')\n",
    "df_pgd_eps4 = pd.read_csv('cifar/pgd/eps64_255.csv')\n",
    "\n",
    "\n",
    "#fgsm with five epsilons\n",
    "df_fgsm_eps1 = pd.read_csv('cifar/fgsm/eps8_255.csv')\n",
    "df_fgsm_eps2 = pd.read_csv('cifar/fgsm/eps16_255.csv')\n",
    "df_fgsm_eps3 = pd.read_csv('cifar/fgsm/eps32_255.csv')\n",
    "df_fgsm_eps4 = pd.read_csv('cifar/fgsm/eps64_255.csv')\n",
    "\n",
    "#bim with five epsilons\n",
    "df_bim_eps1 = pd.read_csv('cifar/bim/eps8_255.csv')\n",
    "df_bim_eps2 = pd.read_csv('cifar/bim/eps16_255.csv')\n",
    "df_bim_eps3 = pd.read_csv('cifar/bim/eps32_255.csv')\n",
    "df_bim_eps4 = pd.read_csv('cifar/bim/eps64_255.csv')\n",
    "\n",
    "#cw with four confidences\n",
    "df_cw_conf1 = pd.read_csv('cifar/cw/conf_0.csv')\n",
    "df_cw_conf2 = pd.read_csv('cifar/cw/conf_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "d6669cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6365979579302933\n",
      "0.7926001682214405\n",
      "0.9339967054857493\n",
      "0.95\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#pgd\n",
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "squeezer_1 = df_pgd_eps1.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_pgd_eps2.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_pgd_eps3.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_pgd_eps4.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_1,t0, t00, logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_2,t0, t00, logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_3,t0, t00, logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_4,t0, t00, logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "3a46ac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8443056195301704\n",
      "0.9476969138645785\n",
      "0.95\n",
      "0.95\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "squeezer_1 = df_fgsm_eps1.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_fgsm_eps2.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_fgsm_eps3.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_fgsm_eps4.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_fgsm_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_fgsm_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_fgsm_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_fgsm_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_fgsm_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_fgsm_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_fgsm_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_fgsm_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_1,t0, t00, logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_2,t0, t00, logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_3,t0, t00, logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_4,t0, t00, logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "d22bcf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822184065934066\n",
      "0.9343773613419979\n",
      "0.9491414835164835\n",
      "0.95\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#bim\n",
    "squeezer_1 = df_bim_eps1.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_bim_eps2.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_bim_eps3.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_bim_eps4.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_bim_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_bim_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_bim_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_bim_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_bim_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_bim_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_bim_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_bim_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_1,t0, t00, logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_2,t0, t00, logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_3,t0, t00, logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_4,t0, t00, logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "df9c9d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5289835164835165\n",
      "0.5456145401504684\n"
     ]
    }
   ],
   "source": [
    "#cw\n",
    "squeezer_1 = df_cw_conf1.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_cw_conf2.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_cw_conf1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_cw_conf2.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_cw_conf1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_cw_conf2.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_1,t0, t00, logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results=[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_2,t0, t00, logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189280b",
   "metadata": {},
   "source": [
    "# Combine all detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "a6bd2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "5b67dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, ap1, i, j, ap2a, k, l, ap2b, m, n, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value5, value6, value7, value8 in zip(meanAb,medianAb,coefiqr,coefvar,ap1,ap2a,ap2b, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else: \n",
    "                        if value5<i or value5>j:\n",
    "                            FP +=1\n",
    "                        else: \n",
    "                            if value6<k or value6>l:\n",
    "                                FP +=1\n",
    "                            else:\n",
    "                                if value7<m or value7>n:\n",
    "                                    FP +=1\n",
    "                                else:\n",
    "                                    if value8<o or value8>p:\n",
    "                                        FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "f58fc714",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1.3,1.85,2,2.5,3,3.5,4,4.5,5]\n",
    "b=[7,7,6,6,6,6,6,6,6]\n",
    "\n",
    "c=[0.9,1.08,1.23,1.33,1.6,1.7,2,2.5,3]\n",
    "d=[5,4,4,4,4,4,4,4,4]\n",
    "\n",
    "e=[0.461,0.491,0.502,0.55,0.66,0.7, 0.74, 0.78, 0.8]\n",
    "f=[0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8]\n",
    "\n",
    "g=[0.42,0.42,0.42, 0.42,0.42,0.42, 0.42, 0.42, 0.42]\n",
    "h=[1.30, 1.27,1.19,1.146, 1.10, 1.0,0.8, 0.6, 0.5]\n",
    "\n",
    "\n",
    "i=[48,68,78,88,98,118,138,158,168,188]\n",
    "j=[230,230,230,230,230,230,230,230,230,230]\n",
    "\n",
    "#logitgaussian3\n",
    "k=[44,64,76, 86, 96, 106, 126, 150, 200, 400]\n",
    "l=[405,405,405,405,405,405,405,405,405,405, 405]\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100, 3500, 4000, 4500, 5000, 5500, 6000, 8000]\n",
    "n=[8800,8800,8800, 8800,8800,8800, 8800,8800,8800, 8800]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[2,2.5,2.8, 3.5, 4.0, 4.5, 5, 5.5, 6.0]\n",
    "p=[10,10,10,10,10,10,10,10,10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "eaca16b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06538461538461539, 0.20961538461538465, 0.36923076923076925, 0.6961538461538461, 0.9884615384615385, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    FPR = compute_FPR(meanAbsDev, t1,t2, medianAbsDev,t3,t4,coef_iqr,t5,t6,coef_var,t7,t8,squeezer_input,t9,t10,\n",
    "                    logit_gaussian3,t11,t12,attr_gaussian3,t13,t14,iqr,t15,t16 )\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "3cc7fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5846806387225548\n",
      "0.7378192384156599\n",
      "0.9135343242414955\n",
      "0.9346153846153846\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_pgd_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_pgd_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_pgd_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_pgd_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_pgd_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_pgd_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_pgd_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_pgd_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_pgd_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_pgd_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_pgd_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_pgd_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_pgd_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_pgd_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_pgd_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_pgd_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_pgd_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_pgd_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_pgd_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_pgd_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "squeezer_1 = df_pgd_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_pgd_eps2.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_pgd_eps3.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_pgd_eps4.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,\n",
    "                      squeezer_1,t9,t10,\n",
    "                    logit_gaussian3_eps1,t11,t12,attr_gaussian3_eps1,t13,t14,y1,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,\n",
    "                      squeezer_2,t9,t10,\n",
    "                    logit_gaussian3_eps2,t11,t12,attr_gaussian3_eps2,t13,t14,y2,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4,cofiqreps3,t5,t6,x3,t7,t8,\n",
    "                      squeezer_3,t9,t10,\n",
    "                    logit_gaussian3_eps3,t11,t12,attr_gaussian3_eps3,t13,t14,y3,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4,cofiqreps4,t5,t6,x4,t7,t8,\n",
    "                      squeezer_4,t9,t10,\n",
    "                    logit_gaussian3_eps4,t11,t12,attr_gaussian3_eps4,t13,t14,y4,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "475b3422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076136189160141\n",
      "0.9318804698295716\n",
      "0.9346153846153846\n",
      "0.9346153846153846\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_fgsm_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_fgsm_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_fgsm_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_fgsm_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_fgsm_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_fgsm_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_fgsm_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_fgsm_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_fgsm_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_fgsm_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_fgsm_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_fgsm_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_fgsm_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_fgsm_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_fgsm_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_fgsm_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "y1 = df_fgsm_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_fgsm_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_fgsm_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_fgsm_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "squeezer_1 = df_fgsm_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_fgsm_eps2.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_fgsm_eps3.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_fgsm_eps4.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_fgsm_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_fgsm_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_fgsm_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_fgsm_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_fgsm_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_fgsm_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_fgsm_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_fgsm_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,\n",
    "                      squeezer_1,t9,t10,\n",
    "                    logit_gaussian3_eps1,t11,t12,attr_gaussian3_eps1,t13,t14,y1,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,\n",
    "                      squeezer_2,t9,t10,\n",
    "                    logit_gaussian3_eps2,t11,t12,attr_gaussian3_eps2,t13,t14,y2,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4,cofiqreps3,t5,t6,x3,t7,t8,\n",
    "                      squeezer_3,t9,t10,\n",
    "                    logit_gaussian3_eps3,t11,t12,attr_gaussian3_eps3,t13,t14,y3,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4,cofiqreps4,t5,t6,x4,t7,t8,\n",
    "                      squeezer_4,t9,t10,\n",
    "                    logit_gaussian3_eps4,t11,t12,attr_gaussian3_eps4,t13,t14,y4,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "ed41e59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777796855921856\n",
      "0.9158077678706362\n",
      "0.9336137820512821\n",
      "0.9346153846153846\n"
     ]
    }
   ],
   "source": [
    "squeezer_1 = df_bim_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_bim_eps2.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_bim_eps3.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_bim_eps4.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_bim_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_bim_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_bim_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_bim_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_bim_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_bim_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_bim_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_bim_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "meanAbsDev_eps1 = df_bim_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_bim_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_bim_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_bim_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_bim_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_bim_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_bim_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_bim_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_bim_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_bim_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_bim_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_bim_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_bim_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_bim_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_bim_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_bim_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_bim_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_bim_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_bim_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_bim_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,\n",
    "                      squeezer_1,t9,t10,\n",
    "                    logit_gaussian3_eps1,t11,t12,attr_gaussian3_eps1,t13,t14,y1,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,\n",
    "                      squeezer_2,t9,t10,\n",
    "                    logit_gaussian3_eps2,t11,t12,attr_gaussian3_eps2,t13,t14,y2,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4,cofiqreps3,t5,t6,x3,t7,t8,\n",
    "                      squeezer_3,t9,t10,\n",
    "                    logit_gaussian3_eps3,t11,t12,attr_gaussian3_eps3,t13,t14,y3,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4,cofiqreps4,t5,t6,x4,t7,t8,\n",
    "                      squeezer_4,t9,t10,\n",
    "                    logit_gaussian3_eps4,t11,t12,attr_gaussian3_eps4,t13,t14,y4,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "36409d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.527209249084249\n",
      "0.5321530016889298\n"
     ]
    }
   ],
   "source": [
    "squeezer_1 = df_cw_conf1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_cw_conf2.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_cw_conf1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_cw_conf2.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_cw_conf1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_cw_conf2.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "meanAbsDev_eps1 = df_cw_conf1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_cw_conf2.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_cw_conf1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_cw_conf2.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_cw_conf1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_cw_conf2.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_cw_conf1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_cw_conf2.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_cw_conf1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_cw_conf2.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,\n",
    "                      squeezer_1,t9,t10,\n",
    "                    logit_gaussian3_eps1,t11,t12,attr_gaussian3_eps1,t13,t14,y1,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,\n",
    "                      squeezer_2,t9,t10,\n",
    "                    logit_gaussian3_eps2,t11,t12,attr_gaussian3_eps2,t13,t14,y2,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3744e",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "e32dfde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnist = pd.read_csv(\"Benign_MNIST_Metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "75004135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd with five epsilons\n",
    "df_pgd_eps1 = pd.read_csv('mnist/pgd/eps8_255.csv')\n",
    "df_pgd_eps2 = pd.read_csv('mnist/pgd/eps16_255.csv')\n",
    "df_pgd_eps3 = pd.read_csv('mnist/pgd/eps32_255.csv')\n",
    "df_pgd_eps4 = pd.read_csv('mnist/pgd/eps64_255.csv')\n",
    "\n",
    "#fgsm with five epsilons\n",
    "df_fgsm_eps1 = pd.read_csv('mnist/fgsm/eps8_255.csv')\n",
    "df_fgsm_eps2 = pd.read_csv('mnist/fgsm/eps16_255.csv')\n",
    "df_fgsm_eps3 = pd.read_csv('mnist/fgsm/eps32_255.csv')\n",
    "df_fgsm_eps4 = pd.read_csv('mnist/fgsm/eps64_255.csv')\n",
    "\n",
    "#bim with five epsilons\n",
    "df_bim_eps1 = pd.read_csv('mnist/bim/eps8_255.csv')\n",
    "df_bim_eps2 = pd.read_csv('mnist/bim/eps16_255.csv')\n",
    "df_bim_eps3 = pd.read_csv('mnist/bim/eps32_255.csv')\n",
    "df_bim_eps4 = pd.read_csv('mnist/bim/eps64_255.csv')\n",
    "\n",
    "#cw with four confidences\n",
    "df_cw_conf1 = pd.read_csv('mnist/cw/conf_0.csv')\n",
    "df_cw_conf2 = pd.read_csv('mnist/cw/conf_50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97aca3",
   "metadata": {},
   "source": [
    "# Using only approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "00b85d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap2a, a, b, ap2b, c, d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<a or value6>b:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<c or value7>d:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "bf3414d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2 in zip(adv1, adv2): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else: \n",
    "                FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "63917373",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.07,0.07,0.07, 0.07,0.07,0.07,0.07,0.07,0.07, 0.07]\n",
    "b=[3.3,2.1,1.7,1.5, 1.3, 1.1, 0.7, 0.5, 0.3, 0.1]\n",
    "c=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]\n",
    "d=[250,150,120, 110, 100, 90, 80, 70, 30,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "d020d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_gaussian3 = df_mnist.iloc[12].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_mnist.iloc[8].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "2909c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.038461538461538464, 0.1, 0.18461538461538463, 0.2173076923076923, 0.3096153846153846, 0.40384615384615385, 0.5961538461538461, 0.7480769230769231, 0.9403846153846154, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    FPR = compute_FPR(logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "5d1c5816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9197349272349272\n",
      "0.952374107850912\n",
      "0.9580415231534635\n",
      "0.9611721611721612\n"
     ]
    }
   ],
   "source": [
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "22944904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9554002905643064\n",
      "0.9591461078761876\n",
      "0.9598343488194973\n",
      "0.9614771682500767\n"
     ]
    }
   ],
   "source": [
    "# FGSM\n",
    "logit_gaussian3_eps1 = df_fgsm_eps1.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_fgsm_eps2.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_fgsm_eps3.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_fgsm_eps4.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_fgsm_eps1.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_fgsm_eps2.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_fgsm_eps3.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_fgsm_eps4.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6c52f4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5807769077230155\n",
      "0.5773742162410155\n",
      "0.632782332209623\n",
      "0.7217117288651943\n"
     ]
    }
   ],
   "source": [
    "#bim\n",
    "logit_gaussian3_eps1 = df_bim_eps1.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_bim_eps2.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_bim_eps3.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_bim_eps4.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_bim_eps1.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_bim_eps2.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_bim_eps3.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_bim_eps4.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "6302fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3741647241647242\n",
      "0.38417832167832167\n"
     ]
    }
   ],
   "source": [
    "#cw\n",
    "\n",
    "logit_gaussian3_eps1 = df_cw_conf1.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_cw_conf2.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_cw_conf1.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_cw_conf2.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81803d",
   "metadata": {},
   "source": [
    "# Use only coef of var and coef of iqr statistical approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "3588efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "e=[0.99,0.999,0.9999,0.99999,0.99999,0.99999]\n",
    "f=[1.1,1.1,1.011,1.01,1.0,0.999]\n",
    "g=[0.34,0.34,0.34, 0.34, 0.34, 0.34]\n",
    "h=[0.73,0.69,0.67, 0.55, 0.50, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "468ff90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_iqr = df_mnist.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_mnist.iloc[3].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "9a559d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(coefiqr, e, f, coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for  value3, value4 in zip(coefiqr,coefvar): \n",
    "        if value3<e or value3>f:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value4<g or value4>h:\n",
    "                FP +=1\n",
    "\n",
    "    \n",
    "\n",
    "    return (FP/(len(coefiqr)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "56cf5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine only coef of iqr and var\n",
    "def compute_TPR(coefiqr, e, f, coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value3, value4 in zip(coefiqr,coefvar):\n",
    "        if value3<e or value3>f:\n",
    "            TP +=1\n",
    "        else:\n",
    "            if value4<g or value4>h:\n",
    "                TP +=1\n",
    "            else:\n",
    "                FN+=1\n",
    "    \n",
    "    \n",
    "    return (TP/(len(coefiqr)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "972c0eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03653846153846154, 0.06153846153846154, 0.09038461538461538, 0.6153846153846154, 0.8288461538461539, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    FPR = compute_FPR(coef_iqr, t1,t2, coef_var,t3,t4)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "a95312a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9582536382536382\n",
      "0.9584952418715305\n",
      "0.9586681974741678\n",
      "0.9605940934065934\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "cofiqreps1 = df_pgd_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_pgd_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_pgd_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_pgd_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_pgd_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_pgd_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_pgd_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_pgd_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps1, t1,t2, x1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps2, t1,t2, x2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps3, t1,t2, x3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps4, t1,t2, x4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "83ec2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9108005811286131\n",
      "0.9460312595770763\n",
      "0.9557425742574257\n",
      "0.954652543671468\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "cofiqreps1 = df_fgsm_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_fgsm_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_fgsm_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_fgsm_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_fgsm_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_fgsm_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_fgsm_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_fgsm_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps1, t1,t2, x1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps2, t1,t2, x2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps3, t1,t2, x3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps4, t1,t2, x4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "08be0877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5818670351604482\n",
      "0.8267013304786665\n",
      "0.8177271682500766\n",
      "0.8762357197258188\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "cofiqreps1 = df_bim_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_bim_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_bim_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_bim_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_bim_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_bim_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_bim_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_bim_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps1, t1,t2, x1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps2, t1,t2, x2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps3, t1,t2, x3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps4, t1,t2, x4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "a9ef693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5458236208236209\n",
      "0.5458236208236209\n"
     ]
    }
   ],
   "source": [
    "cofiqreps1 = df_cw_conf1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_cw_conf2.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_cw_conf1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_cw_conf2.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps1, t1,t2, x1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(e,f,g,h):\n",
    "    TPR = compute_TPR(cofiqreps2, t1,t2, x2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcfe195",
   "metadata": {},
   "source": [
    "# cascade all statistical detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "1954d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.2,0.29,0.34,0.55,0.77,0.88]\n",
    "b=[1.3,1.3,1.3,1.3,1.3,1.3]\n",
    "c=[0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "d=[0.29,0.23,0.2, 0.15, 0.10, 0.05]\n",
    "e=[0.99,0.999,0.9999,0.99999,0.99999,0.99999]\n",
    "f=[1.1,1.1,1.011,1.01,1.0,0.999]\n",
    "g=[0.34,0.34,0.34, 0.34, 0.34, 0.34]\n",
    "h=[0.73,0.69,0.67, 0.55, 0.50, 0.45]\n",
    "i=[0.20,0.32,0.37,0.40, 0.50, 0.70]\n",
    "j=[1.24,1.34,1.34,1.34,1.34,1.34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "fa91caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h,iqr, i, j): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value8 in zip(meanAb,medianAb,coefiqr,coefvar,iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else:\n",
    "                        if value8<i or value8>j:\n",
    "                            FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "8db372bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanAbsDev = df_mnist.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_mnist.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_mnist.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_mnist.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_mnist.iloc[3].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "f0c320f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05769230769230769, 0.20192307692307693, 0.3, 0.7903846153846154, 0.9365384615384617, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    FPR = compute_FPR(meanAbsDev, t1,t2, medianAbsDev,t3,t4,coef_iqr,t5,t6,coef_var,t7,t8,iqr,t9,t10 )\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "7f70b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, iqr, i,j): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value5 in zip(meanAb,medianAb,coefiqr,coefvar, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    TP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        TP +=1\n",
    "                    else:\n",
    "                        if value5<i or value5>j:\n",
    "                            TP +=1\n",
    "                        else:\n",
    "                            FN+=1\n",
    "    \n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "136c1b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9423076923076923\n",
      "0.9423076923076923\n",
      "0.9423076923076923\n",
      "0.9423076923076923\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_pgd_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_pgd_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_pgd_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_pgd_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_pgd_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_pgd_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_pgd_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_pgd_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_pgd_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_pgd_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_pgd_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_pgd_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_pgd_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_pgd_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_pgd_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_pgd_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_pgd_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_pgd_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_pgd_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_pgd_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,y1,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,y2,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4,cofiqreps3,t5,t6,x3,t7,t8,y3,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4,cofiqreps4,t5,t6,x4,t7,t8,y4,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "f56721fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8969605444257532\n",
      "0.9304934109714986\n",
      "0.9387547600913938\n",
      "0.9345157830217591\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_fgsm_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_fgsm_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_fgsm_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_fgsm_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_fgsm_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_fgsm_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_fgsm_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_fgsm_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_fgsm_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_fgsm_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_fgsm_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_fgsm_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_fgsm_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_fgsm_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_fgsm_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_fgsm_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_fgsm_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_fgsm_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_fgsm_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_fgsm_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,y1,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,y2,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4,cofiqreps3,t5,t6,x3,t7,t8,y3,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4,cofiqreps4,t5,t6,x4,t7,t8,y4,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "4ee44912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6760536619069553\n",
      "0.8406560636182903\n",
      "0.8395475789151089\n",
      "0.8899790555978676\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_bim_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_bim_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_bim_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_bim_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_bim_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_bim_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_bim_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_bim_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_bim_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_bim_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_bim_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_bim_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_bim_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_bim_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_bim_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_bim_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_bim_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_bim_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_bim_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_bim_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,y1,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,y2,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4,cofiqreps3,t5,t6,x3,t7,t8,y3,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4,cofiqreps4,t5,t6,x4,t7,t8,y4,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "6e408bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6577602952602953\n",
      "0.6577602952602953\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_cw_conf1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_cw_conf2.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_cw_conf1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_cw_conf2.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_cw_conf1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_cw_conf2.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_cw_conf1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_cw_conf2.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_cw_conf1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_cw_conf2.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,y1,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10 in zip(a, b, c, d, e,f,g,h,i,j):\n",
    "    TPR = compute_TPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,y2,t9,t10 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8c24c",
   "metadata": {},
   "source": [
    "# combine approach 1 and approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "800a88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#app1\n",
    "a=[16,25,35,45,55,70,100,200,250]\n",
    "b=[370,370,370,370,370,370,370,370,370]\n",
    "\n",
    "c=[0.07,0.07,0.07, 0.07,0.07,0.07,0.07,0.07,0.07]\n",
    "d=[3.3,2.1,1.7,1.5, 1.3, 1.1, 0.7, 0.5, 0.3]\n",
    "e=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]\n",
    "f=[250,150,120, 110, 100, 90, 80, 70, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "c1c00d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezer_input = df_mnist.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_mnist.iloc[12].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_mnist.iloc[8].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "094d2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap1, i, j, ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value5, value6, value7 in zip(ap1,ap2a,ap2b):\n",
    "        if value5<i or value5>j:\n",
    "            FP +=1\n",
    "        else: \n",
    "            if value6<k or value6>l:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value7<m or value7>n:\n",
    "                    FP +=1\n",
    "\n",
    "    return (FP/(len(ap1)))*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "9610a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d, adv3, e, f): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3 in zip(adv1, adv2, adv3): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else:\n",
    "                if value3<e or value3>f:\n",
    "                    TP+=1\n",
    "                else:\n",
    "                    FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "7f409ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05576923076923077, 0.13076923076923078, 0.24807692307692306, 0.3384615384615385, 0.5019230769230769, 0.6865384615384617, 0.9096153846153847, 0.9961538461538462, 1.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fpr_results =[]\n",
    "for t1,t2,t3,t4,t5,t6 in zip(a,b,c,d,e,f):\n",
    "    FPR = compute_FPR(squeezer_input, t1,t2,logit_gaussian3,t3,t4, attr_gaussian3,t5,t6)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "8162cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9442307692307692\n",
      "0.9442307692307692\n",
      "0.9442307692307692\n",
      "0.9442307692307692\n"
     ]
    }
   ],
   "source": [
    "#pgd\n",
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "squeezer_1 = df_pgd_eps1.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_pgd_eps2.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_pgd_eps3.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_pgd_eps4.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_1, t1,t2,logit_gaussian3_eps1, t3,t4, attr_gaussian3_eps1,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_2, t1,t2,logit_gaussian3_eps2, t3,t4, attr_gaussian3_eps2,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_3, t1,t2,logit_gaussian3_eps3, t3,t4, attr_gaussian3_eps3,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_4, t1,t2,logit_gaussian3_eps4, t3,t4, attr_gaussian3_eps4,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "2dd7b13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9442307692307692\n",
      "0.9442307692307692\n",
      "0.9442307692307692\n",
      "0.9442307692307692\n"
     ]
    }
   ],
   "source": [
    "#fgsm\n",
    "squeezer_1 = df_fgsm_eps1.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_fgsm_eps2.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_fgsm_eps3.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_fgsm_eps4.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_fgsm_eps1.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_fgsm_eps2.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_fgsm_eps3.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_fgsm_eps4.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_fgsm_eps1.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_fgsm_eps2.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_fgsm_eps3.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_fgsm_eps4.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_1, t1,t2,logit_gaussian3_eps1, t3,t4, attr_gaussian3_eps1,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_2, t1,t2,logit_gaussian3_eps2, t3,t4, attr_gaussian3_eps2,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_3, t1,t2,logit_gaussian3_eps3, t3,t4, attr_gaussian3_eps3,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_4, t1,t2,logit_gaussian3_eps4, t3,t4, attr_gaussian3_eps4,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "ce09ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8265200368493781\n",
      "0.8580019880715706\n",
      "0.8511032791909285\n",
      "0.7655293221629855\n"
     ]
    }
   ],
   "source": [
    "#bim\n",
    "squeezer_1 = df_bim_eps1.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_bim_eps2.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_bim_eps3.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_bim_eps4.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_bim_eps1.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_bim_eps2.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_bim_eps3.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_bim_eps4.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_bim_eps1.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_bim_eps2.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_bim_eps3.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_bim_eps4.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_1, t1,t2,logit_gaussian3_eps1, t3,t4, attr_gaussian3_eps1,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_2, t1,t2,logit_gaussian3_eps2, t3,t4, attr_gaussian3_eps2,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_3, t1,t2,logit_gaussian3_eps3, t3,t4, attr_gaussian3_eps3,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_4, t1,t2,logit_gaussian3_eps4, t3,t4, attr_gaussian3_eps4,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "86dc61cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8411810411810411\n",
      "0.8507899507899508\n"
     ]
    }
   ],
   "source": [
    "#cw\n",
    "squeezer_1 = df_cw_conf1.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_cw_conf2.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_cw_conf1.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_cw_conf2.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_cw_conf1.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_cw_conf2.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_1, t1,t2,logit_gaussian3_eps1, t3,t4, attr_gaussian3_eps1,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(squeezer_2, t1,t2,logit_gaussian3_eps2, t3,t4, attr_gaussian3_eps2,t5,t6)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae55dfcf",
   "metadata": {},
   "source": [
    "# sanity check combine all detectors: to see if auc is low for approach that has very high fpr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "f6ce3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.1,0.29,0.34,0.55,0.77,0.88]\n",
    "b=[1.1,1.3,1.3,1.3,1.3,1.3]\n",
    "c=[0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "d=[0.39,0.23,0.2, 0.15, 0.10, 0.05]\n",
    "e=[0.99,0.999,0.9999,0.99999,0.99999,0.99999]\n",
    "f=[1.1,1.1,1.011,1.01,1.0,0.999]\n",
    "g=[0.34,0.34,0.34, 0.34, 0.34, 0.34]\n",
    "h=[0.83,0.69,0.67, 0.55, 0.50, 0.45]\n",
    "\n",
    "#app1\n",
    "i=[6,25,35,45,55,70,100,200,250]\n",
    "j=[370,370,370,370,370,370,370,370,370]\n",
    "\n",
    "#app2a:logitgaussian3\n",
    "k=[0.07,0.07,0.07, 0.07,0.07,0.07,0.07,0.07,0.07]\n",
    "l=[4.3,2.1,1.7,1.5, 1.3, 1.1, 0.7, 0.5, 0.3]\n",
    "\n",
    "#app2b:attrgaussian3\n",
    "m=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]\n",
    "n=[350,150,120, 110, 100, 90, 80, 70, 30]\n",
    "\n",
    "#iqr\n",
    "o=[0.20,0.32,0.37,0.40, 0.50, 0.70]\n",
    "p=[1.24,1.34,1.34,1.34,1.34,1.34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "b52256b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanAbsDev = df_mnist.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_mnist.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_mnist.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_mnist.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_mnist.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_mnist.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_mnist.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_mnist.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_FPR(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, ap1, i, j, ap2a, k, l, ap2b, m, n, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value5, value6, value7, value8 in zip(meanAb,medianAb,coefiqr,coefvar,ap1,ap2a,ap2b, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else: \n",
    "                        if value5<i or value5>j:\n",
    "                            FP +=1\n",
    "                        else: \n",
    "                            if value6<k or value6>l:\n",
    "                                FP +=1\n",
    "                            else:\n",
    "                                if value7<m or value7>n:\n",
    "                                    FP +=1\n",
    "                                else:\n",
    "                                    if value8<o or value8>p:\n",
    "                                        FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2bd3185b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8615384615384616, 0.9980769230769231, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    FPR = compute_FPR(meanAbsDev, t1,t2, medianAbsDev,t3,t4,coef_iqr,t5,t6,coef_var,t7,t8,squeezer_input,t9,t10,\n",
    "                    logit_gaussian3,t11,t12,attr_gaussian3,t13,t14,iqr,t15,t16 )\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "ad7a8c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1384615384615384\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_pgd_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_pgd_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_pgd_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_pgd_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_pgd_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_pgd_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_pgd_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_pgd_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_pgd_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_pgd_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_pgd_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_pgd_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_pgd_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_pgd_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_pgd_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_pgd_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_pgd_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_pgd_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_pgd_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_pgd_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "squeezer_1 = df_pgd_eps1.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_pgd_eps2.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_pgd_eps3.iloc[7].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_pgd_eps4.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[12].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[8].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,\n",
    "                      squeezer_1,t9,t10,\n",
    "                    logit_gaussian3_eps1,t11,t12,attr_gaussian3_eps1,t13,t14,y1,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121af24",
   "metadata": {},
   "source": [
    "Yes, it works! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a3ba6",
   "metadata": {},
   "source": [
    "# ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "31f03c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgd with five epsilons\n",
    "df_pgd_eps1 = pd.read_csv('imagenet/pgd/eps8_255.csv')\n",
    "df_pgd_eps2 = pd.read_csv('imagenet/pgd/eps16_255.csv')\n",
    "df_pgd_eps3 = pd.read_csv('imagenet/pgd/eps32_255.csv')\n",
    "df_pgd_eps4 = pd.read_csv('imagenet/pgd/eps64_255.csv')\n",
    "\n",
    "\n",
    "#fgsm with five epsilons\n",
    "df_fgsm_eps1 = pd.read_csv('imagenet/fgsm/eps8_255.csv')\n",
    "df_fgsm_eps2 = pd.read_csv('imagenet/fgsm/eps16_255.csv')\n",
    "df_fgsm_eps3 = pd.read_csv('imagenet/fgsm/eps32_255.csv')\n",
    "df_fgsm_eps4 = pd.read_csv('imagenet/fgsm/eps64_255.csv')\n",
    "\n",
    "#bim with five epsilons\n",
    "df_bim_eps1 = pd.read_csv('imagenet/bim/eps8_255.csv')\n",
    "df_bim_eps2 = pd.read_csv('imagenet/bim/eps16_255.csv')\n",
    "df_bim_eps3 = pd.read_csv('imagenet/bim/eps32_255.csv')\n",
    "df_bim_eps4 = pd.read_csv('imagenet/bim/eps64_255.csv')\n",
    "\n",
    "#cw with four confidences\n",
    "df_cw_conf1 = pd.read_csv('imagenet/cw/conf_0.csv')\n",
    "df_cw_conf2 = pd.read_csv('imagenet/cw/conf_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "c1a13f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imagenet = pd.read_csv(\"Benign_IMAGENET_Metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "f128567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_gaussian3 = df_imagenet.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_imagenet.iloc[10].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "c30d870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap2a, a, b, ap2b, c, d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<a or value6>b:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<c or value7>d:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "0d0ad1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2 in zip(adv1, adv2): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else: \n",
    "                FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "eab48bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1810,2510,2810,3000, 3200,3500, 6000]\n",
    "b=[6700,6700,6700,6700,6700,6700, 6700]\n",
    "c=[1400,1750,1900, 2300, 3200, 3500, 6000]\n",
    "d=[6600,6600,6600,6600,6600,6600,6600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "8520475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06274509803921569, 0.20784313725490197, 0.296078431372549, 0.5372549019607843, 0.8666666666666667, 0.9215686274509803, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    FPR = compute_FPR(logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "f8ee568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5668780086885054\n",
      "0.6391432820633244\n",
      "0.7857677464624021\n",
      "0.8736444080614353\n"
     ]
    }
   ],
   "source": [
    "#pgd\n",
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "4837859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8163696369636964\n",
      "0.8907632635559194\n",
      "0.9321292405851229\n",
      "0.9371109554933085\n"
     ]
    }
   ],
   "source": [
    "# FGSM\n",
    "logit_gaussian3_eps1 = df_fgsm_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_fgsm_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_fgsm_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_fgsm_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_fgsm_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_fgsm_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_fgsm_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_fgsm_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "1c7f6039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541485760971055\n",
      "0.5514324292591288\n",
      "0.6092814371257486\n",
      "0.8370316443409047\n"
     ]
    }
   ],
   "source": [
    "#bim\n",
    "logit_gaussian3_eps1 = df_bim_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_bim_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_bim_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_bim_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_bim_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_bim_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_bim_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_bim_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "30f951e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5011694538650451\n",
      "0.5072174794371028\n"
     ]
    }
   ],
   "source": [
    "#cw\n",
    "\n",
    "logit_gaussian3_eps1 = df_cw_conf1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_cw_conf2.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_cw_conf1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_cw_conf2.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4 in zip(a,b,c,d):\n",
    "    TPR = compute_TPR(logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2dfc9",
   "metadata": {},
   "source": [
    "# combine 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "2707ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=[1300,1800,2000,2800,3600,4500,5000]\n",
    "j=[5700,5700,5700,5700,5700,5700,5700]\n",
    "k=[1810,2510,2810,3000, 3200,3500, 6000]\n",
    "l=[6700,6700,6700,6700,6700,6700, 6700]\n",
    "m=[1400,1750,1900, 2300, 3200, 3500, 6000]\n",
    "n=[6600,6600,6600,6600,6600,6600,6600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "f23057d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using approach 1 and 2 only\n",
    "squeezer_input = df_imagenet.iloc[6].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_imagenet.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_imagenet.iloc[10].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "62807875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap1, i, j, ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value5, value6, value7 in zip(ap1,ap2a,ap2b):\n",
    "        if value5<i or value5>j:\n",
    "            FP +=1\n",
    "        else: \n",
    "            if value6<k or value6>l:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value7<m or value7>n:\n",
    "                    FP +=1\n",
    "\n",
    "    return (FP/(len(ap1)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "cea0e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d, adv3, e, f): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3 in zip(adv1, adv2, adv3): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else:\n",
    "                if value3<e or value3>f:\n",
    "                    TP+=1\n",
    "                else:\n",
    "                    FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "367df34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07647058823529412, 0.23725490196078428, 0.34509803921568627, 0.7431372549019608, 0.9588235294117647, 0.9921568627450981, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    FPR = compute_FPR(squeezer_input,t0, t00, logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "6c67cc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5459766741027748\n",
      "0.60213103205354\n",
      "0.7524110240517677\n",
      "0.8536408996998401\n"
     ]
    }
   ],
   "source": [
    "#pgd\n",
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "squeezer_1 = df_pgd_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_pgd_eps2.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_pgd_eps3.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_pgd_eps4.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_1,t0, t00, logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_2,t0, t00, logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_3,t0, t00, logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_4,t0, t00, logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "9c32ff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7902795573675014\n",
      "0.8750984290336413\n",
      "0.9183181605975723\n",
      "0.9233699035169624\n"
     ]
    }
   ],
   "source": [
    "#fgsm\n",
    "squeezer_1 = df_fgsm_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_fgsm_eps2.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_fgsm_eps3.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_fgsm_eps4.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_fgsm_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_fgsm_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_fgsm_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_fgsm_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_fgsm_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_fgsm_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_fgsm_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_fgsm_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_1,t0, t00, logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_2,t0, t00, logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_3,t0, t00, logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_4,t0, t00, logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "98861ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5326272175536882\n",
      "0.5412234354819773\n",
      "0.5749618410238346\n",
      "0.8248611920015531\n"
     ]
    }
   ],
   "source": [
    "#bim\n",
    "squeezer_1 = df_bim_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_bim_eps2.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_bim_eps3.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_bim_eps4.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_bim_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_bim_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_bim_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_bim_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_bim_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_bim_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_bim_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_bim_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_1,t0, t00, logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_2,t0, t00, logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_3,t0, t00, logit_gaussian3_eps3, t1,t2, attr_gaussian3_eps3,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_4,t0, t00, logit_gaussian3_eps4, t1,t2, attr_gaussian3_eps4,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "343b6807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48875959926714224\n",
      "0.48342104237321165\n"
     ]
    }
   ],
   "source": [
    "#cw\n",
    "squeezer_1 = df_cw_conf1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_cw_conf2.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_cw_conf1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_cw_conf2.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_cw_conf1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_cw_conf2.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_1,t0, t00, logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t0,t00,t1,t2,t3,t4 in zip(i,j,k,l,m,n):\n",
    "    TPR = compute_TPR(squeezer_2,t0, t00, logit_gaussian3_eps2, t1,t2, attr_gaussian3_eps2,t3,t4)\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5fd7d5",
   "metadata": {},
   "source": [
    "# combine all detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "166a2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, ap1, i, j, ap2a, k, l, ap2b, m, n, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value5, value6, value7, value8 in zip(meanAb,medianAb,coefiqr,coefvar,ap1,ap2a,ap2b, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else: \n",
    "                        if value5<i or value5>j:\n",
    "                            FP +=1\n",
    "                        else: \n",
    "                            if value6<k or value6>l:\n",
    "                                FP +=1\n",
    "                            else:\n",
    "                                if value7<m or value7>n:\n",
    "                                    FP +=1\n",
    "                                else:\n",
    "                                    if value8<o or value8>p:\n",
    "                                        FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "f35cc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, ap1, i, j, ap2a, k, l, ap2b, m, n, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value5, value6, value7, value8 in zip(meanAb,medianAb,coefiqr,coefvar,ap1,ap2a,ap2b, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    TP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        TP +=1\n",
    "                    else: \n",
    "                        if value5<i or value5>j:\n",
    "                            TP +=1\n",
    "                        else: \n",
    "                            if value6<k or value6>l:\n",
    "                                TP +=1\n",
    "                            else:\n",
    "                                if value7<m or value7>n:\n",
    "                                    TP +=1\n",
    "                                else:\n",
    "                                    if value8<o or value8>p:\n",
    "                                        TP +=1\n",
    "                                    else:\n",
    "                                        FN+=1\n",
    "    \n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "62221b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanAbsDev = df_imagenet.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_imagenet.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_imagenet.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_imagenet.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_imagenet.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_imagenet.iloc[6].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_imagenet.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_imagenet.iloc[10].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "bdd3b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.015,0.019,0.022,0.33,0.35,0.37,0.40]\n",
    "b=[0.11,0.11,0.11,0.11,0.11,0.11,0.11]\n",
    "c=[0.008,0.01,0.0115,0.015,0.025,0.030,0.035]\n",
    "d=[0.055,0.055,0.055,0.055,0.055,0.055,0.055]\n",
    "e=[0.49,0.516,0.5257,0.54,0.55,0.60,0.65]\n",
    "f=[0.74,0.74,0.74,0.74,0.74,0.74,0.74]\n",
    "g=[0.38,0.38,0.38,0.38,0.38,0.38,0.38]\n",
    "h=[1.14,1.09,1.07,1.0,0.9,0.8,0.7]\n",
    "\n",
    "\n",
    "i=[1300,1800,2000,2800,3600,4500,48000]\n",
    "j=[5700,5700,5700,5700,5700,5700,5700]\n",
    "\n",
    "k=[1810,2510,2810,3000, 3200,3500, 4000]\n",
    "l=[6700,6700,6700,6700,6700,6700, 6700]\n",
    "\n",
    "m=[1400,1750,1900, 2300, 3200, 3500, 6000]\n",
    "n=[6600,6600,6600,6600,6600,6600,6600]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[0.019,0.024,0.027,0.03,0.04,0.05,0.06]\n",
    "p=[0.13,0.13,0.13,0.13,0.13,0.13,0.13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "86114598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09019607843137255, 0.28627450980392155, 0.42745098039215684, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "fpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    FPR = compute_FPR(meanAbsDev, t1,t2, medianAbsDev,t3,t4,coef_iqr,t5,t6,coef_var,t7,t8,squeezer_input,t9,t10,\n",
    "                    logit_gaussian3,t11,t12,attr_gaussian3,t13,t14,iqr,t15,t16 )\n",
    "    fpr_results.append(FPR/100)\n",
    "print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "64c058ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5527454894133302\n",
      "0.6171734961449649\n",
      "0.7777647838459439\n",
      "0.8651775620785094\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_pgd_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_pgd_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_pgd_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_pgd_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_pgd_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_pgd_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_pgd_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_pgd_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_pgd_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_pgd_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_pgd_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_pgd_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_pgd_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_pgd_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_pgd_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_pgd_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_pgd_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_pgd_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_pgd_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_pgd_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "squeezer_1 = df_pgd_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_pgd_eps2.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_pgd_eps3.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_pgd_eps4.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_pgd_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_pgd_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_pgd_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_pgd_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_pgd_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_pgd_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_pgd_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_pgd_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,\n",
    "                      squeezer_1,t9,t10,\n",
    "                    logit_gaussian3_eps1,t11,t12,attr_gaussian3_eps1,t13,t14,y1,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,\n",
    "                      squeezer_2,t9,t10,\n",
    "                    logit_gaussian3_eps2,t11,t12,attr_gaussian3_eps2,t13,t14,y2,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4,cofiqreps3,t5,t6,x3,t7,t8,\n",
    "                      squeezer_3,t9,t10,\n",
    "                    logit_gaussian3_eps3,t11,t12,attr_gaussian3_eps3,t13,t14,y3,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4,cofiqreps4,t5,t6,x4,t7,t8,\n",
    "                      squeezer_4,t9,t10,\n",
    "                    logit_gaussian3_eps4,t11,t12,attr_gaussian3_eps4,t13,t14,y4,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "b8d80a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8068802174335081\n",
      "0.884832183370366\n",
      "0.9078586990351696\n",
      "0.9098039215686273\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev_eps1 = df_fgsm_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_fgsm_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_fgsm_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_fgsm_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_fgsm_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_fgsm_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_fgsm_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_fgsm_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_fgsm_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_fgsm_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_fgsm_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_fgsm_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_fgsm_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_fgsm_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_fgsm_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_fgsm_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "y1 = df_fgsm_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_fgsm_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_fgsm_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_fgsm_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "squeezer_1 = df_fgsm_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_fgsm_eps2.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_fgsm_eps3.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_fgsm_eps4.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_fgsm_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_fgsm_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_fgsm_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_fgsm_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_fgsm_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_fgsm_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_fgsm_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_fgsm_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,\n",
    "                      squeezer_1,t9,t10,\n",
    "                    logit_gaussian3_eps1,t11,t12,attr_gaussian3_eps1,t13,t14,y1,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,\n",
    "                      squeezer_2,t9,t10,\n",
    "                    logit_gaussian3_eps2,t11,t12,attr_gaussian3_eps2,t13,t14,y2,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4,cofiqreps3,t5,t6,x3,t7,t8,\n",
    "                      squeezer_3,t9,t10,\n",
    "                    logit_gaussian3_eps3,t11,t12,attr_gaussian3_eps3,t13,t14,y3,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4,cofiqreps4,t5,t6,x4,t7,t8,\n",
    "                      squeezer_4,t9,t10,\n",
    "                    logit_gaussian3_eps4,t11,t12,attr_gaussian3_eps4,t13,t14,y4,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "5b2e13a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "0.6063559156197409\n",
      "0.6648272083284411\n",
      "0.8392079207920792\n"
     ]
    }
   ],
   "source": [
    "squeezer_1 = df_bim_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_bim_eps2.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_3 = df_bim_eps3.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_4 = df_bim_eps4.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_bim_eps1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_bim_eps2.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps3 = df_bim_eps3.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps4 = df_bim_eps4.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_bim_eps1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_bim_eps2.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps3 = df_bim_eps3.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps4 = df_bim_eps4.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "meanAbsDev_eps1 = df_bim_eps1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_bim_eps2.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps3 = df_bim_eps3.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps4 = df_bim_eps4.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_bim_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_bim_eps2.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps3 = df_bim_eps3.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps4 = df_bim_eps4.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_bim_eps1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_bim_eps2.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps3 = df_bim_eps3.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps4 = df_bim_eps4.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_bim_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_bim_eps2.iloc[3].values.flatten().tolist()[1:]\n",
    "x3 = df_bim_eps3.iloc[3].values.flatten().tolist()[1:]\n",
    "x4 = df_bim_eps4.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_bim_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_bim_eps2.iloc[2].values.flatten().tolist()[1:]\n",
    "y3 = df_bim_eps3.iloc[2].values.flatten().tolist()[1:]\n",
    "y4 = df_bim_eps4.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,\n",
    "                      squeezer_1,t9,t10,\n",
    "                    logit_gaussian3_eps1,t11,t12,attr_gaussian3_eps1,t13,t14,y1,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,\n",
    "                      squeezer_2,t9,t10,\n",
    "                    logit_gaussian3_eps2,t11,t12,attr_gaussian3_eps2,t13,t14,y2,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps3, t1,t2, medianAbsDev_eps3,t3,t4,cofiqreps3,t5,t6,x3,t7,t8,\n",
    "                      squeezer_3,t9,t10,\n",
    "                    logit_gaussian3_eps3,t11,t12,attr_gaussian3_eps3,t13,t14,y3,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps4, t1,t2, medianAbsDev_eps4,t3,t4,cofiqreps4,t5,t6,x4,t7,t8,\n",
    "                      squeezer_4,t9,t10,\n",
    "                    logit_gaussian3_eps4,t11,t12,attr_gaussian3_eps4,t13,t14,y4,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "0702ca8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5500175418079756\n",
      "0.5337387440065489\n"
     ]
    }
   ],
   "source": [
    "squeezer_1 = df_cw_conf1.iloc[6].values.flatten().tolist()[1:]\n",
    "squeezer_2 = df_cw_conf2.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3_eps1 = df_cw_conf1.iloc[14].values.flatten().tolist()[1:]\n",
    "logit_gaussian3_eps2 = df_cw_conf2.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "attr_gaussian3_eps1 = df_cw_conf1.iloc[10].values.flatten().tolist()[1:]\n",
    "attr_gaussian3_eps2 = df_cw_conf2.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "meanAbsDev_eps1 = df_cw_conf1.iloc[1].values.flatten().tolist()[1:]\n",
    "meanAbsDev_eps2 = df_cw_conf2.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps1 = df_cw_conf1.iloc[0].values.flatten().tolist()[1:]\n",
    "medianAbsDev_eps2 = df_cw_conf2.iloc[0].values.flatten().tolist()[1:]\n",
    "cofiqreps1 = df_cw_conf1.iloc[4].values.flatten().tolist()[1:]\n",
    "cofiqreps2 = df_cw_conf2.iloc[4].values.flatten().tolist()[1:]\n",
    "x1 = df_cw_conf1.iloc[3].values.flatten().tolist()[1:]\n",
    "x2 = df_cw_conf2.iloc[3].values.flatten().tolist()[1:]\n",
    "y1 = df_cw_conf1.iloc[2].values.flatten().tolist()[1:]\n",
    "y2 = df_cw_conf2.iloc[2].values.flatten().tolist()[1:]\n",
    "\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps1, t1,t2, medianAbsDev_eps1,t3,t4,cofiqreps1,t5,t6,x1,t7,t8,\n",
    "                      squeezer_1,t9,t10,\n",
    "                    logit_gaussian3_eps1,t11,t12,attr_gaussian3_eps1,t13,t14,y1,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))\n",
    "tpr_results =[]\n",
    "for t1,t2,t3,t4,t5, t6, t7,t8,t9,t10,t11,t12,t13,t14,t15,t16 in zip(a, b, c, d, e,f,g,h,i,j,k,l,m,n,o,p):\n",
    "    TPR = compute_FPR(meanAbsDev_eps2, t1,t2, medianAbsDev_eps2,t3,t4,cofiqreps2,t5,t6,x2,t7,t8,\n",
    "                      squeezer_2,t9,t10,\n",
    "                    logit_gaussian3_eps2,t11,t12,attr_gaussian3_eps2,t13,t14,y2,t15,t16 )\n",
    "    tpr_results.append(TPR/100)\n",
    "print(sklearn.metrics.auc(fpr_results, tpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b59c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
