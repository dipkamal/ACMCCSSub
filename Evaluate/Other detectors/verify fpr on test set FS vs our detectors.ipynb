{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f7555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6768abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_dist = lambda x1,x2: np.sum(np.abs(x1 - x2), axis=tuple(range(len(x1.shape))[1:]))\n",
    "l2_dist = lambda x1,x2: np.sum((x1-x2)**2, axis=tuple(range(len(x1.shape))[1:]))**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d9b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: KL-divergence is not symentric.\n",
    "# Designed for probability distribution (e.g. softmax output).\n",
    "def kl(x1, x2):\n",
    "    assert x1.shape == x2.shape\n",
    "    # x1_2d, x2_2d = reshape_2d(x1), reshape_2d(x2)\n",
    "\n",
    "    # Transpose to [?, #num_examples]\n",
    "    x1_2d_t = x1.transpose()\n",
    "    x2_2d_t = x2.transpose()\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    e = entropy(x1_2d_t, x2_2d_t)\n",
    "    e[np.where(e==np.inf)] = 2\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b7033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_precision_py(x, npp):\n",
    "    \"\"\"\n",
    "    Reduce the precision of image, the numpy version.\n",
    "    :param x: a float tensor, which has been scaled to [0, 1].\n",
    "    :param npp: number of possible values per pixel. E.g. it's 256 for 8-bit gray-scale image, and 2 for binarized image.\n",
    "    :return: a tensor representing image(s) with lower precision.\n",
    "    \"\"\"\n",
    "    # Note: 0 is a possible value too.\n",
    "    npp_int = npp - 1\n",
    "    x_int = np.rint(x * npp_int)\n",
    "    x_float = x_int / npp_int\n",
    "    return x_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b62c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter_py(x, width, height=-1):\n",
    "    \"\"\"\n",
    "    Median smoothing by Scipy.\n",
    "    :param x: a tensor of image(s)\n",
    "    :param width: the width of the sliding window (number of pixels)\n",
    "    :param height: the height of the window. The same as width by default.\n",
    "    :return: a modified tensor with the same shape as x.\n",
    "    \"\"\"\n",
    "    if height == -1:\n",
    "        height = width\n",
    "    var = ndimage.filters.median_filter(x, size=(1,width,height,1), mode='reflect')\n",
    "    #print(\"inside median filter\")\n",
    "    #print(type(var))\n",
    "    return torch.from_numpy(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ed14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeezers implemented in OpenCV\n",
    "# OpenCV expects uint8 as image data type.\n",
    "def opencv_wrapper(imgs, opencv_func, argv):\n",
    "    ret_imgs = []\n",
    "    imgs_copy = imgs\n",
    "\n",
    "    if imgs.shape[3] == 1:\n",
    "        imgs_copy = np.squeeze(imgs)\n",
    "\n",
    "    for img in imgs_copy:\n",
    "        img_uint8 = np.clip(np.rint(img * 255), 0, 255).astype(np.uint8)\n",
    "        ret_img = opencv_func(*[img_uint8]+argv)\n",
    "        if type(ret_img) == tuple:\n",
    "            ret_img = ret_img[1]\n",
    "        ret_img = ret_img.astype(np.float32) / 255.\n",
    "        ret_imgs.append(ret_img)\n",
    "    ret_imgs = np.stack(ret_imgs)\n",
    "\n",
    "    if imgs.shape[3] == 1:\n",
    "        ret_imgs = np.expand_dims(ret_imgs, axis=3)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75852df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_depth_py(x, bits):\n",
    "    precisions = 2**bits\n",
    "    return reduce_precision_py(x, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "356d2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_local_means_color_py(imgs, search_window, block_size, photo_render):\n",
    "    import cv2\n",
    "    ret_imgs = opencv_wrapper(imgs, cv2.fastNlMeansDenoisingColored, [None,photo_render,photo_render,block_size,search_window])\n",
    "    return ret_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37e8420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e541e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(model, dataset, X1):\n",
    "    #X1_pred = model.predict(X1)\n",
    "    X1_pred = m(model(X1))\n",
    "    vals_squeezed = []\n",
    "\n",
    "    if dataset == 'mnist':\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.cpu(), 1)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        \n",
    "        #model.predict is tf based. need torch based softmax. \n",
    "        #vals_squeezed.append(model.predict(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.cpu(), 2)\n",
    "        #print((\"outside func\",type(X1_seqeezed_filter_median)))\n",
    "        vals_squeezed.append(m(model(X1_seqeezed_filter_median.to(device))))\n",
    "\n",
    "    else:\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.cpu(), 5)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.cpu(), 2)\n",
    "        #vals_squeezed.append(model(torch.from_numpy(X1_seqeezed_filter_median).float().to(device)))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_filter_median).to(device))))\n",
    "        #X1_seqeezed_filter_local = non_local_means_color_py(X1.cpu().numpy(), 13, 3, 2)\n",
    "        #vals_squeezed.append(m(model((X1_seqeezed_filter_local).to(device))))\n",
    "\n",
    "    dist_array = []\n",
    "    for val_squeezed in vals_squeezed:\n",
    "        dist = np.sum(np.abs(X1_pred.cpu().detach().numpy() - val_squeezed.cpu().detach().numpy()), axis=tuple(range(len(X1_pred.shape))[1:]))\n",
    "        dist_array.append(dist)\n",
    "\n",
    "    dist_array = np.array(dist_array)\n",
    "    return np.max(dist_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60d78008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_test(model, dataset, X1):\n",
    "    #X1_pred = model.predict(X1)\n",
    "    X1_pred = m(model(X1))\n",
    "    vals_squeezed = []\n",
    "\n",
    "    if dataset == 'mnist':\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.detach().cpu(), 1)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        \n",
    "        #model.predict is tf based. need torch based softmax. \n",
    "        #vals_squeezed.append(model.predict(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.detach().cpu(), 2)\n",
    "        #print((\"outside func\",type(X1_seqeezed_filter_median)))\n",
    "        vals_squeezed.append(m(model(X1_seqeezed_filter_median.to(device))))\n",
    "\n",
    "    else:\n",
    "        X1_seqeezed_bit = bit_depth_py(X1.detach().cpu(), 5)\n",
    "        #print(type(X1_seqeezed_bit))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_bit).to(device))))\n",
    "        X1_seqeezed_filter_median = median_filter_py(X1.detach().cpu(), 2)\n",
    "        #vals_squeezed.append(model(torch.from_numpy(X1_seqeezed_filter_median).float().to(device)))\n",
    "        vals_squeezed.append(m(model((X1_seqeezed_filter_median).to(device))))\n",
    "        #X1_seqeezed_filter_local = non_local_means_color_py(X1.cpu().numpy(), 13, 3, 2)\n",
    "        #vals_squeezed.append(m(model((X1_seqeezed_filter_local).to(device))))\n",
    "\n",
    "    dist_array = []\n",
    "    for val_squeezed in vals_squeezed:\n",
    "        dist = np.sum(np.abs(X1_pred.cpu().detach().numpy() - val_squeezed.cpu().detach().numpy()), axis=tuple(range(len(X1_pred.shape))[1:]))\n",
    "        dist_array.append(dist)\n",
    "\n",
    "    dist_array = np.array(dist_array)\n",
    "    return np.max(dist_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d8e8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_test(model, dataset, X):\n",
    "    distances = get_distance_test(model, dataset, X)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e085c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent,\n",
    ")\n",
    "import gc\n",
    "from captum.attr import *\n",
    "import quantus\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torchvision.transforms as transforms\n",
    "from quantus.functions.perturb_func import baseline_replacement_by_indices\n",
    "from art.attacks.evasion import CarliniLInfMethod\n",
    "import torch.optim as optim\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import BasicIterativeMethod\n",
    "from art.attacks.evasion import SaliencyMapMethod\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab29f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b95c4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Sequence, Tuple, Union, List\n",
    "\n",
    "def infer_attribution_axes(a_batch: np.ndarray, x_batch: np.ndarray)-> Sequence[int]:\n",
    "    \"\"\"\n",
    "    Reference: quantus library\n",
    "    Infers the axes in x_batch that are covered by a_batch.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_batch: np.ndarray\n",
    "        A np.ndarray which contains the input data that are explained.\n",
    "    a_batch: np.ndarray\n",
    "        An array which contains pre-computed attributions i.e., explanations.\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The axes inferred.\n",
    "    \"\"\"\n",
    "    # TODO: Adapt for batched processing.\n",
    "\n",
    "    if a_batch.shape[0] != x_batch.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"a_batch and x_batch must have same number of batches ({a_batch.shape[0]} != {x_batch.shape[0]})\"\n",
    "        )\n",
    "\n",
    "    if a_batch.ndim > x_batch.ndim:\n",
    "        raise ValueError(\n",
    "            \"Attributions need to have <= dimensions than inputs, but {} > {}\".format(\n",
    "                a_batch.ndim, x_batch.ndim\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # TODO: We currently assume here that the batch axis is not carried into the perturbation functions.\n",
    "    a_shape = [s for s in np.shape(a_batch)[1:] if s != 1]\n",
    "    x_shape = [s for s in np.shape(x_batch)[1:]]\n",
    "\n",
    "    if a_shape == x_shape:\n",
    "        return np.arange(0, len(x_shape))\n",
    "\n",
    "    # One attribution value per sample\n",
    "    if len(a_shape) == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    x_subshapes = [\n",
    "        [x_shape[i] for i in range(start, start + len(a_shape))]\n",
    "        for start in range(0, len(x_shape) - len(a_shape) + 1)\n",
    "    ]\n",
    "    if x_subshapes.count(a_shape) < 1:\n",
    "\n",
    "        # Check that attribution dimensions are (consecutive) subdimensions of inputs\n",
    "        raise ValueError(\n",
    "            \"Attribution dimensions are not (consecutive) subdimensions of inputs:  \"\n",
    "            \"inputs were of shape {} and attributions of shape {}\".format(\n",
    "                x_batch.shape, a_batch.shape\n",
    "            )\n",
    "        )\n",
    "    elif x_subshapes.count(a_shape) > 1:\n",
    "\n",
    "        # Check that attribution dimensions are (unique) subdimensions of inputs.\n",
    "        # Consider potentially expanded dims in attributions.\n",
    "\n",
    "        if a_batch.ndim == x_batch.ndim and len(a_shape) < a_batch.ndim:\n",
    "            a_subshapes = [\n",
    "                [np.shape(a_batch)[1:][i] for i in range(start, start + len(a_shape))]\n",
    "                for start in range(0, len(np.shape(a_batch)[1:]) - len(a_shape) + 1)\n",
    "            ]\n",
    "            if a_subshapes.count(a_shape) == 1:\n",
    "\n",
    "                # Inferring channel shape.\n",
    "                for dim in range(len(np.shape(a_batch)[1:]) + 1):\n",
    "                    if a_shape == np.shape(a_batch)[1:][dim:]:\n",
    "                        return np.arange(dim, len(np.shape(a_batch)[1:]))\n",
    "                    if a_shape == np.shape(a_batch)[1:][:dim]:\n",
    "                        return np.arange(0, dim)\n",
    "\n",
    "            raise ValueError(\n",
    "                \"Attribution axes could not be inferred for inputs of \"\n",
    "                \"shape {} and attributions of shape {}\".format(\n",
    "                    x_batch.shape, a_batch.shape\n",
    "                )\n",
    "            )\n",
    "\n",
    "        raise ValueError(\n",
    "            \"Attribution dimensions are not unique subdimensions of inputs:  \"\n",
    "            \"inputs were of shape {} and attributions of shape {}.\"\n",
    "            \"Please expand attribution dimensions for a unique solution\".format(\n",
    "                x_batch.shape, a_batch.shape\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        # Infer attribution axes.\n",
    "        for dim in range(len(x_shape) + 1):\n",
    "            if a_shape == x_shape[dim:]:\n",
    "                return np.arange(dim, len(x_shape))\n",
    "            if a_shape == x_shape[:dim]:\n",
    "                return np.arange(0, dim)\n",
    "\n",
    "    raise ValueError(\n",
    "        \"Attribution axes could not be inferred for inputs of \"\n",
    "        \"shape {} and attributions of shape {}\".format(x_batch.shape, a_batch.shape)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0d8a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_x_based_on_attribution(x_batch, a_batch_benign, d_type, top_k = 100):\n",
    "    #get attribution axes\n",
    "    a_axes = infer_attribution_axes(a_batch_benign, x_batch)\n",
    "    perturbed_arr = []\n",
    "\n",
    "    #modify each sample one-by-one\n",
    "    for x,a in zip(x_batch, a_batch_benign):\n",
    "        #flatten the attribution \n",
    "        a = a.flatten()\n",
    "        #get indices of sorted attributions (ascending)\n",
    "        a_ind = np.argsort(a)\n",
    "        #get indices of top_k \n",
    "        a_ix = a_ind[-top_k:]\n",
    "        if d_type==\"adv\":\n",
    "            x = x.cpu()\n",
    "            x_perturbed = baseline_replacement_by_indices(arr = x.detach().numpy(), indices = a_ix, indexed_axes = a_axes, perturb_baseline = \"black\")\n",
    "            if (x.detach().numpy().flatten() != x_perturbed.flatten()).any():\n",
    "                perturbed_arr.append(torch.from_numpy(x_perturbed))\n",
    "    \n",
    "        else:\n",
    "            x_perturbed = baseline_replacement_by_indices(arr = x.cpu().numpy(), indices = a_ix, indexed_axes = a_axes, perturb_baseline = \"black\")\n",
    "            if (x.cpu().numpy().flatten() != x_perturbed.flatten()).any():\n",
    "                perturbed_arr.append(torch.from_numpy(x_perturbed))\n",
    "    \n",
    "    new_batch = torch.stack(perturbed_arr)\n",
    "    return new_batch.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41d995f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(x_batch, y_batch, spread):\n",
    "    new_x_batch = []\n",
    "    for x in x_batch:\n",
    "        x = x.data.cpu().numpy()\n",
    "        stdev = spread * (np.max(x)-np.min(x))\n",
    "        noise = np.random.normal(0, stdev, x.shape).astype(np.float32)\n",
    "        x_plus_noise = x + noise\n",
    "        x_plus_noise = np.clip(x_plus_noise, 0, 1)\n",
    "        x_plus_noise = torch.from_numpy(x_plus_noise).cpu()\n",
    "        new_x_batch.append(x_plus_noise)\n",
    "    new_batch = torch.stack(new_x_batch).to(device)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2af11c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define uniform noise function\n",
    "def add_uniform_noise(image):\n",
    "    # Generate uniform noise with mean 0 and standard deviation 25\n",
    "    noise = np.random.uniform(low=-0.5, high=0.5, size=image.shape).astype(np.float32)\n",
    "    noisy_image = np.clip(image + noise, 0, 1).astype(np.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "def uniform_noise(x_batch, y_batch): \n",
    "    # Convert batch of images to numpy array\n",
    "    images = x_batch.detach().cpu().numpy().transpose(0, 2, 3, 1) * 1.0\n",
    "    # Add Poisson noise to each image in the batch\n",
    "    noisy_images = [add_uniform_noise(image) for image in images]\n",
    "    # Convert noisy images back to Tensor format\n",
    "    noisy_inputs = torch.from_numpy(np.array(noisy_images).transpose(0, 3, 1, 2) / 1.0).float()\n",
    "    return noisy_inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9319b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_abs_dev(attr): \n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        avg = np.mean(a)\n",
    "        deviation = a - avg \n",
    "        absolute_deviation = np.abs(deviation)\n",
    "        result = np.mean(absolute_deviation)\n",
    "        scores.append(result)\n",
    "    return scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5abc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_median_abs_dev(attr): \n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        med = np.median(a)\n",
    "        deviation = a - med \n",
    "        abs_deviation = np.abs(deviation)\n",
    "        result = np.median(abs_deviation)\n",
    "        scores.append(result)\n",
    "    return scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cee98ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iqr(attr):\n",
    "    #inter-quartile range\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        score_qt = score_75 - score_25\n",
    "        scores.append(score_qt)\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6874f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative measure of dispersion\n",
    "def compute_coef_var(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        m = np.mean(a)\n",
    "        st = np.std(attr[i])\n",
    "        sc = m/st\n",
    "        scores.append(sc)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfb8c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative measure of dispersion\n",
    "\n",
    "## Coefficient of quartile dev\n",
    "\n",
    "def compute_coef_iqr(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        score_qt = (score_75 - score_25)/(score_75 + score_25)\n",
    "        scores.append(score_qt)\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98db4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_attack(x_batch, y_batch, eps, normal_model): \n",
    "    \n",
    "    alpha = eps/10\n",
    "    steps = int(alpha*eps)\n",
    "    images_pgd = projected_gradient_descent(normal_model, x_batch, eps, alpha, steps, np.inf)\n",
    "    _, y_pred_pgd = normal_model(images_pgd).max(1)\n",
    "    index = (y_pred_pgd != y_batch)\n",
    "    pgd_images = images_pgd[index]\n",
    "    y_pred_pgd = y_pred_pgd[index]\n",
    "    return pgd_images, y_pred_pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52976675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fgsm_attack(x_batch, y_batch, eps, normal_model): \n",
    "    \n",
    "    images_pgd = fast_gradient_method(normal_model, x_batch, eps, np.inf)\n",
    "    _, y_pred_pgd = normal_model(images_pgd).max(1)\n",
    "    index = (y_pred_pgd != y_batch)\n",
    "    pgd_images = images_pgd[index]\n",
    "    y_pred_pgd = y_pred_pgd[index]\n",
    "    return pgd_images, y_pred_pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23ac9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cw_attack(attack, x_batch, y_batch, normal_model):\n",
    "    #convert tensor to numpy\n",
    "    #x_batch=x_batch.to('cuda')\n",
    "    #_, y_pred_pgd = normal_model(x_batch).max(1)\n",
    "    x_batch = x_batch.cpu().numpy()\n",
    "    x_test_adv = attack.generate(x=x_batch)\n",
    "    #convert the nd array back to tensor\n",
    "    x_test = torch.from_numpy(x_test_adv).to('cuda')\n",
    "    _, y_test = normal_model(x_test).max(1)\n",
    "    index = (y_test != y_batch)\n",
    "    adv_images = x_test[index]\n",
    "    y_pred_adv = y_test[index]\n",
    "    return adv_images, y_pred_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d75df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bim_attack(attack, x_batch, y_batch, normal_model):\n",
    "    #convert tensor to numpy\n",
    "    #x_batch=x_batch.to('cuda')\n",
    "    #_, y_pred_pgd = normal_model(x_batch).max(1)\n",
    "    x_batch = x_batch.cpu().numpy()\n",
    "    x_test_adv = attack.generate(x=x_batch)\n",
    "    #convert the nd array back to tensor\n",
    "    x_test = torch.from_numpy(x_test_adv).to('cuda')\n",
    "    _, y_test = normal_model(x_test).max(1)\n",
    "    index = (y_test != y_batch)\n",
    "    adv_images = x_test[index]\n",
    "    y_pred_adv = y_test[index]\n",
    "    return adv_images, y_pred_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60a66f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for natural and adversarial LeNet Model \n",
    "class LeNet_normal(torch.nn.Module):\n",
    "    \"\"\"Network architecture from: https://github.com/ChawDoe/LeNet5-MNIST-PyTorch.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.conv_2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.fc_1 = torch.nn.Linear(256, 120)\n",
    "        self.relu_3 = torch.nn.ReLU()\n",
    "        self.fc_2 = torch.nn.Linear(120, 84)\n",
    "        self.relu_4 = torch.nn.ReLU()\n",
    "        self.fc_3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool_1(self.relu_1(self.conv_1(x)))\n",
    "        x = self.pool_2(self.relu_2(self.conv_2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.relu_3(self.fc_1(x))\n",
    "        x = self.relu_4(self.fc_2(x))\n",
    "        x = self.fc_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87fe11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from rev2.cifar10.model_utils import resnet50, CIFAR10_RESNET50_CKPT_PATH\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, out_keys=None):\n",
    "        out = {}\n",
    "        x = self.conv1(x)\n",
    "        out[\"c1\"] = x\n",
    "        x = self.bn1(x)\n",
    "        out[\"bn1\"] = x\n",
    "        x = F.relu(x)\n",
    "        out[\"r1\"] = x\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        out[\"l1\"] = x\n",
    "        x = self.layer2(x)\n",
    "        out[\"l2\"] = x\n",
    "        x = self.layer3(x)\n",
    "        out[\"l3\"] = x\n",
    "        x = self.layer4(x)\n",
    "        out[\"l4\"] = x\n",
    "\n",
    "        x = F.avg_pool2d(x, 4)\n",
    "        out[\"gvp\"] = x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        out[\"fc\"] = x\n",
    "\n",
    "        if out_keys is None:\n",
    "            return x\n",
    "        res = {}\n",
    "        for key in out_keys:\n",
    "            res[key] = out[key]\n",
    "        return res\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,8,36,3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1,3,32,32))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbdc3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist\n",
    "def compute_benign_mnist(train_loader_mnist, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for benign\")\n",
    "    #statistics benign\n",
    "    medianAbs_ben = []\n",
    "    meanAbs_ben = []\n",
    "    iqr_ben = []\n",
    "    coef_var_ben=[]\n",
    "    coef_iqr_ben = []\n",
    "\n",
    "    #input squeeze benign\n",
    "    logit_ben1 = []\n",
    "    logit_ben2 = []\n",
    "    logit_ben3 = []\n",
    "\n",
    "    #attribution robustness\n",
    "    benign_attribution_gaussian1 = []\n",
    "    benign_attribution_gaussian2 = []\n",
    "    benign_attribution_gaussian3 = []\n",
    "    benign_attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    fs = []\n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader_mnist):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"mnist\", x_batch)\n",
    "        fs.extend(d)\n",
    "        \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(x_batch)\n",
    "        a_batch_benign = (Saliency(normal_model).attribute(inputs=x_batch, target=y_batch).sum(axis=1).cpu().numpy())\n",
    "        meanAbs_ben += compute_mean_abs_dev(a_batch_benign)\n",
    "        medianAbs_ben += compute_median_abs_dev(a_batch_benign)\n",
    "        iqr_ben += compute_iqr(a_batch_benign)\n",
    "        coef_var_ben += compute_coef_var(a_batch_benign)\n",
    "        coef_iqr_ben += compute_coef_iqr(a_batch_benign)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch_benign = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=x_batch, target=y_batch).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(x_batch, a_batch_benign, top_k = 100, d_type=\"not-adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(x_batch, a_batch_benign, top_k = 150, d_type=\"not-adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(x_batch, a_batch_benign, top_k = 180, d_type=\"not-adv\")\n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit_ben1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_ben2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_ben3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch_benign = quantus.explain(\n",
    "            model=normal_model, inputs=x_batch, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(x_batch, y_batch, spread = 0.005)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(x_batch, y_batch, spread = 0.01)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(x_batch, y_batch, spread = 0.05)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(x_batch, y_batch)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch_benign, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch_benign, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch_benign, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch_benign, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if step > 50: #500\n",
    "            \n",
    "            df = pd.DataFrame([\n",
    "            medianAbs_ben,\n",
    "            meanAbs_ben, \n",
    "            iqr_ben, \n",
    "            coef_var_ben, \n",
    "            coef_iqr_ben, \n",
    "            logit_ben1,\n",
    "            logit_ben2,\n",
    "            logit_ben3,\n",
    "            benign_attribution_gaussian1,\n",
    "            benign_attribution_gaussian2,\n",
    "            benign_attribution_gaussian3,\n",
    "            benign_attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Benign Median Absolute Dev\", \n",
    "            \"Benign Mean Absolute Dev\", \n",
    "            \"Benign IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze top 100\",\n",
    "            \"Input squeeze top 150\",\n",
    "            \"Input squeeze top 180\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "                \"FS\"\n",
    "        ])\n",
    "            \n",
    "            df.to_csv(\"Benign_MNIST_Metrics.csv\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "805bc96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cifar\n",
    "\n",
    "def compute_benign_cifar(train_loader_cifar, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for benign\")\n",
    "    #statistics benign\n",
    "    medianAbs_ben = []\n",
    "    meanAbs_ben = []\n",
    "    iqr_ben = []\n",
    "    coef_var_ben=[]\n",
    "    coef_iqr_ben = []\n",
    "\n",
    "    #input squeeze benign\n",
    "    logit_ben1 = []\n",
    "    logit_ben2 = []\n",
    "    logit_ben3 = []\n",
    "\n",
    "    #attribution robustness\n",
    "    benign_attribution_gaussian1 = []\n",
    "    benign_attribution_gaussian2 = []\n",
    "    benign_attribution_gaussian3 = []\n",
    "    benign_attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    \n",
    "    fs = []\n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader_cifar):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        #approach: feature squeezing \n",
    "        d = compute_distance_test(normal_model, \"cifar\", x_batch)\n",
    "        fs.extend(d)\n",
    "        \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(x_batch)\n",
    "        a_batch_benign = (Saliency(normal_model).attribute(inputs=x_batch, target=y_batch).sum(axis=1).cpu().numpy())\n",
    "        meanAbs_ben += compute_mean_abs_dev(a_batch_benign)\n",
    "        medianAbs_ben += compute_median_abs_dev(a_batch_benign)\n",
    "        iqr_ben += compute_iqr(a_batch_benign)\n",
    "        coef_var_ben += compute_coef_var(a_batch_benign)\n",
    "        coef_iqr_ben += compute_coef_iqr(a_batch_benign)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch_benign = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=x_batch, target=y_batch).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(x_batch, a_batch_benign, top_k = 400, d_type=\"not-adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(x_batch, a_batch_benign, top_k = 450, d_type=\"not-adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(x_batch, a_batch_benign, top_k = 500, d_type=\"not-adv\")\n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit_ben1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_ben2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_ben3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch_benign = quantus.explain(\n",
    "            model=normal_model, inputs=x_batch, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(x_batch, y_batch, spread = 0.05)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(x_batch, y_batch, spread = 0.10)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(x_batch, y_batch, spread = 0.15)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(x_batch, y_batch)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch_benign, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch_benign, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch_benign, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch_benign, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if step > 50: #500\n",
    "            \n",
    "            df = pd.DataFrame([\n",
    "            medianAbs_ben,\n",
    "            meanAbs_ben, \n",
    "            iqr_ben, \n",
    "            coef_var_ben, \n",
    "            coef_iqr_ben, \n",
    "            logit_ben1,\n",
    "            logit_ben2,\n",
    "            logit_ben3,\n",
    "            benign_attribution_gaussian1,\n",
    "            benign_attribution_gaussian2,\n",
    "            benign_attribution_gaussian3,\n",
    "            benign_attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "            fs], index = [\n",
    "            \"Benign Median Absolute Dev\", \n",
    "            \"Benign Mean Absolute Dev\", \n",
    "            \"Benign IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze top 400\",\n",
    "            \"Input squeeze top 450\",\n",
    "            \"Input squeeze top 500\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "                \"Feature squeeze\"\n",
    "        ])\n",
    "            \n",
    "            df.to_csv(\"Benign_CIFAR_Metrics.csv\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73f2dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenet\n",
    "\n",
    "def compute_benign(train_loader, normal_model): \n",
    "    #compute metrics for svhn\n",
    "    \n",
    "    print(\"Computing metrics for benign\")\n",
    "    #statistics benign\n",
    "    medianAbs_ben = []\n",
    "    meanAbs_ben = []\n",
    "    iqr_ben = []\n",
    "    coef_var_ben=[]\n",
    "    coef_iqr_ben = []\n",
    "\n",
    "    #input squeeze benign\n",
    "    logit_ben1 = []\n",
    "    logit_ben2 = []\n",
    "    logit_ben3 = []\n",
    "\n",
    "    #attribution robustness\n",
    "    benign_attribution_gaussian1 = []\n",
    "    benign_attribution_gaussian2 = []\n",
    "    benign_attribution_gaussian3 = []\n",
    "    benign_attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    \n",
    "    fs=[]\n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        d = compute_distance_test(normal_model, \"imagenet\", x_batch)\n",
    "        fs.extend(d)\n",
    "        \n",
    "        #approach: statistics\n",
    "        x_logits = normal_model(x_batch)\n",
    "        a_batch_benign = (Saliency(normal_model).attribute(inputs=x_batch, target=y_batch).sum(axis=1).cpu().numpy())\n",
    "        meanAbs_ben += compute_mean_abs_dev(a_batch_benign)\n",
    "        medianAbs_ben += compute_median_abs_dev(a_batch_benign)\n",
    "        iqr_ben += compute_iqr(a_batch_benign)\n",
    "        coef_var_ben += compute_coef_var(a_batch_benign)\n",
    "        coef_iqr_ben += compute_coef_iqr(a_batch_benign)\n",
    "        \n",
    "        #approach: input squeeze\n",
    "        a_batch_benign = quantus.normalise_func.normalise_by_negative(Saliency(normal_model).attribute(inputs=x_batch, target=y_batch).sum(axis=1).cpu().numpy())\n",
    "        x_modified1 = modify_x_based_on_attribution(x_batch, a_batch_benign, top_k = 5000, d_type=\"not-adv\")\n",
    "        x_modified2 = modify_x_based_on_attribution(x_batch, a_batch_benign, top_k = 10000, d_type=\"not-adv\")\n",
    "        x_modified3 = modify_x_based_on_attribution(x_batch, a_batch_benign, top_k = 30000, d_type=\"not-adv\")\n",
    "        x_logits1 = normal_model(x_modified1)\n",
    "        x_logits2 = normal_model(x_modified2)\n",
    "        x_logits3 = normal_model(x_modified3)\n",
    "        diff1 = torch.norm(x_logits-x_logits1,p=1, dim=1)\n",
    "        diff2 = torch.norm(x_logits-x_logits2,p=1, dim=1)\n",
    "        diff3 = torch.norm(x_logits-x_logits3,p=1, dim=1)\n",
    "        logit_ben1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_ben2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_ben3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch_benign = quantus.explain(\n",
    "            model=normal_model, inputs=x_batch, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(x_batch, y_batch, spread = 0.15)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(x_batch, y_batch, spread = 0.25)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(x_batch, y_batch, spread = 0.35)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(x_batch, y_batch)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1)\n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "    \n",
    "        for a, b in zip(a_batch_benign, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch_benign, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch_benign, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch_benign, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            benign_attribution_uniform.append(c)\n",
    "        \n",
    "        #save the results in csv\n",
    "        if step > 100: #500\n",
    "            break\n",
    "    \n",
    "    df = pd.DataFrame([\n",
    "            medianAbs_ben,\n",
    "            meanAbs_ben, \n",
    "            iqr_ben, \n",
    "            coef_var_ben, \n",
    "            coef_iqr_ben, \n",
    "            logit_ben1,\n",
    "            logit_ben2,\n",
    "            logit_ben3,\n",
    "            benign_attribution_gaussian1,\n",
    "            benign_attribution_gaussian2,\n",
    "            benign_attribution_gaussian3,\n",
    "            benign_attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "            logit_uniform, \n",
    "    fs], index = [\n",
    "            \"Benign Median Absolute Dev\", \n",
    "            \"Benign Mean Absolute Dev\", \n",
    "            \"Benign IQR\", \n",
    "            \"Coefficient of Variance\",\n",
    "            \"Coef of IQR\",\n",
    "            \"Input squeeze top 100\",\n",
    "            \"Input squeeze top 150\",\n",
    "            \"Input squeeze top 200\",\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Unifrom attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "            \"Uniform logit robusntess\",\n",
    "        \"feature squeeze\"\n",
    "        ])\n",
    "    \n",
    "    df.to_csv(\"Benign_IMAGENET_Metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "401199fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_model():\n",
    "    model=torchvision.models.mobilenet_v3_small(weights=True).to(device)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f31bc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_imagenet(): \n",
    "    \n",
    "    images = '/home/db1702/Downloads/imagenet-mini/val/'\n",
    "    normal_model = load_imagenet_model()\n",
    "    normal_model.to(device)\n",
    "    normal_model.eval()\n",
    "    \n",
    "    # the validation transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.5, 0.5, 0.5],\n",
    "            std=[0.5, 0.5, 0.5]\n",
    "        )])\n",
    "\n",
    "    #get dataset\n",
    "    train = torchvision.datasets.ImageFolder(images, transform=valid_transform)\n",
    "    train_loader = DataLoader(train, shuffle=True, batch_size = 5)\n",
    "\n",
    "    \n",
    "    compute_benign(train_loader, normal_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0228861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_model(path):\n",
    "    model = LeNet_normal()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef28d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_mnist():\n",
    "    \n",
    "    \n",
    "    #get model\n",
    "    path = \"mnist_model.pth\"\n",
    "    normal_model = load_mnist_model(path)\n",
    "    normal_model.to(device)\n",
    "    normal_model.eval()\n",
    "    \n",
    "    #get dataset\n",
    "    test_set = torchvision.datasets.MNIST(root='./sample_data', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=10, pin_memory=True)\n",
    "    \n",
    "    \n",
    "    compute_benign_mnist(test_loader, normal_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19232677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar_model(path):\n",
    "    model = resnet50()\n",
    "    ckpt_dict = torch.load(path, lambda storage, loc: storage)\n",
    "    model.load_state_dict(ckpt_dict)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "668cf03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_cifar(): \n",
    "    \n",
    "    #load cifar model and set to eval\n",
    "    path = \"cifar.ckpt\"\n",
    "    normal_model = load_cifar_model(path)\n",
    "    normal_model.to(device)\n",
    "    normal_model.eval()\n",
    "    \n",
    "    #get dataset\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=torchvision.transforms.ToTensor())\n",
    "    test_loader = DataLoader(testset, shuffle=True, batch_size=10)\n",
    "    \n",
    "    compute_benign_cifar(test_loader, normal_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990b1e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0334a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imagenet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f884b",
   "metadata": {},
   "source": [
    "# compute fpr for all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "14f18bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cifar = pd.read_csv(\"Benign_CIFAR_Metrics.csv\")\n",
    "df_mnist = pd.read_csv(\"Benign_MNIST_Metrics.csv\")\n",
    "df_imagenet = pd.read_csv(\"Benign_IMAGENET_Metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0abee7",
   "metadata": {},
   "source": [
    "# CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5b037b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_squeezer = df_cifar.iloc[16].values.flatten().tolist()[1:]\n",
    "threshold = [1.15526, 1.14371, 0.3224780]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "478626d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(ben, threshold): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in ben: \n",
    "        if value<threshold:\n",
    "            TN += 1\n",
    "        else: \n",
    "            FP += 1\n",
    "    \n",
    "    \n",
    "    return (FP/(TN+FP))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e2b0d640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.923076923076923\n",
      "11.923076923076923\n",
      "18.076923076923077\n"
     ]
    }
   ],
   "source": [
    "for th in threshold:\n",
    "    FPR = compute_metrics(feature_squeezer, th)\n",
    "    print(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c7e8f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using all detectors\n",
    "\n",
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics1(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, ap1, i, j, ap2a, k, l, ap2b, m, n, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value5, value6, value7, value8 in zip(meanAb,medianAb,coefiqr,coefvar,ap1,ap2a,ap2b, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else: \n",
    "                        if value5<i or value5>j:\n",
    "                            FP +=1\n",
    "                        else: \n",
    "                            if value6<k or value6>l:\n",
    "                                FP +=1\n",
    "                            else:\n",
    "                                if value7<m or value7>n:\n",
    "                                    FP +=1\n",
    "                                else:\n",
    "                                    if value8<o or value8>p:\n",
    "                                        FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4309e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.923076923076923\n",
      "23.46153846153846\n",
      "39.23076923076923\n"
     ]
    }
   ],
   "source": [
    "a=[1.3,1.85,2]\n",
    "b=[7,7,6]\n",
    "c=[0.9,1.08,1.23]\n",
    "d=[5,4,4]\n",
    "e=[0.461,0.491,0.502]\n",
    "f=[0.8,0.8,10]\n",
    "g=[0.42,0.42,0.42]\n",
    "h=[1.27,1.19,1.146]\n",
    "\n",
    "i=[48,68,78]\n",
    "j=[230,230,230]\n",
    "\n",
    "#logitgaussian3\n",
    "k=[44,64,76]\n",
    "l=[405,405,405]\n",
    "\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100]\n",
    "n=[8800,8800,8800]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[2,2.5,2.8]\n",
    "p=[10,10,10]\n",
    "\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[0], b[0],\n",
    "                      medianAbsDev ,c[0], d[0],\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                      squeezer_input,i[0],j[0], \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0], \n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[1], b[1], \n",
    "                      medianAbsDev, c[1], d[1], \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                      squeezer_input,i[1],j[1], \n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1], \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[2], b[2],\n",
    "                      medianAbsDev , c[2], d[2],\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                      squeezer_input,i[2],j[2], \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2], \n",
    "                      iqr, o[2], p[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f71b3314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.076923076923077\n",
      "6.730769230769231\n",
      "11.346153846153847\n"
     ]
    }
   ],
   "source": [
    "#using only approach 1\n",
    "\n",
    "#using only approach 1 and 2 detectors\n",
    "\n",
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2(ap1, i, j): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value5 in (ap1):\n",
    "        if value5<i or value5>j:\n",
    "            FP +=1\n",
    "        \n",
    "\n",
    "    return (FP/(len(ap1)))*100\n",
    "\n",
    "\n",
    "i=[48,68,78]\n",
    "j=[230,230,230]\n",
    "\n",
    "#logitgaussian3\n",
    "k=[44,64,76]\n",
    "l=[405,405,405]\n",
    "\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100]\n",
    "n=[8800,8800,8800]\n",
    "\n",
    "\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[0],j[0]))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[1],j[1]))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[2],j[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eb01ebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "14.615384615384617\n",
      "27.115384615384613\n"
     ]
    }
   ],
   "source": [
    "#using only approach 1 and 2 detectors\n",
    "\n",
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2(ap1, i, j, ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value5, value6, value7 in zip(ap1,ap2a,ap2b):\n",
    "        if value5<i or value5>j:\n",
    "            FP +=1\n",
    "        else: \n",
    "            if value6<k or value6>l:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value7<m or value7>n:\n",
    "                    FP +=1\n",
    "\n",
    "    return (FP/(len(ap1)))*100\n",
    "\n",
    "\n",
    "i=[48,68,78]\n",
    "j=[230,230,230]\n",
    "\n",
    "#logitgaussian3\n",
    "k=[44,64,76]\n",
    "l=[405,405,405]\n",
    "\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100]\n",
    "n=[8800,8800,8800]\n",
    "\n",
    "\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[0],j[0], \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0]))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[1],j[1], \n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1]))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[2],j[2], \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "27657128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.076923076923077\n",
      "10.384615384615385\n",
      "20.76923076923077\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2(ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100\n",
    "\n",
    "#logitgaussian3\n",
    "k=[44,64,76]\n",
    "l=[405,405,405]\n",
    "\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100]\n",
    "n=[8800,8800,8800]\n",
    "\n",
    "\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c49633cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.307692307692308\n",
      "5.5769230769230775\n",
      "10.192307692307692\n"
     ]
    }
   ],
   "source": [
    "#just 2a FPR\n",
    "\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "#attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2(ap2a, k, l): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6 in (ap2a):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100\n",
    "\n",
    "#logitgaussian3\n",
    "k=[44,64,76]\n",
    "l=[405,405,405]\n",
    "\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100]\n",
    "n=[8800,8800,8800]\n",
    "\n",
    "\n",
    "\n",
    "print(compute_metrics2(logit_gaussian3, k[0],l[0]))\n",
    "\n",
    "print(compute_metrics2(logit_gaussian3, k[1],l[1]))\n",
    "\n",
    "print(compute_metrics2(logit_gaussian3, k[2],l[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "85314f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692307692307693\n",
      "5.1923076923076925\n",
      "11.346153846153847\n"
     ]
    }
   ],
   "source": [
    "#just 2b FPR\n",
    "\n",
    "#logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2(ap2a, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6 in (ap2a):\n",
    "        if value6<m or value6>n:\n",
    "            FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100\n",
    "\n",
    "#logitgaussian3\n",
    "k=[44,64,76]\n",
    "l=[405,405,405]\n",
    "\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100]\n",
    "n=[8800,8800,8800]\n",
    "\n",
    "\n",
    "\n",
    "print(compute_metrics2(attr_gaussian3, m[0],n[0]))\n",
    "\n",
    "print(compute_metrics2(attr_gaussian3, m[1],n[1]))\n",
    "\n",
    "print(compute_metrics2(attr_gaussian3, m[2],n[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f57b9a",
   "metadata": {},
   "source": [
    "# using all statistical detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "912543b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.076923076923077\n",
      "15.0\n",
      "26.153846153846157\n"
     ]
    }
   ],
   "source": [
    "#all statistical approaches\n",
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "a=[1.3,1.85,2]\n",
    "b=[7,7,6]\n",
    "c=[0.9,1.08,1.23]\n",
    "d=[5,4,4]\n",
    "e=[0.461,0.491,0.502]\n",
    "f=[0.8,0.8,0.8]\n",
    "g=[0.42,0.42,0.42]\n",
    "h=[1.27,1.19,1.146]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[2,2.5,2.8]\n",
    "p=[10,10,10]\n",
    "\n",
    "\n",
    "def compute_metrics1(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h,iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value8 in zip(meanAb,medianAb,coefiqr,coefvar,iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else:\n",
    "                        if value8<o or value8>p:\n",
    "                            FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[0], b[0],\n",
    "                      medianAbsDev ,c[0], d[0],\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                    \n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[1], b[1], \n",
    "                      medianAbsDev, c[1], d[1], \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                      \n",
    "                    \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[2], b[2],\n",
    "                      medianAbsDev , c[2], d[2],\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                     \n",
    "                     \n",
    "                      iqr, o[2], p[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf0b2447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9615384615384616\n",
      "5.1923076923076925\n",
      "9.038461538461538\n"
     ]
    }
   ],
   "source": [
    "#using mean abs dev\n",
    "\n",
    "#all statistical approaches\n",
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "a=[1.3,1.85,2]\n",
    "b=[7,7,6]\n",
    "c=[0.9,1.08,1.23]\n",
    "d=[5,4,4]\n",
    "e=[0.461,0.491,0.502]\n",
    "f=[0.8,0.8,0.8]\n",
    "g=[0.42,0.42,0.42]\n",
    "h=[1.27,1.19,1.146]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[2,2.5,2.8]\n",
    "p=[10,10,10]\n",
    "\n",
    "\n",
    "def compute_metrics1(meanAb, a, b): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1 in (meanAb): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        \n",
    "    return (FP/(len(meanAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[0], b[0]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[1], b[1]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[2], b[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c321861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.576923076923077\n",
      "4.807692307692308\n",
      "10.576923076923077\n"
     ]
    }
   ],
   "source": [
    "#median abs dev\n",
    "\n",
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "a=[1.3,1.85,2]\n",
    "b=[7,7,6]\n",
    "c=[0.9,1.08,1.23]\n",
    "d=[5,4,4]\n",
    "e=[0.461,0.491,0.502]\n",
    "f=[0.8,0.8,0.8]\n",
    "g=[0.42,0.42,0.42]\n",
    "h=[1.27,1.19,1.146]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[2,2.5,2.8]\n",
    "p=[10,10,10]\n",
    "\n",
    "\n",
    "def compute_metrics1(medianAb, c,d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value2 in (medianAb): \n",
    "        if value2<c or value2>d:\n",
    "            FP += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (FP/(len(medianAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev ,c[0], d[0]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev, c[1], d[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev , c[2], d[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "afa0fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.576923076923077\n",
      "3.4615384615384617\n",
      "10.192307692307692\n"
     ]
    }
   ],
   "source": [
    "#iqr  approaches\n",
    "\n",
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "a=[1.3,1.85,2]\n",
    "b=[7,7,6]\n",
    "c=[0.9,1.08,1.23]\n",
    "d=[5,4,4]\n",
    "e=[0.461,0.491,0.502]\n",
    "f=[0.8,0.8,0.8]\n",
    "g=[0.42,0.42,0.42]\n",
    "h=[1.27,1.19,1.146]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[2,2.5,2.8]\n",
    "p=[10,10,10]\n",
    "\n",
    "\n",
    "def compute_metrics1(iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value8 in (iqr): \n",
    "        if value8<o or value8>p:\n",
    "            FP += 1\n",
    "    \n",
    "    return (FP/(len(iqr)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                    \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      iqr, o[2], p[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "db0d641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9615384615384616\n",
      "5.1923076923076925\n",
      "8.846153846153847\n"
     ]
    }
   ],
   "source": [
    "#coef iqr\n",
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "a=[1.3,1.85,2]\n",
    "b=[7,7,6]\n",
    "c=[0.9,1.08,1.23]\n",
    "d=[5,4,4]\n",
    "e=[0.461,0.491,0.502]\n",
    "f=[0.8,0.8,0.8]\n",
    "g=[0.42,0.42,0.42]\n",
    "h=[1.27,1.19,1.146]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[2,2.5,2.8]\n",
    "p=[10,10,10]\n",
    "\n",
    "\n",
    "def compute_metrics1(coefiqr, e, f): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value3 in (coefiqr): \n",
    "        if value3<e or value3>f:\n",
    "            FP += 1\n",
    "    \n",
    "    return (FP/(len(coefiqr)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_iqr, e[0], f[0]))\n",
    "                    \n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_iqr, e[1], f[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_iqr , e[2], f[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ac7ed304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.153846153846154\n",
      "5.961538461538462\n",
      "10.192307692307692\n"
     ]
    }
   ],
   "source": [
    "#coef var\n",
    "meanAbsDev = df_cifar.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_cifar.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_cifar.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "a=[1.3,1.85,2]\n",
    "b=[7,7,6]\n",
    "c=[0.9,1.08,1.23]\n",
    "d=[5,4,4]\n",
    "e=[0.461,0.491,0.502]\n",
    "f=[0.8,0.8,0.8]\n",
    "g=[0.42,0.42,0.42]\n",
    "h=[1.27,1.19,1.146]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[2,2.5,2.8]\n",
    "p=[10,10,10]\n",
    "\n",
    "\n",
    "def compute_metrics1(coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value4 in (coefvar): \n",
    "        if value4<g or value4>h:\n",
    "            FP += 1   \n",
    "    \n",
    "    return (FP/(len(coefvar)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_var, g[0], h[0]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_var, g[1], h[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_var,g[2], h[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dba3e0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.038461538461538\n",
      "14.807692307692308\n",
      "27.884615384615387\n"
     ]
    }
   ],
   "source": [
    "# what if i add one statistical appraoch? coef of variance. \n",
    "\n",
    "# so using only second approach. we have results already. lets check FPR\n",
    "\n",
    "coef_var = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_cifar.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_cifar.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2(ap2a, k, l, ap2b, m, n, coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7, value8 in zip(ap2a,ap2b,coefvar):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value8<g or value8>h:\n",
    "                    FP+=1\n",
    "                \n",
    "    return (FP/(len(ap2a)))*100\n",
    "\n",
    "\n",
    "#coef of var\n",
    "g=[0.42,0.42,0.42]\n",
    "h=[1.27,1.19,1.146]\n",
    "\n",
    "#logitgaussian3\n",
    "k=[44,64,76]\n",
    "l=[405,405,405]\n",
    "\n",
    "#attrgaussian3\n",
    "m=[2200,2800,3100]\n",
    "n=[8800,8800,8800]\n",
    "\n",
    "\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0],\n",
    "coef_var, g[0], h[0]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1],coef_var, g[1], h[1]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2], coef_var, g[2], h[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890e379",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3e54dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_squeezer = df_mnist.iloc[16].values.flatten().tolist()[1:]\n",
    "threshold = [0.54005, 0.540058, 0.05971]\n",
    "\n",
    "\n",
    "def compute_metrics(ben, threshold): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in ben: \n",
    "        if value<threshold:\n",
    "            TN += 1\n",
    "        else: \n",
    "            FP += 1\n",
    "    \n",
    "    \n",
    "    return (FP/(TN+FP))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a16f49d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1923076923076925\n",
      "5.1923076923076925\n",
      "11.153846153846155\n"
     ]
    }
   ],
   "source": [
    "for th in threshold:\n",
    "    FPR = compute_metrics(feature_squeezer, th)\n",
    "    print(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d892ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using all approaches\n",
    "meanAbsDev = df_mnist.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_mnist.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_mnist.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_mnist.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_mnist.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_mnist.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_mnist.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_mnist.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_metrics1(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, ap1, i, j, ap2a, k, l, ap2b, m, n, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value5, value6, value7, value8 in zip(meanAb,medianAb,coefiqr,coefvar,ap1,ap2a,ap2b, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else: \n",
    "                        if value5<i or value5>j:\n",
    "                            FP +=1\n",
    "                        else: \n",
    "                            if value6<k or value6>l:\n",
    "                                FP +=1\n",
    "                            else:\n",
    "                                if value7<m or value7>n:\n",
    "                                    FP +=1\n",
    "                                else:\n",
    "                                    if value8<o or value8>p:\n",
    "                                        FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d911af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.2,0.29,0.34]\n",
    "b=[1.3,1.3,1.3]\n",
    "c=[0.0,0.0,0.0]\n",
    "d=[0.29,0.23,0.2]\n",
    "e=[0.99,0.999,0.9999]\n",
    "f=[1.1,1.1,1.0]\n",
    "g=[0.34,0.34,0.34]\n",
    "h=[0.73,0.69,0.67]\n",
    "\n",
    "#app1\n",
    "i=[16,25,35]\n",
    "j=[370,370,370]\n",
    "\n",
    "#app2a:logitgaussian3\n",
    "k=[0.07,0.07,0.07]\n",
    "l=[3.3,2.1,1.7]\n",
    "\n",
    "#app2b:attrgaussian3\n",
    "m=[0.1,0.1,0.1]\n",
    "n=[250,150,120]\n",
    "\n",
    "#iqr\n",
    "o=[0.20,0.32,0.37]\n",
    "p=[1.24,1.34,1.34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "234b746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.46153846153847\n",
      "99.8076923076923\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_metrics1(meanAbsDev, a[0], b[0],\n",
    "                      medianAbsDev ,c[0], d[0],\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                      squeezer_input,i[0],j[0], \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0], \n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[1], b[1], \n",
    "                      medianAbsDev, c[1], d[1], \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                      squeezer_input,i[1],j[1], \n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1], \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[2], b[2],\n",
    "                      medianAbsDev , c[2], d[2],\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                      squeezer_input,i[2],j[2], \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2], \n",
    "                      iqr, o[2], p[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4007f59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7307692307692308\n",
      "3.653846153846154\n",
      "7.5\n"
     ]
    }
   ],
   "source": [
    "#using only approach 1\n",
    "\n",
    "\n",
    "squeezer_input = df_mnist.iloc[7].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics(ap1, i, j): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value5 in (ap1):\n",
    "        if value5<i or value5>j:\n",
    "            FP +=1\n",
    "        \n",
    "\n",
    "    return (FP/(len(ap1)))*100\n",
    "\n",
    "\n",
    "#app1\n",
    "i=[16,25,35]\n",
    "j=[370,370,370]\n",
    "\n",
    "#app2a:logitgaussian3\n",
    "k=[0.07,0.07,0.07]\n",
    "l=[3.3,2.1,1.7]\n",
    "\n",
    "#app2b:attrgaussian3\n",
    "m=[0.1,0.1,0.1]\n",
    "n=[250,150,120]\n",
    "\n",
    "\n",
    "\n",
    "print(compute_metrics(squeezer_input,i[0],j[0]))\n",
    "\n",
    "print(compute_metrics(squeezer_input,i[1],j[1]))\n",
    "\n",
    "print(compute_metrics(squeezer_input,i[2],j[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5b36415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5769230769230775\n",
      "13.076923076923078\n",
      "24.807692307692307\n"
     ]
    }
   ],
   "source": [
    "#just using approach 1 and approach 2\n",
    "squeezer_input = df_mnist.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_mnist.iloc[12].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_mnist.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_metrics2(ap1, i, j, ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value5, value6, value7 in zip(ap1,ap2a,ap2b):\n",
    "        if value5<i or value5>j:\n",
    "            FP +=1\n",
    "        else: \n",
    "            if value6<k or value6>l:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value7<m or value7>n:\n",
    "                    FP +=1\n",
    "\n",
    "    return (FP/(len(ap1)))*100\n",
    "\n",
    "\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[0],j[0], \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0]))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[1],j[1], \n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1]))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[2],j[2], \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6ab1daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8461538461538463\n",
      "10.0\n",
      "18.461538461538463\n"
     ]
    }
   ],
   "source": [
    "#just using approach 2\n",
    "\n",
    "logit_gaussian3 = df_mnist.iloc[12].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_mnist.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_metrics2(ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics2( \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1]))\n",
    "\n",
    "print(compute_metrics2( \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b32ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7307692307692308\n",
      "6.538461538461539\n",
      "11.73076923076923\n"
     ]
    }
   ],
   "source": [
    "#just using approach 2(a)\n",
    "\n",
    "#just using approach 2\n",
    "\n",
    "logit_gaussian3 = df_mnist.iloc[12].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_metrics2(ap2a, k, l): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6 in (ap2a):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        \n",
    "    return (FP/(len(ap2a)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics2( \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                     ))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                    ))\n",
    "\n",
    "print(compute_metrics2( \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f4086fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1153846153846154\n",
      "4.615384615384616\n",
      "9.230769230769232\n"
     ]
    }
   ],
   "source": [
    "#just using approach 2(b)\n",
    "\n",
    "#just using approach 2\n",
    "\n",
    "attr_gaussian3 = df_mnist.iloc[8].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_metrics2( ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value7 in (ap2b):\n",
    "        if value7<m or value7>n:\n",
    "            FP +=1\n",
    "    \n",
    "    return (FP/(len(ap2b)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics2( \n",
    "                     \n",
    "                      attr_gaussian3,m[0], n[0]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                     \n",
    "                     attr_gaussian3,m[1], n[1]))\n",
    "\n",
    "print(compute_metrics2( \n",
    "                     \n",
    "                     attr_gaussian3,m[2], n[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1d30e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.769230769230769\n",
      "20.192307692307693\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "#all statistical approaches\n",
    "meanAbsDev = df_mnist.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_mnist.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_mnist.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_mnist.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_mnist.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_mnist.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_mnist.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_mnist.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_metrics1(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h,iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value8 in zip(meanAb,medianAb,coefiqr,coefvar,iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else:\n",
    "                        if value8<o or value8>p:\n",
    "                            FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[0], b[0],\n",
    "                      medianAbsDev ,c[0], d[0],\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                    \n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[1], b[1], \n",
    "                      medianAbsDev, c[1], d[1], \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                      \n",
    "                    \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[2], b[2],\n",
    "                      medianAbsDev , c[2], d[2],\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                     \n",
    "                     \n",
    "                      iqr, o[2], p[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8a20b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.2,0.29,0.34]\n",
    "b=[1.3,1.3,1.3]\n",
    "c=[0.0,0.0,0.0]\n",
    "d=[0.29,0.23,0.2]\n",
    "e=[0.99,0.999,0.9999]\n",
    "f=[1.1,1.1,1.0]\n",
    "g=[0.34,0.34,0.34]\n",
    "h=[0.73,0.69,0.67]\n",
    "\n",
    "#app1\n",
    "i=[16,25,35]\n",
    "j=[370,370,370]\n",
    "\n",
    "#app2a:logitgaussian3\n",
    "k=[0.07,0.07,0.07]\n",
    "l=[3.3,2.1,1.7]\n",
    "\n",
    "#app2b:attrgaussian3\n",
    "m=[0.1,0.1,0.1]\n",
    "n=[250,150,120]\n",
    "\n",
    "#iqr\n",
    "o=[0.20,0.32,0.37]\n",
    "p=[1.24,1.34,1.34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6202124a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7307692307692308\n",
      "8.269230769230768\n",
      "14.423076923076922\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev = df_mnist.iloc[1].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(meanAb, a, b): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1 in (meanAb): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        \n",
    "    return (FP/(len(meanAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[0], b[0]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[1], b[1]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[2], b[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1b5d27d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.153846153846154\n",
      "5.769230769230769\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "medianAbsDev = df_mnist.iloc[0].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(medianAb, c,d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value2 in (medianAb): \n",
    "        if value2<c or value2>d:\n",
    "            FP += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (FP/(len(medianAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev ,c[0], d[0]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev, c[1], d[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev , c[2], d[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7bdc2886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3461538461538463\n",
      "9.423076923076923\n",
      "13.846153846153847\n"
     ]
    }
   ],
   "source": [
    "iqr = df_mnist.iloc[2].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value8 in (iqr): \n",
    "        if value8<o or value8>p:\n",
    "            FP += 1\n",
    "    \n",
    "    return (FP/(len(iqr)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                    \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      iqr, o[2], p[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e1168dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2692307692307696\n",
      "3.653846153846154\n",
      "3.653846153846154\n"
     ]
    }
   ],
   "source": [
    "coef_iqr = df_mnist.iloc[4].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(coefiqr, e, f): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value3 in (coefiqr): \n",
    "        if value3<e or value3>f:\n",
    "            FP += 1\n",
    "    \n",
    "    return (FP/(len(coefiqr)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_iqr, e[0], f[0]))\n",
    "                    \n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_iqr, e[1], f[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_iqr , e[2], f[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "852057be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692307692307693\n",
      "3.8461538461538463\n",
      "6.923076923076923\n"
     ]
    }
   ],
   "source": [
    "coef_var = df_mnist.iloc[3].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value4 in (coefvar): \n",
    "        if value4<g or value4>h:\n",
    "            FP += 1   \n",
    "    \n",
    "    return (FP/(len(coefvar)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_var, g[0], h[0]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_var, g[1], h[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_var,g[2], h[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c807965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5769230769230775\n",
      "17.307692307692307\n",
      "27.307692307692307\n"
     ]
    }
   ],
   "source": [
    "#all statistical approaches except iqr\n",
    "meanAbsDev = df_mnist.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_mnist.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_mnist.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_mnist.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_mnist.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_mnist.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_mnist.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_mnist.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_metrics1(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4 in zip(meanAb,medianAb,coefiqr,coefvar): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[0], b[0],\n",
    "                      medianAbsDev ,c[0], d[0],\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                    ))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[1], b[1], \n",
    "                      medianAbsDev, c[1], d[1], \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                      ))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[2], b[2],\n",
    "                      medianAbsDev , c[2], d[2],\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f2c760d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.038461538461538\n",
      "9.615384615384617\n",
      "14.615384615384617\n"
     ]
    }
   ],
   "source": [
    "#all statistical approaches except iqr and mean abs dev\n",
    "\n",
    "medianAbsDev = df_mnist.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_mnist.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_mnist.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_mnist.iloc[3].values.flatten().tolist()[1:]\n",
    "squeezer_input = df_mnist.iloc[7].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_mnist.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_mnist.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_metrics1(medianAb, c,d, coefiqr, e, f, coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value2, value3, value4 in zip(medianAb,coefiqr,coefvar): \n",
    "        if value2<c or value2>d:\n",
    "            FP +=1\n",
    "        else: \n",
    "            if value3<e or value3>f:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value4<g or value4>h:\n",
    "                    FP +=1\n",
    "\n",
    "    \n",
    "\n",
    "    return (FP/(len(medianAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev ,c[0], d[0],\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                    ))\n",
    "\n",
    "print(compute_metrics1( \n",
    "                      medianAbsDev, c[1], d[1], \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                      ))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev , c[2], d[2],\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e8f8fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.653846153846154\n",
      "6.153846153846154\n",
      "9.038461538461538\n"
     ]
    }
   ],
   "source": [
    "# statistical approaches using coef of var and coef of iqr only \n",
    "\n",
    "coef_iqr = df_mnist.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_mnist.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics1(coefiqr, e, f, coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for  value3, value4 in zip(coefiqr,coefvar): \n",
    "        if value3<e or value3>f:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value4<g or value4>h:\n",
    "                FP +=1\n",
    "\n",
    "    \n",
    "\n",
    "    return (FP/(len(coefiqr)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                     \n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                    ))\n",
    "\n",
    "print(compute_metrics1( \n",
    "                     \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                      ))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                     \n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33def0ae",
   "metadata": {},
   "source": [
    "# imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4e4d9c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benign Median Absolute Dev</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.020484</td>\n",
       "      <td>0.021316</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.017424</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.033298</td>\n",
       "      <td>0.015329</td>\n",
       "      <td>0.019026</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>0.019164</td>\n",
       "      <td>0.021244</td>\n",
       "      <td>0.018071</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.025899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benign Mean Absolute Dev</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>0.032768</td>\n",
       "      <td>0.041157</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>0.030149</td>\n",
       "      <td>0.036664</td>\n",
       "      <td>0.040445</td>\n",
       "      <td>0.028866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>0.058719</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>0.020665</td>\n",
       "      <td>0.030322</td>\n",
       "      <td>0.035129</td>\n",
       "      <td>0.036164</td>\n",
       "      <td>0.033193</td>\n",
       "      <td>0.041576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benign IQR</td>\n",
       "      <td>0.028198</td>\n",
       "      <td>0.019277</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.052185</td>\n",
       "      <td>0.021889</td>\n",
       "      <td>0.040852</td>\n",
       "      <td>0.049536</td>\n",
       "      <td>0.050808</td>\n",
       "      <td>0.037256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030106</td>\n",
       "      <td>0.077184</td>\n",
       "      <td>0.037065</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.042910</td>\n",
       "      <td>0.048298</td>\n",
       "      <td>0.043622</td>\n",
       "      <td>0.045557</td>\n",
       "      <td>0.059069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coefficient of Variance</td>\n",
       "      <td>0.744189</td>\n",
       "      <td>1.045666</td>\n",
       "      <td>1.071272</td>\n",
       "      <td>0.895818</td>\n",
       "      <td>0.670811</td>\n",
       "      <td>0.977936</td>\n",
       "      <td>1.021734</td>\n",
       "      <td>0.900896</td>\n",
       "      <td>0.944452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977874</td>\n",
       "      <td>0.961550</td>\n",
       "      <td>0.887167</td>\n",
       "      <td>1.139028</td>\n",
       "      <td>1.049775</td>\n",
       "      <td>1.091366</td>\n",
       "      <td>0.927226</td>\n",
       "      <td>0.875777</td>\n",
       "      <td>1.092827</td>\n",
       "      <td>1.086345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coef of IQR</td>\n",
       "      <td>0.572312</td>\n",
       "      <td>0.543271</td>\n",
       "      <td>0.554579</td>\n",
       "      <td>0.591542</td>\n",
       "      <td>0.568094</td>\n",
       "      <td>0.587290</td>\n",
       "      <td>0.546192</td>\n",
       "      <td>0.562787</td>\n",
       "      <td>0.566464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594566</td>\n",
       "      <td>0.586153</td>\n",
       "      <td>0.608877</td>\n",
       "      <td>0.486604</td>\n",
       "      <td>0.538749</td>\n",
       "      <td>0.539617</td>\n",
       "      <td>0.588851</td>\n",
       "      <td>0.579019</td>\n",
       "      <td>0.507159</td>\n",
       "      <td>0.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Input squeeze top 100</td>\n",
       "      <td>2763.148926</td>\n",
       "      <td>2081.828369</td>\n",
       "      <td>1023.216736</td>\n",
       "      <td>3165.566895</td>\n",
       "      <td>2523.543457</td>\n",
       "      <td>1926.836670</td>\n",
       "      <td>2048.480225</td>\n",
       "      <td>3013.867676</td>\n",
       "      <td>2095.982178</td>\n",
       "      <td>...</td>\n",
       "      <td>2124.283447</td>\n",
       "      <td>2703.627441</td>\n",
       "      <td>2947.141113</td>\n",
       "      <td>5345.160156</td>\n",
       "      <td>2508.094971</td>\n",
       "      <td>1528.462280</td>\n",
       "      <td>2568.843750</td>\n",
       "      <td>2811.551758</td>\n",
       "      <td>4963.367188</td>\n",
       "      <td>1407.468872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Input squeeze top 150</td>\n",
       "      <td>3862.401367</td>\n",
       "      <td>2548.094482</td>\n",
       "      <td>1529.362061</td>\n",
       "      <td>4507.639648</td>\n",
       "      <td>3142.960449</td>\n",
       "      <td>2056.201660</td>\n",
       "      <td>2796.873047</td>\n",
       "      <td>4553.828125</td>\n",
       "      <td>2425.316895</td>\n",
       "      <td>...</td>\n",
       "      <td>2457.674805</td>\n",
       "      <td>3022.847656</td>\n",
       "      <td>3282.999756</td>\n",
       "      <td>6066.457031</td>\n",
       "      <td>3486.907471</td>\n",
       "      <td>2046.148804</td>\n",
       "      <td>3031.932129</td>\n",
       "      <td>3942.962402</td>\n",
       "      <td>5536.892578</td>\n",
       "      <td>1664.476562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Input squeeze top 200</td>\n",
       "      <td>5170.620605</td>\n",
       "      <td>4282.488770</td>\n",
       "      <td>3457.750000</td>\n",
       "      <td>6209.315430</td>\n",
       "      <td>4115.356445</td>\n",
       "      <td>2683.388672</td>\n",
       "      <td>3700.596680</td>\n",
       "      <td>5285.743652</td>\n",
       "      <td>4659.582031</td>\n",
       "      <td>...</td>\n",
       "      <td>2505.857178</td>\n",
       "      <td>4154.269043</td>\n",
       "      <td>4783.180664</td>\n",
       "      <td>6161.008789</td>\n",
       "      <td>4379.708984</td>\n",
       "      <td>2318.330078</td>\n",
       "      <td>3826.410400</td>\n",
       "      <td>6047.323242</td>\n",
       "      <td>7253.958008</td>\n",
       "      <td>2350.700195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gaussian1 attribution</td>\n",
       "      <td>2058.083496</td>\n",
       "      <td>1512.591797</td>\n",
       "      <td>4591.742188</td>\n",
       "      <td>3610.160645</td>\n",
       "      <td>1759.417236</td>\n",
       "      <td>2427.506348</td>\n",
       "      <td>3457.222412</td>\n",
       "      <td>2805.120605</td>\n",
       "      <td>2660.168701</td>\n",
       "      <td>...</td>\n",
       "      <td>1926.328979</td>\n",
       "      <td>4939.623047</td>\n",
       "      <td>2015.094482</td>\n",
       "      <td>3138.607666</td>\n",
       "      <td>2141.564697</td>\n",
       "      <td>3485.207031</td>\n",
       "      <td>2988.595947</td>\n",
       "      <td>3139.858398</td>\n",
       "      <td>2598.096191</td>\n",
       "      <td>3340.587891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gaussian2 attribution</td>\n",
       "      <td>1987.025879</td>\n",
       "      <td>1437.073364</td>\n",
       "      <td>4453.267578</td>\n",
       "      <td>2912.220459</td>\n",
       "      <td>1437.591309</td>\n",
       "      <td>2207.568115</td>\n",
       "      <td>2832.688721</td>\n",
       "      <td>2717.238037</td>\n",
       "      <td>2273.826904</td>\n",
       "      <td>...</td>\n",
       "      <td>1736.976807</td>\n",
       "      <td>4110.721680</td>\n",
       "      <td>1939.618896</td>\n",
       "      <td>2230.654053</td>\n",
       "      <td>2068.590820</td>\n",
       "      <td>2731.733887</td>\n",
       "      <td>2668.289795</td>\n",
       "      <td>2404.806885</td>\n",
       "      <td>2413.304688</td>\n",
       "      <td>4177.527344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gaussian3 attribution</td>\n",
       "      <td>1660.970825</td>\n",
       "      <td>1135.426147</td>\n",
       "      <td>3487.021973</td>\n",
       "      <td>2774.288086</td>\n",
       "      <td>1284.676270</td>\n",
       "      <td>2159.890381</td>\n",
       "      <td>2611.236572</td>\n",
       "      <td>2648.919189</td>\n",
       "      <td>2126.035889</td>\n",
       "      <td>...</td>\n",
       "      <td>1633.453613</td>\n",
       "      <td>4009.792969</td>\n",
       "      <td>1938.355103</td>\n",
       "      <td>2070.558594</td>\n",
       "      <td>2171.856689</td>\n",
       "      <td>2372.220459</td>\n",
       "      <td>2432.109619</td>\n",
       "      <td>2236.305908</td>\n",
       "      <td>2320.056152</td>\n",
       "      <td>3415.918213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Unifrom attribution</td>\n",
       "      <td>2100.951416</td>\n",
       "      <td>1423.103638</td>\n",
       "      <td>2918.373779</td>\n",
       "      <td>3010.822266</td>\n",
       "      <td>1265.957520</td>\n",
       "      <td>2313.497070</td>\n",
       "      <td>2982.402100</td>\n",
       "      <td>2781.512695</td>\n",
       "      <td>2519.150391</td>\n",
       "      <td>...</td>\n",
       "      <td>1674.358154</td>\n",
       "      <td>4739.211426</td>\n",
       "      <td>2321.792969</td>\n",
       "      <td>2798.257324</td>\n",
       "      <td>1843.193359</td>\n",
       "      <td>2631.107910</td>\n",
       "      <td>3006.612793</td>\n",
       "      <td>2627.519531</td>\n",
       "      <td>2662.880127</td>\n",
       "      <td>3184.976074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gaussian1 logit robusntess</td>\n",
       "      <td>3379.439453</td>\n",
       "      <td>2174.388428</td>\n",
       "      <td>2309.858154</td>\n",
       "      <td>3602.798828</td>\n",
       "      <td>2714.104492</td>\n",
       "      <td>2385.859375</td>\n",
       "      <td>2850.828613</td>\n",
       "      <td>3895.825195</td>\n",
       "      <td>3447.208008</td>\n",
       "      <td>...</td>\n",
       "      <td>2704.341553</td>\n",
       "      <td>3456.318848</td>\n",
       "      <td>2509.999512</td>\n",
       "      <td>5022.938477</td>\n",
       "      <td>3198.248779</td>\n",
       "      <td>2126.512939</td>\n",
       "      <td>3583.803467</td>\n",
       "      <td>5072.624023</td>\n",
       "      <td>6779.002441</td>\n",
       "      <td>2978.536621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gaussian2 logit robusntess</td>\n",
       "      <td>3621.924805</td>\n",
       "      <td>3134.299561</td>\n",
       "      <td>2275.599121</td>\n",
       "      <td>4264.901367</td>\n",
       "      <td>3442.013184</td>\n",
       "      <td>2686.653320</td>\n",
       "      <td>3639.207031</td>\n",
       "      <td>4201.635742</td>\n",
       "      <td>4157.773926</td>\n",
       "      <td>...</td>\n",
       "      <td>3174.351074</td>\n",
       "      <td>4439.166016</td>\n",
       "      <td>2722.755127</td>\n",
       "      <td>5914.911133</td>\n",
       "      <td>3443.627686</td>\n",
       "      <td>2322.263184</td>\n",
       "      <td>3798.295166</td>\n",
       "      <td>6094.173828</td>\n",
       "      <td>6839.426758</td>\n",
       "      <td>2619.165527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gaussian3 logit robusntess</td>\n",
       "      <td>4150.384277</td>\n",
       "      <td>4000.120361</td>\n",
       "      <td>2593.934326</td>\n",
       "      <td>4532.910156</td>\n",
       "      <td>3613.379883</td>\n",
       "      <td>2480.045898</td>\n",
       "      <td>4116.506348</td>\n",
       "      <td>4438.172852</td>\n",
       "      <td>4524.918945</td>\n",
       "      <td>...</td>\n",
       "      <td>3446.116699</td>\n",
       "      <td>4888.455078</td>\n",
       "      <td>3432.489502</td>\n",
       "      <td>6271.122070</td>\n",
       "      <td>3803.699219</td>\n",
       "      <td>2430.431885</td>\n",
       "      <td>4283.317383</td>\n",
       "      <td>6108.483398</td>\n",
       "      <td>7056.986328</td>\n",
       "      <td>2681.623535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Uniform logit robusntess</td>\n",
       "      <td>4383.148438</td>\n",
       "      <td>4294.405762</td>\n",
       "      <td>4118.792480</td>\n",
       "      <td>5716.517578</td>\n",
       "      <td>3793.641113</td>\n",
       "      <td>3128.244141</td>\n",
       "      <td>4448.709961</td>\n",
       "      <td>4865.911133</td>\n",
       "      <td>4513.285156</td>\n",
       "      <td>...</td>\n",
       "      <td>3972.127930</td>\n",
       "      <td>4222.874023</td>\n",
       "      <td>3866.113770</td>\n",
       "      <td>6314.219727</td>\n",
       "      <td>4891.716309</td>\n",
       "      <td>2280.019531</td>\n",
       "      <td>4308.629883</td>\n",
       "      <td>6223.528809</td>\n",
       "      <td>7490.967773</td>\n",
       "      <td>3037.934326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feature squeeze</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>1.020788</td>\n",
       "      <td>0.027935</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>0.762123</td>\n",
       "      <td>0.650761</td>\n",
       "      <td>0.106364</td>\n",
       "      <td>1.790647</td>\n",
       "      <td>0.150973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352322</td>\n",
       "      <td>0.641863</td>\n",
       "      <td>0.297523</td>\n",
       "      <td>0.046670</td>\n",
       "      <td>0.860570</td>\n",
       "      <td>0.662743</td>\n",
       "      <td>1.018593</td>\n",
       "      <td>1.540317</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.270967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Unnamed: 0            0            1            2   \n",
       "0   Benign Median Absolute Dev     0.011741     0.008387     0.020484  \\\n",
       "1     Benign Mean Absolute Dev     0.025300     0.014168     0.032768   \n",
       "2                   Benign IQR     0.028198     0.019277     0.046132   \n",
       "3      Coefficient of Variance     0.744189     1.045666     1.071272   \n",
       "4                  Coef of IQR     0.572312     0.543271     0.554579   \n",
       "5        Input squeeze top 100  2763.148926  2081.828369  1023.216736   \n",
       "6        Input squeeze top 150  3862.401367  2548.094482  1529.362061   \n",
       "7        Input squeeze top 200  5170.620605  4282.488770  3457.750000   \n",
       "8        Gaussian1 attribution  2058.083496  1512.591797  4591.742188   \n",
       "9        Gaussian2 attribution  1987.025879  1437.073364  4453.267578   \n",
       "10       Gaussian3 attribution  1660.970825  1135.426147  3487.021973   \n",
       "11         Unifrom attribution  2100.951416  1423.103638  2918.373779   \n",
       "12  Gaussian1 logit robusntess  3379.439453  2174.388428  2309.858154   \n",
       "13  Gaussian2 logit robusntess  3621.924805  3134.299561  2275.599121   \n",
       "14  Gaussian3 logit robusntess  4150.384277  4000.120361  2593.934326   \n",
       "15    Uniform logit robusntess  4383.148438  4294.405762  4118.792480   \n",
       "16             feature squeeze     0.009560     1.020788     0.027935   \n",
       "\n",
       "              3            4            5            6            7   \n",
       "0      0.021316     0.008825     0.017424     0.021685     0.021631  \\\n",
       "1      0.041157     0.022436     0.030149     0.036664     0.040445   \n",
       "2      0.052185     0.021889     0.040852     0.049536     0.050808   \n",
       "3      0.895818     0.670811     0.977936     1.021734     0.900896   \n",
       "4      0.591542     0.568094     0.587290     0.546192     0.562787   \n",
       "5   3165.566895  2523.543457  1926.836670  2048.480225  3013.867676   \n",
       "6   4507.639648  3142.960449  2056.201660  2796.873047  4553.828125   \n",
       "7   6209.315430  4115.356445  2683.388672  3700.596680  5285.743652   \n",
       "8   3610.160645  1759.417236  2427.506348  3457.222412  2805.120605   \n",
       "9   2912.220459  1437.591309  2207.568115  2832.688721  2717.238037   \n",
       "10  2774.288086  1284.676270  2159.890381  2611.236572  2648.919189   \n",
       "11  3010.822266  1265.957520  2313.497070  2982.402100  2781.512695   \n",
       "12  3602.798828  2714.104492  2385.859375  2850.828613  3895.825195   \n",
       "13  4264.901367  3442.013184  2686.653320  3639.207031  4201.635742   \n",
       "14  4532.910156  3613.379883  2480.045898  4116.506348  4438.172852   \n",
       "15  5716.517578  3793.641113  3128.244141  4448.709961  4865.911133   \n",
       "16     0.191392     0.762123     0.650761     0.106364     1.790647   \n",
       "\n",
       "              8  ...          500          501          502          503   \n",
       "0      0.016082  ...     0.012902     0.033298     0.015329     0.019026  \\\n",
       "1      0.028866  ...     0.022228     0.058719     0.028696     0.029467   \n",
       "2      0.037256  ...     0.030106     0.077184     0.037065     0.041414   \n",
       "3      0.944452  ...     0.977874     0.961550     0.887167     1.139028   \n",
       "4      0.566464  ...     0.594566     0.586153     0.608877     0.486604   \n",
       "5   2095.982178  ...  2124.283447  2703.627441  2947.141113  5345.160156   \n",
       "6   2425.316895  ...  2457.674805  3022.847656  3282.999756  6066.457031   \n",
       "7   4659.582031  ...  2505.857178  4154.269043  4783.180664  6161.008789   \n",
       "8   2660.168701  ...  1926.328979  4939.623047  2015.094482  3138.607666   \n",
       "9   2273.826904  ...  1736.976807  4110.721680  1939.618896  2230.654053   \n",
       "10  2126.035889  ...  1633.453613  4009.792969  1938.355103  2070.558594   \n",
       "11  2519.150391  ...  1674.358154  4739.211426  2321.792969  2798.257324   \n",
       "12  3447.208008  ...  2704.341553  3456.318848  2509.999512  5022.938477   \n",
       "13  4157.773926  ...  3174.351074  4439.166016  2722.755127  5914.911133   \n",
       "14  4524.918945  ...  3446.116699  4888.455078  3432.489502  6271.122070   \n",
       "15  4513.285156  ...  3972.127930  4222.874023  3866.113770  6314.219727   \n",
       "16     0.150973  ...     0.352322     0.641863     0.297523     0.046670   \n",
       "\n",
       "            504          505          506          507          508   \n",
       "0      0.012905     0.019164     0.021244     0.018071     0.020315  \\\n",
       "1      0.020665     0.030322     0.035129     0.036164     0.033193   \n",
       "2      0.028777     0.042910     0.048298     0.043622     0.045557   \n",
       "3      1.049775     1.091366     0.927226     0.875777     1.092827   \n",
       "4      0.538749     0.539617     0.588851     0.579019     0.507159   \n",
       "5   2508.094971  1528.462280  2568.843750  2811.551758  4963.367188   \n",
       "6   3486.907471  2046.148804  3031.932129  3942.962402  5536.892578   \n",
       "7   4379.708984  2318.330078  3826.410400  6047.323242  7253.958008   \n",
       "8   2141.564697  3485.207031  2988.595947  3139.858398  2598.096191   \n",
       "9   2068.590820  2731.733887  2668.289795  2404.806885  2413.304688   \n",
       "10  2171.856689  2372.220459  2432.109619  2236.305908  2320.056152   \n",
       "11  1843.193359  2631.107910  3006.612793  2627.519531  2662.880127   \n",
       "12  3198.248779  2126.512939  3583.803467  5072.624023  6779.002441   \n",
       "13  3443.627686  2322.263184  3798.295166  6094.173828  6839.426758   \n",
       "14  3803.699219  2430.431885  4283.317383  6108.483398  7056.986328   \n",
       "15  4891.716309  2280.019531  4308.629883  6223.528809  7490.967773   \n",
       "16     0.860570     0.662743     1.018593     1.540317     0.001657   \n",
       "\n",
       "            509  \n",
       "0      0.025899  \n",
       "1      0.041576  \n",
       "2      0.059069  \n",
       "3      1.086345  \n",
       "4      0.547000  \n",
       "5   1407.468872  \n",
       "6   1664.476562  \n",
       "7   2350.700195  \n",
       "8   3340.587891  \n",
       "9   4177.527344  \n",
       "10  3415.918213  \n",
       "11  3184.976074  \n",
       "12  2978.536621  \n",
       "13  2619.165527  \n",
       "14  2681.623535  \n",
       "15  3037.934326  \n",
       "16     0.270967  \n",
       "\n",
       "[17 rows x 511 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fe4ba3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_squeezer = df_imagenet.iloc[16].values.flatten().tolist()[1:]\n",
    "threshold = [1.36418, 1.3909, 1.299158]\n",
    "\n",
    "def compute_metrics(ben, threshold): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in ben: \n",
    "        if value<threshold:\n",
    "            TN += 1\n",
    "        else: \n",
    "            FP += 1\n",
    "    \n",
    "    \n",
    "    return (FP/(TN+FP))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0b2b797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.941176470588237\n",
      "11.76470588235294\n",
      "15.294117647058824\n"
     ]
    }
   ],
   "source": [
    "for th in threshold:\n",
    "    FPR = compute_metrics(feature_squeezer, th)\n",
    "    print(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f5c7ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.015,0.019,0.022]\n",
    "b=[0.11,0.11,0.11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "179a956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanAbsDev = df_imagenet.iloc[1].values.flatten().tolist()[1:]\n",
    "medianAbsDev = df_imagenet.iloc[0].values.flatten().tolist()[1:]\n",
    "iqr = df_imagenet.iloc[2].values.flatten().tolist()[1:]\n",
    "coef_iqr = df_imagenet.iloc[4].values.flatten().tolist()[1:]\n",
    "coef_var = df_imagenet.iloc[3].values.flatten().tolist()[1:]\n",
    "\n",
    "squeezer_input = df_imagenet.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "logit_gaussian3 = df_imagenet.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_imagenet.iloc[10].values.flatten().tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8c56365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, ap1, i, j, ap2a, k, l, ap2b, m, n, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value5, value6, value7, value8 in zip(meanAb,medianAb,coefiqr,coefvar,ap1,ap2a,ap2b, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else: \n",
    "                        if value5<i or value5>j:\n",
    "                            FP +=1\n",
    "                        else: \n",
    "                            if value6<k or value6>l:\n",
    "                                FP +=1\n",
    "                            else:\n",
    "                                if value7<m or value7>n:\n",
    "                                    FP +=1\n",
    "                                else:\n",
    "                                    if value8<o or value8>p:\n",
    "                                        FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cceb0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.015,0.019,0.022]\n",
    "b=[0.11,0.11,0.11]\n",
    "c=[0.008,0.01,0.0115]\n",
    "d=[0.055,0.055,0.055]\n",
    "e=[0.49,0.516,0.5257]\n",
    "f=[0.74,0.74,0.74]\n",
    "g=[0.38,0.38,0.38]\n",
    "h=[1.14,1.09,1.07]\n",
    "\n",
    "\n",
    "i=[1300,1800,2000]\n",
    "j=[5700,5700,5700]\n",
    "\n",
    "k=[1810,2510,2810]\n",
    "l=[6700,6700,6700]\n",
    "\n",
    "m=[1400,1750,1900]\n",
    "n=[6600,6600,6600]\n",
    "\n",
    "\n",
    "#iqr\n",
    "o=[0.019,0.024,0.027]\n",
    "p=[0.13,0.13,0.13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a73da393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.019607843137255\n",
      "28.627450980392155\n",
      "42.745098039215684\n"
     ]
    }
   ],
   "source": [
    "print(compute_metrics(meanAbsDev, a[0], b[0],\n",
    "                      medianAbsDev ,c[0], d[0],\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                      squeezer_input,i[0],j[0], \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0], \n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics(meanAbsDev, a[1], b[1], \n",
    "                      medianAbsDev, c[1], d[1], \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                      squeezer_input,i[1],j[1], \n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1], \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics(meanAbsDev, a[2], b[2],\n",
    "                      medianAbsDev , c[2], d[2],\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                      squeezer_input,i[2],j[2], \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2], \n",
    "                      iqr, o[2], p[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f47c081c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.941176470588235\n",
      "12.549019607843137\n",
      "23.52941176470588\n"
     ]
    }
   ],
   "source": [
    "#using statistical approach only \n",
    "\n",
    "def compute_metrics(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value8 in zip(meanAb,medianAb,coefiqr,coefvar, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else:\n",
    "                        if value8<o or value8>p:\n",
    "                            FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics(meanAbsDev, a[0], b[0],\n",
    "                      medianAbsDev ,c[0], d[0],\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                      \n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics(meanAbsDev, a[1], b[1], \n",
    "                      medianAbsDev, c[1], d[1], \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                     \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics(meanAbsDev, a[2], b[2],\n",
    "                      medianAbsDev , c[2], d[2],\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                     \n",
    "                      iqr, o[2], p[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c0eaf19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7843137254901961\n",
      "4.117647058823529\n",
      "9.607843137254903\n"
     ]
    }
   ],
   "source": [
    "meanAbsDev = df_imagenet.iloc[1].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(meanAb, a, b): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1 in (meanAb): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        \n",
    "    return (FP/(len(meanAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[0], b[0]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[1], b[1]))\n",
    "\n",
    "print(compute_metrics1(meanAbsDev, a[2], b[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8080c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9803921568627451\n",
      "4.705882352941177\n",
      "9.215686274509805\n"
     ]
    }
   ],
   "source": [
    "medianAbsDev = df_imagenet.iloc[0].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(medianAb, c,d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value2 in (medianAb): \n",
    "        if value2<c or value2>d:\n",
    "            FP += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (FP/(len(medianAb)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev ,c[0], d[0]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev, c[1], d[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      medianAbsDev , c[2], d[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ad58ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1764705882352942\n",
      "5.098039215686274\n",
      "8.627450980392156\n"
     ]
    }
   ],
   "source": [
    "iqr = df_imagenet.iloc[2].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value8 in (iqr): \n",
    "        if value8<o or value8>p:\n",
    "            FP += 1\n",
    "    \n",
    "    return (FP/(len(iqr)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                    \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      iqr, o[2], p[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2e04bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7843137254901961\n",
      "4.313725490196078\n",
      "8.03921568627451\n"
     ]
    }
   ],
   "source": [
    "coef_iqr = df_imagenet.iloc[4].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(coefiqr, e, f): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value3 in (coefiqr): \n",
    "        if value3<e or value3>f:\n",
    "            FP += 1\n",
    "    \n",
    "    return (FP/(len(coefiqr)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_iqr, e[0], f[0]))\n",
    "                    \n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_iqr, e[1], f[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_iqr , e[2], f[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5658cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3725490196078431\n",
      "5.294117647058823\n",
      "8.823529411764707\n"
     ]
    }
   ],
   "source": [
    "coef_var = df_imagenet.iloc[3].values.flatten().tolist()[1:]\n",
    "def compute_metrics1(coefvar, g, h): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value4 in (coefvar): \n",
    "        if value4<g or value4>h:\n",
    "            FP += 1   \n",
    "    \n",
    "    return (FP/(len(coefvar)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_var, g[0], h[0]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_var, g[1], h[1]))\n",
    "\n",
    "print(compute_metrics1(\n",
    "                      coef_var,g[2], h[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "06b1b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8431372549019605\n",
      "26.078431372549023\n",
      "38.82352941176471\n"
     ]
    }
   ],
   "source": [
    "#using approach 2 and statistical\n",
    "def compute_metrics(meanAb, a, b, medianAb, c,d, coefiqr, e, f, coefvar, g, h, ap2a, k, l, ap2b, m, n, iqr, o, p): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2, value3, value4, value6, value7, value8 in zip(meanAb,medianAb,coefiqr,coefvar,ap2a,ap2b, iqr): \n",
    "        if value1<a or value1>b:\n",
    "            FP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                FP +=1\n",
    "            else: \n",
    "                if value3<e or value3>f:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value4<g or value4>h:\n",
    "                        FP +=1\n",
    "                    else:\n",
    "                        if value6<k or value6>l:\n",
    "                            FP +=1\n",
    "                        else:\n",
    "                            if value7<m or value7>n:\n",
    "                                FP +=1\n",
    "                            else:\n",
    "                                if value8<o or value8>p:\n",
    "                                    FP +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(meanAb)))*100\n",
    "\n",
    "print(compute_metrics(meanAbsDev, a[0], b[0],\n",
    "                      medianAbsDev ,c[0], d[0],\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                     \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0], \n",
    "                      iqr, o[0], p[0]))\n",
    "\n",
    "print(compute_metrics(meanAbsDev, a[1], b[1], \n",
    "                      medianAbsDev, c[1], d[1], \n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                     \n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1], \n",
    "                      iqr, o[1], p[1]))\n",
    "\n",
    "print(compute_metrics(meanAbsDev, a[2], b[2],\n",
    "                      medianAbsDev , c[2], d[2],\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                      \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2], \n",
    "                      iqr, o[2], p[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f072e963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8431372549019605\n",
      "25.68627450980392\n",
      "37.84313725490196\n"
     ]
    }
   ],
   "source": [
    "#using approach 2 and coef of var and coef of iqr\n",
    "def compute_metrics( coefiqr, e, f, coefvar, g, h, ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value3, value4, value6, value7 in zip(coefiqr,coefvar,ap2a,ap2b): \n",
    "        if value3<e or value3>f:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value4<g or value4>h:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value6<k or value6>l:\n",
    "                    FP +=1\n",
    "                else:\n",
    "                    if value7<m or value7>n:\n",
    "                        FP +=1\n",
    "              \n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(coefiqr)))*100\n",
    "\n",
    "print(compute_metrics(\n",
    "                      coef_iqr , e[0], f[0], \n",
    "                      coef_var, g[0], h[0],\n",
    "                     \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0], \n",
    "                      ))\n",
    "\n",
    "print(compute_metrics(\n",
    "                      coef_iqr, e[1], f[1],\n",
    "                      coef_var, g[1], h[1], \n",
    "                     \n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1], \n",
    "                    ))\n",
    "\n",
    "print(compute_metrics(\n",
    "                      coef_iqr , e[2], f[2], \n",
    "                      coef_var,g[2], h[2],\n",
    "                      \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2], \n",
    "                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "771bf40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.450980392156863\n",
      "24.313725490196077\n",
      "35.68627450980392\n"
     ]
    }
   ],
   "source": [
    "#using approach 2 and coef of var\n",
    "def compute_metrics( coefvar, g, h, ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value4, value6, value7 in zip(coefvar,ap2a,ap2b): \n",
    "        if value4<g or value4>h:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value6<k or value6>l:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value7<m or value7>n:\n",
    "                    FP +=1\n",
    "              \n",
    "\n",
    "    \n",
    "    \n",
    "    return (FP/(len(coefvar)))*100\n",
    "\n",
    "print(compute_metrics(\n",
    "                      \n",
    "                      coef_var, g[0], h[0],\n",
    "                     \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0], \n",
    "                      ))\n",
    "\n",
    "print(compute_metrics(\n",
    "                     \n",
    "                      coef_var, g[1], h[1], \n",
    "                     \n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1], \n",
    "                    ))\n",
    "\n",
    "print(compute_metrics(\n",
    "                      \n",
    "                      coef_var,g[2], h[2],\n",
    "                      \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2], \n",
    "                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8d10fca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.647058823529412\n",
      "23.72549019607843\n",
      "34.509803921568626\n"
     ]
    }
   ],
   "source": [
    "#using approach 1 and 2 only\n",
    "squeezer_input = df_imagenet.iloc[6].values.flatten().tolist()[1:]\n",
    "logit_gaussian3 = df_imagenet.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_imagenet.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2(ap1, i, j, ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value5, value6, value7 in zip(ap1,ap2a,ap2b):\n",
    "        if value5<i or value5>j:\n",
    "            FP +=1\n",
    "        else: \n",
    "            if value6<k or value6>l:\n",
    "                FP +=1\n",
    "            else:\n",
    "                if value7<m or value7>n:\n",
    "                    FP +=1\n",
    "\n",
    "    return (FP/(len(ap1)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[0],j[0], \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0]))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[1],j[1], \n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1]))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[2],j[2], \n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1bcaa8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.156862745098039\n",
      "5.686274509803922\n",
      "12.352941176470589\n"
     ]
    }
   ],
   "source": [
    "#using approach 1  only\n",
    "squeezer_input = df_imagenet.iloc[6].values.flatten().tolist()[1:]\n",
    "\n",
    "\n",
    "def compute_metrics2(ap1, i, j): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value5 in (ap1):\n",
    "        if value5<i or value5>j:\n",
    "            FP +=1\n",
    "\n",
    "    return (FP/(len(ap1)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[0],j[0]\n",
    "                      ))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[1],j[1]))\n",
    "\n",
    "print(compute_metrics2(squeezer_input,i[2],j[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f1765849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2745098039215685\n",
      "20.784313725490197\n",
      "29.607843137254903\n"
     ]
    }
   ],
   "source": [
    "#using approach 2 only\n",
    "logit_gaussian3 = df_imagenet.iloc[14].values.flatten().tolist()[1:]\n",
    "attr_gaussian3 = df_imagenet.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2(ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics2( \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      attr_gaussian3,m[0], n[0]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[1],l[1],\n",
    "                     attr_gaussian3,m[1], n[1]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                     attr_gaussian3,m[2], n[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "001bfa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5686274509803921\n",
      "6.470588235294119\n",
      "10.392156862745098\n"
     ]
    }
   ],
   "source": [
    "#using approach 2a only\n",
    "logit_gaussian3 = df_imagenet.iloc[14].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2(ap2a, k, l): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6 in (ap2a):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "       \n",
    "    return (FP/(len(ap2a)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics2( \n",
    "                      logit_gaussian3, k[0],l[0],\n",
    "                      ))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[1],l[1]\n",
    "   ))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                      logit_gaussian3, k[2],l[2],\n",
    "                   ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9996cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.705882352941177\n",
      "15.88235294117647\n",
      "23.52941176470588\n"
     ]
    }
   ],
   "source": [
    "#using approach 2b only\n",
    "attr_gaussian3 = df_imagenet.iloc[10].values.flatten().tolist()[1:]\n",
    "\n",
    "def compute_metrics2( ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value7 in (ap2b):\n",
    "        if value7<m or value7>n:\n",
    "            FP +=1\n",
    "        \n",
    "    return (FP/(len(ap2b)))*100\n",
    "\n",
    "\n",
    "print(compute_metrics2( \n",
    "                     \n",
    "                      attr_gaussian3,m[0], n[0]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                     \n",
    "                     attr_gaussian3,m[1], n[1]))\n",
    "\n",
    "print(compute_metrics2(\n",
    "                     \n",
    "                     attr_gaussian3,m[2], n[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8c776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
